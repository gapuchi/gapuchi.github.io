{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Index","text":"<p>This site contains my notes of various topics that I have looked into. Some of it may be incomplete, rough, or not thorough depending on what I wanted to learn.</p> <p>Check it out. Or don't. I'm not a cop.</p>"},{"location":"notes/AWS/ecs/","title":"Elastic Container Service","text":"<p>A highly scalable, fast container service that makes it easy to run, stop, and manage containers on a cluster. (Cluster here could be many things, e.g. Fargate or EC2)</p>"},{"location":"notes/AWS/ecs/#security","title":"Security","text":""},{"location":"notes/AWS/ecs/#ecs-task-execution-role","title":"ECS Task Execution Role","text":"<p>Allows ECS container and Fargate agents to make API calls.</p> <p>https://aws.amazon.com/blogs/compute/building-blocks-of-amazon-ecs/</p>"},{"location":"notes/AWS/ecs/#services","title":"Services","text":"<p>ECS Service allows you to run and maintain a specified number of instances of a task definition simultaneously in an Amazon ECS cluster.</p>"},{"location":"notes/AWS/eks/","title":"EKS","text":""},{"location":"notes/AWS/eks/#iam-roles-for-service-accounts-irsa","title":"IAM Roles for Service Accounts (IRSA)","text":"<p>Documentation</p> <p>Amazon EKS supports IRSA - which allows clusters operators to map IAM Roles to Kubernetes Service Accounts.</p> <p>This helps control access to other AWS tools, such as S3.</p> <p>This works with IAM OpenID Connect Provider (OIDC) that EKS exposes. OIDC is an identity layer on top of the OAuth 2.0 protocol, that verifies the identity of the End-User based on the authentication performed by the Authentication Server.</p> <p>In EKS, there is an admission controller that injects AWS session credentials into pods based on the annotations on the Service Account used by the pod.</p> <p>Just because EKS has a OIDC Provider URL does not mean that an existing identity provider exists! Check \"Identity Providers\" under IAM to see if there exists one. Most like you'll need to create one : <code>eksctl utils associate-iam-oidc-provider --cluster &lt;cluster_name&gt; --approve</code></p> <p>In <code>eksctl</code>, the IAM Role and Service Accounts are represented by a resource <code>iamserviceaccount</code>.</p> <p>Why does EKS have its own auth config map for permissioning? Why not have permission in IAM roles?</p> <p>This is for permission model inside Kubernetes, to allow AWS permission inside of it. (So not permission on a pod level, but on a Kubernetes user level).</p>"},{"location":"notes/AWS/eks/#identity-and-access-management","title":"Identity and Access Management","text":"<ol> <li>Service-linked Role - <code>AWSServiceRoleForAmazonEKS</code></li> <li>Service-linked Role (Node Groups) - <code>AWSServiceRoleForAmazonEKSNodegroup</code></li> <li>Cluster IAM Role</li> <li>Node IAM Role</li> <li>Pod execution IAM Role</li> <li>Service Account (Kubernetes) IAM Role (IRSA)</li> </ol>"},{"location":"notes/AWS/emr-on-eks/","title":"EMR on EKS","text":""},{"location":"notes/AWS/emr-on-eks/#emr-getting-permission-for-eks","title":"EMR Getting Permission For EKS","text":"<pre><code>eksctl create iamidentitymapping \\\n    --cluster my_eks_cluster \\\n    --namespace kubernetes_namespace \\\n    --service-name \"emr-containers\"\n</code></pre> <p>What this does:</p> <ol> <li>Create Kubernetes Role - \"emr-containers\"</li> <li>Create Kubernetes RoleBinding - Role \"emr-containers\", User \"emr-containers\"</li> <li>Update <code>aws-auth</code> config map to map IAM Role <code>AWSServiceRoleForAmazonEMRContainers</code> to User \"emr-containers\"</li> </ol> <p>Who creates the User \"emr-containers\"?</p> <p>From K8s doc: In this regard, Kubernetes does not have objects which represent normal user accounts. Normal users cannot be added to a cluster through an API call.</p>"},{"location":"notes/AWS/emr-on-eks/#logging","title":"Logging","text":"<p>EMR on EKS uses FluentD for logging. A dedicated container is created, the name of which contains \"fluentd\" (as of 2021-04-19).</p>"},{"location":"notes/AWS/kinesis-streams/","title":"Amazon Kinesis Data Streams","text":"<p>Kinesis Data Streams can be used to collect and process large streams of data records in real time.</p> Kinesis Data Stream A set of shards. Each shard has a sequence of data records. Each data record has a sequence number. Data Record A unit of data stored in a Kinesis data stream. It is a composition of a sequence number, partition key, and a data blob. Shard A uniquely identified sequence of data records in a stream. Each shard provides a unit of capacity (5 TPS reads, total 2MB/sec, 1000 records/sec writes, total 1MB/sec write)"},{"location":"notes/AWS/route-53/","title":"Route 53","text":"<p>Amazon Route 53 is a DNS web service. With this you can:</p> <ol> <li>register domains</li> <li>route DNS</li> <li>health check</li> </ol>"},{"location":"notes/AWS/vpc/","title":"VPCs and Subnets","text":""},{"location":"notes/AWS/vpc/#vpc-concepts","title":"VPC Concepts","text":"Virtual Private Cloud (VPC) A virtual network dedicated to your AWS account Subnet A range of IP addresses in your VPC. Route table A set of rules (called routes) that are used to determine where network traffic is directed. Internet gateway A gateway that is attached to your VPC to enable communication between resources in your VPC and the internet VPC endpoint Enables you to privately connect your VPC to supported AWS services and VPC endpoints. This is powered by one of: * PrivateLink without requiring an internet gateway * NAT device * VPN connection * AWS Direct Connect connection CIDR block Classless Inter-Domain Routing. An internet protocol address allocation and route aggregation methodology."},{"location":"notes/AWS/vpc/#vpc","title":"VPC","text":"<p>A VPC is logically isolated from other virtual networks in the AWS Cloud. You can launch AWS resources like EC2 instances, into your VPC.</p> <p>When you create a VPC, you have to specify a range of IPv4 addresses (in the form of a CIDR block).</p> <p>If you specify <code>10.0.0.0/16</code>, then your main route table will look like:</p> Destination Target 10.0.0.0/16 local <p>A VPC spans all of the Availability Zones in the Region. </p>"},{"location":"notes/AWS/vpc/#subnet","title":"Subnet","text":"<p>Once you have a VPC, you can then specify subnets in any of the AZs. A subnet must reside entirely in one AZ and cannot span zones. Each subnet will also have IP addresses that is a subset of the VPC's IP addresses.</p> Public Subnet A subnet whose traffic is routed to an internet gateway. Private Subnet A subnet that doesn't have a route to the internet gateway. <p>If you want your instance in a public subnet to communicate with the internet over IPv4, it must have a public IPv4 address or an Elastic IP address (IPv4).</p> <pre><code>//TODO Public IPv4 Addresses\n</code></pre> <p>The first 4 IP addresses and the last IP address in each subnet CIDR block is reserved. For example, for a subnet with a CIDR block <code>10.0.0.0/24</code>, the following are reserved.</p> IP Address Purpose <code>10.0.0.0</code> Network address <code>10.0.0.1</code> Reserved by AWS for the VPC router. <code>10.0.0.2</code> Reserved by AWS for the DNS server. The DNS server actually runs on the base of the VPC addresses plus two, but the base + 2 is also reserved for all subnets. If there are multiple CIDR blocks, the main CIDR is used. <code>10.0.0.3</code> Reserved by AWS for the future. <code>10.0.0.255</code> Network broadcast address. AWS does not support broadcast in a VPC, so this is reserved. <p>A VPC can have multiple CIDR blocks?</p> <p>Yes! You can can assign multiple CIDR blocks to a VPC. If you create a VPC with <code>10.0.0.0/16</code>, you can later add <code>10.2.0.0/16</code> to the VPC. It can then have subnets under each of these CIDR blocks. The first block is the main CIDR block.</p>"},{"location":"notes/AWS/vpc/#routing","title":"Routing","text":"<ul> <li>Each subnet must be associated with a route table. </li> <li>Each subnet is automatically associated with the main route table for the VPC.</li> </ul> <p>If a subnet had the following route table:</p> Destination Target 10.0.0.0/16 local 0.0.0.0/0 igw-id <p>All IPv4 traffic (represented by <code>0.0.0.0/0</code>) would be routed to an internet gateway (<code>igw-id</code>). (Again, it must have a public IPv4 address or an Elastic IP address). Because it'd have a public IPv4 address, it can be accessed by the internet.</p> <p>If you want to prevent unsolicited inbound connections from the internet but still have outbound connections, you can use a network address translation (NAT) gateway or instance. Since the number of Elastic IP addresses are limited, using a NAT gateway is suggested if there a lot of instances needing public IP addresses.</p> <pre><code>//TODO\nNAT\n</code></pre>"},{"location":"notes/AWS/vpc/#security","title":"Security","text":"<p>Two features are in AWS to increase security in your VPC:</p> <ol> <li>Security groups</li> <li>Network ACL's</li> </ol> <p>Security groups control inbound and outbound traffic for your instances.</p> <p>Network ACL's control inbound and outbound traffic for your subnets.</p> <p>Security groups in most cases can meet your needs.</p> <p>Each subnet must be associated with a network ACL. Every subnet created will be associated with the VPC's default network ACL.</p>"},{"location":"notes/AWS/vpc/#default-vpc","title":"Default VPC","text":"<p>Every account comes with a default VPC that has a default subnet in each Availability Zone. </p> <pre><code>\\\\TODO Read up on AZ\n</code></pre>"},{"location":"notes/AWS/vpc/#route-tables","title":"Route Tables","text":"<p>You can associate a subnet with a particular route table.</p> <p>Otherwise, the subnet is implicitly associated with the main route table. (What is the main route table?)</p> <p>Route table has a one to many relationship with subnet</p> <p>Route table has a many to one relationship with a VPC</p>"},{"location":"notes/AWS/vpc/#connecting-to-internet","title":"Connecting To Internet","text":"<p>Your default VPC includes an internet gateway.</p> <p>Each default subnet is a \"public\" subnet. Each instance launched in these subnets has a private and public IPv4 address. These instances can communicate with the internet.</p> <p>Each instance launched into a nondefault subnet has a private IPv4 address and no public IPv4 address (by default, unless you assign one). These instances can communicate with each other but not the internet.</p>"},{"location":"notes/AWS/vpc/#eni","title":"ENI","text":"<p>An elastic network interface is a logical networking component in a VPC that represents a virtual network card. It can include the following attributes:</p>"},{"location":"notes/containers/namespaces/","title":"Container Namespaces","text":"<p>My notes from this Medium article.</p> <p>Containers are:</p> <ol> <li>isolated</li> <li>groups of processes</li> <li>running on a single host</li> <li>which fulfill a set of common features.</li> </ol>"},{"location":"notes/containers/namespaces/#chroot","title":"Chroot","text":"<p>Most Unix operating systems have the ability to change the root directory of the current process (and its children). This is available as the syscall <code>chroot(2)</code>. It is also known as jail.</p> <p>What is the significance of changing the root?</p> <p>It (kinda) changes the environment. The root contains all the binaries/libraries that processes can use. When you kick off a shell, one of the processes that gets kicked off is <code>bash</code>. The process looks for this in <code>/bin/bash</code>.</p> <p>It was used in the first approaches of running microservices. It is currently used by a wide range of applications, including within build systems for different distributions.</p> <p>How can we set up a chroot environment? With little effort:</p> <pre><code>$ mkdir -p new-root/{bin,lib64}\n$ cp /bin/bash new-root/bin\n$ cp /lib64/{ld-linux-x86-64.so*,libc.so*,libdl.so.*,libreadline.so*,libtinfo.so*} new-root/lib64\n// This isn't working on my system because a dependency is missing\n$ sudo chroot new-root\n</code></pre> <p>This creates a new folder, copies the bash shell and its dependencies to this folder, and sets this new folder as the root. This jail only has bash capabilities (and everything that comes with bash, e.g. <code>cd</code>, <code>pwd</code>, etc.). Not really a useful jail, but a working example.</p> <p>Could we run a binary in this jail and call it a container? No.</p>"},{"location":"notes/containers/namespaces/#why-cant-we-create-containers-with-chroot","title":"Why can't we create containers with <code>chroot</code>?","text":"<p>Let's take a look at the 4 attributes of containers:</p> <ol> <li>isolated? It actually isn't isolated. We will expand on this below.</li> <li>groups of processes? Yes. In linux, processes live in a tree structure, so this means having a root process. A root process can then kick off child processes, giving us a group of processes.</li> <li>running on a single host? Yes.</li> <li>which fulfill a set of common features. Yes.* This is kinda vague, but we can set up a chroot environment with proper functionalities to support a set of common features.</li> </ol> <p>Let's take a look at the \"isolation\" a jail provides.</p> <p>The current working directory is unchanged when calling <code>chroot(2)</code> via a syscall. Although your absolute paths are different now, relative paths can still refer to files outside of the new root.</p> <p>Only priviledged processes with the <code>CAP_SYS_CHROOT</code> capability are able to call <code>chroot</code>.</p> <p>Calls to <code>chroot</code> do not stack. It will override the current jail. So a root user could escape jail with a program like:</p> <pre><code>#include &lt;sys/stat.h&gt;\n#include &lt;unistd.h&gt;\n\nint main(void)\n{\nmkdir(\".out\", 0755);                        //Create a new folder\nchroot(\".out\");                             //Make it the new root, removing the old jail\nchdir(\"../../../../../\");                   //Changed the working directory to a location outside of the jail\nchroot(\".\");                                //Made it the new root\nreturn execl(\"/bin/bash\", \"-i\", NULL);\n}\n</code></pre> <p>Did we need to create a new jail before changing the working directory outside of the jail? Could we not have used the current jail?</p> <p>So, <code>chroot</code> doesn't give isolation of the file system.</p> <p>We can sneak peak outside of a jail from a process perspective:</p> <pre><code>$ mkdir /proc\n$ mount -t proc proc /proc\n$ ps aux\n...\n</code></pre> <p>There is no process isolation at all. We can even kill processes outside of the jail.</p> <p>We can sneak peak out of a jail from a network perspective:</p> <pre><code>$ mkdir /sys\n$ mount -t sysfs sys /sys\n$ ls /sys/class/net\neth0 lo\n</code></pre> <p>There is no network isolation either.</p> <p>This lack of isolation is a security risk - and doesn't meet the criteria for a container to be isolated.</p> <p>How do we address this? Using Linux namespaces.</p>"},{"location":"notes/containers/namespaces/#linux-namespaces","title":"Linux Namespaces","text":"<p>The idea - wrap certain global system resources in an abstraction layer. This allows different groups of processes to have different views of the system.</p> <p>Processes within a namespace have their own isolated instance of the resources.</p> Namespaces (General) a space of names (Linux) a type of namespace (e.g. process id, mount, etc.) <p>What is important here is that the term \"namespaces\" are used in different ways. When a process is \"in a namespace\", it is in an instance of a namespace type.</p> <p>There are 7 namespace (or I'll refer to is as \"namespace types\" to keep terminology less confusing):</p> <ol> <li>mnt</li> <li>pid</li> <li>net</li> <li>ipc</li> <li>uts</li> <li>cgroup</li> <li>user</li> </ol> <p>A process will be in a namespace of every type. (It will have a specific <code>mnt</code> ns, <code>pid</code> ns, etc.)</p> <p>There were two more proposed in 2016 - time and syslog, but they have not been implemented yet.</p> <p>With the introduction of user namespace in 2013, the kernel became \"container ready\".</p>"},{"location":"notes/containers/namespaces/#namespace-api","title":"Namespace API","text":"<p>Before we look at the namespaces, it'll be useful to look at the namespace API. It consists of 3 system calls.</p> <p>Coming from an OO background, I assumed \"namespace API\" meant the API of a namespace. I assume that each namespace had a \"verb\" or an implementation of the below API's that could vary among the namespace types. This is not the case.</p> <p>Rather, it is an API of the kernel (?) that operates with namespaces. These are syscall's.</p>"},{"location":"notes/containers/namespaces/#1-clone","title":"1. clone","text":"<p><code>clone(2)</code> creates a new child process, like <code>fork(2)</code>. Unlike <code>fork</code>, <code>clone</code> allows the child process to share parts of its execution context with the calling process (such as the memory space, the table of file descriptors, and table of signal handlers).</p> <p>You can pass different namespace flags to <code>clone</code> to create new namespaces for the child process.</p>"},{"location":"notes/containers/namespaces/#2-unshare","title":"2. unshare","text":"<p><code>unshare(2)</code> allows a process to disassociate parts of the execution context which are currently being shared with others.</p>"},{"location":"notes/containers/namespaces/#3-setns","title":"3. setns","text":"<p><code>setns(2)</code> reassociates the calling thread with the provided namespace file descriptor.</p> <p>This can be used to join an existing namespace.</p>"},{"location":"notes/containers/namespaces/#proc","title":"proc","text":"<p>Not a syscall, but the <code>proc</code> filesystem provides additional namespace related files. Each file in <code>/proc/$PID/ns</code> is a magic link that be used as a handle for performing operations (like <code>setns</code>) to the referenced namespace.</p> <pre><code>$ ps\n    PID TTY          TIME CMD\n  24900 pts/2    00:00:00 zsh\n  25039 pts/2    00:00:00 ps\n</code></pre> <pre><code>$ ls -Gg /proc/24900/ns\ntotal 0\nlrwxrwxrwx 1 0 Feb 21 16:37 cgroup -&gt; 'cgroup:[4026531835]'\nlrwxrwxrwx 1 0 Feb 21 16:37 ipc -&gt; 'ipc:[4026531839]'\nlrwxrwxrwx 1 0 Feb 21 16:37 mnt -&gt; 'mnt:[4026531840]'\nlrwxrwxrwx 1 0 Feb 21 16:37 net -&gt; 'net:[4026532000]'\nlrwxrwxrwx 1 0 Feb 21 16:37 pid -&gt; 'pid:[4026531836]'\nlrwxrwxrwx 1 0 Feb 21 16:37 pid_for_children -&gt; 'pid:[4026531836]'\nlrwxrwxrwx 1 0 Feb 21 16:37 time -&gt; 'time:[4026531834]'\nlrwxrwxrwx 1 0 Feb 21 16:37 time_for_children -&gt; 'time:[4026531834]'\nlrwxrwxrwx 1 0 Feb 21 16:37 user -&gt; 'user:[4026531837]'\nlrwxrwxrwx 1 0 Feb 21 16:37 uts -&gt; 'uts:[4026531838]'\n</code></pre> <pre><code>$ ls -Gg /proc/self/ns\ntotal 0\nlrwxrwxrwx 1 0 Feb 21 16:40 cgroup -&gt; 'cgroup:[4026531835]'\nlrwxrwxrwx 1 0 Feb 21 16:40 ipc -&gt; 'ipc:[4026531839]'\nlrwxrwxrwx 1 0 Feb 21 16:40 mnt -&gt; 'mnt:[4026531840]'\nlrwxrwxrwx 1 0 Feb 21 16:40 net -&gt; 'net:[4026532000]'\nlrwxrwxrwx 1 0 Feb 21 16:40 pid -&gt; 'pid:[4026531836]'\nlrwxrwxrwx 1 0 Feb 21 16:40 pid_for_children -&gt; 'pid:[4026531836]'\nlrwxrwxrwx 1 0 Feb 21 16:40 time -&gt; 'time:[4026531834]'\nlrwxrwxrwx 1 0 Feb 21 16:40 time_for_children -&gt; 'time:[4026531834]'\nlrwxrwxrwx 1 0 Feb 21 16:40 user -&gt; 'user:[4026531837]'\nlrwxrwxrwx 1 0 Feb 21 16:40 uts -&gt; 'uts:[4026531838]'\n</code></pre> <p>We can actually track which namespaces a process resides in using this.</p> <p>Another tool, <code>util-linux</code> package, contains dedicated wrapper programs for the above syscalls.</p>"},{"location":"notes/containers/namespaces/#available-namespaces-or-namespace-types","title":"Available Namespaces (or Namespace Types)","text":""},{"location":"notes/containers/namespaces/#mount-mnt","title":"Mount (mnt)","text":"<p>With the <code>mnt</code> namespace, Linux is able to isolate a set of mount points by a group of processes. Another way to put this, for a group of processes, we have a specific set of mount points. This abstraction gives us the ability to create an entire virtual environment where we are the root user even without root permissions.</p> <p>The flag for this namespace type is <code>CLONE_NEWNS</code> (CLONE NEW NameSpace). This was the first implemented namespace (2002) and most people didn't think more than one namespace was needed, which was why this flag is so generic.</p> <p>A use case for the mnt namespace is to improve our jail (by making it more secure):</p> <pre><code>$ sudo unshare -m\n# mkdir mount-dir\n# mount -n -o size=10m -t tmpfs tmpfs mount-dir\n# man mount\n# df mount-dir/\nFilesystem      Size  Used Avail Use% Mounted on\ntmpfs            10M     0   10M   0% /home/arjun/mount-dir\n# touch mount-dir/{0,1,2}\n# ls mount-dir/\n0  1  2\n</code></pre> <p>If we try to access this on the host system:</p> <pre><code>$ la mount-dir\ntotal 0\n$ grep mount-dir /proc/mounts\n$\n</code></pre> <p>We see folder (a file) created in the first namespace, but no files under it. This is because we mounted a tmpfs (a temporary fs) to that folder and added files to that mount. Since our host system is in another <code>mnt</code> namespace, it cannot see these files, or see this mount.</p> <p>We can actually see the mount point in the <code>mountinfo</code> file inside of the <code>proc</code> filesystem:</p> <pre><code>$ grep mount-dir /proc/$(pgrep -u root bash)/mountinfo\n441 440 0:54 / /home/arjun/mount-dir rw,relatime - tmpfs tmpfs rw,size=10240k,inode64\n</code></pre> <p>The memory being used here is in an abstraction layer called Virtual File System (VFS), which is part of the kernel. This is also where other file systems are based on. If the namespace gets destroyed, the mount memory is unrecoverably lost.</p> <p>How to work with these mount points in the source code? Programs tend to keep track of the <code>/proc/$PID/ns/mnt</code> file, which is referring to the used namespace.</p>"},{"location":"notes/containers/namespaces/#unix-time-sharing-system-uts","title":"UNIX Time-sharing System (uts)","text":"<p>With the <code>uts</code> namespace, we can unshare the domain and hostname from the current host system.</p> <pre><code>$ hostname\narjun-b250hd3\n$ sudo unshare -u\n# hostname\narjun-b250hd3\n# hostname a-cooler-hostname\n# hostname\na-cooler-hostname\n</code></pre> <p>and if we look at the system:</p> <pre><code>$ hostname\narjun-b250hd3\n</code></pre> <p>it is unchanged. This is useful for container networking related topics.</p>"},{"location":"notes/containers/namespaces/#interprocess-communication-ipc","title":"Interprocess Communication (ipc)","text":"<p>With the <code>ipc</code> namespace, we can isolate interprocess communication (IPC) resources.</p> <p>These are System V IPC objects and POSIX message queues.</p> <p>Use Case - Separate the shared memory (SHM) between two processes.</p> <p>Each process will be able to use the same identifiers for a shared memory segment and have two different regions.</p> <p>When an IPC namespace is destroyed, all IPC objects in the namespace is destroyed too.</p>"},{"location":"notes/containers/namespaces/#process-id-pid","title":"Process ID (pid)","text":"<p>With the <code>pid</code> namespaces, processes can have independent set of process identifiers (PIDs).</p> <p>Process in two different <code>pid</code> namespaces can have the same PID.</p> <p>A process will have more than one PID:</p> <ol> <li>the PID inside the namespace</li> <li>the PID on the host system</li> </ol> <p>The <code>pid</code> namespace can be nested, so a process will have a PID for each namespace from its current namespace up to the initial namespace.</p> <p>Does this mean the host system can still see this process? This namespace doesn't seem to isolate the process from other namespaces. Only the PID.</p> <p>The first process created in a <code>pid</code> namespace gets the number 1 and gains all the same special treatment as the usual init process, like:</p> <ul> <li>All processes within a namespace will be reparented to the namespace's PID 1 instead of the host system's PID 1.</li> <li>The termination of this PID will terminate all processes in its PID namespace and any descendants.</li> </ul> <pre><code>$ ps aux\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot           1  0.0  0.0 171184 10752 ?        Ss   16:22   0:00 /sbin/init\nroot           2  0.0  0.0      0     0 ?        S    16:22   0:00 [kthreadd]\nroot           3  0.0  0.0      0     0 ?        I&lt;   16:22   0:00 [rcu_gp]\n.... //The list goes on\n$ sudo unshare -fp --mount-proc\n# ps aux\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot           1  0.0  0.0   7728  4484 pts/4    S    17:27   0:00 -bash\nroot           6  0.0  0.0   9876  3424 pts/4    R+   17:27   0:00 ps aux\n#\n</code></pre> <p><code>--mount-proc</code> is needed to remount the <code>proc</code> filesystem. Why? We didn't unshare the <code>mnt</code> namespace.</p>"},{"location":"notes/containers/namespaces/#network-net","title":"Network (net)","text":"<p>With the <code>net</code> namespace, we can virtualize the network stack.</p> <p>Each network namespace contains its own resource properties within <code>/proc/net</code>.</p> <p>A network namespace only contains a loopback interface on creation:</p> <pre><code>$ sudo unshare -n\n[arjun-b250hd3 gapuchi.github.io]# ip link\n1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n</code></pre> <p>Every network interface (physical or virtual) is present exactly once per namespace.</p> <p>An interface can be moved between namespaces.</p> <p>Each namespace contains:</p> <ul> <li>a private set of IP addresses</li> <li>its own routing table</li> <li>socket listing</li> <li>connection tracking table</li> <li>firewall</li> <li>other network-related resources</li> </ul> <p>Destroying a network namespace will destroy any virtual interfaces and move any physical interfaces back to teh initial network namespace.</p>"},{"location":"notes/containers/namespaces/#use-case-software-defined-network","title":"Use Case - Software Defined Network","text":"<p>TBD</p>"},{"location":"notes/containers/namespaces/#user-id-user","title":"User ID (user)","text":"<p>With the <code>user</code> namespace, we can isolate user and group IDs.</p> <p>This allows a user and group ID's of a process be different inside and outside of the namespace.</p> <p>Use Case - A process can have a normal, unprivileged user ID outside a user namespace while being fully privileged inside.</p> <pre><code>$ whoami\narjun\n$ id -u\n1000\n$ unshare -U\n$ whoami\nnobody\n$ id -u\n65534\n</code></pre> <p>After we create the namespace, the files <code>/proc/$PID/{u,g}id_map</code> expose the mappings for user and group ID's for the PID. This can be written only once. These files contain a 1:1 mapping a range of contiguous user IDs between two user namespaces.</p> <p>An example file:</p> <pre><code>&gt; cat /proc/$PID/uid_map\n0 1000 1\n</code></pre> <p>This means user ID starting at <code>0</code> are mapped to ID <code>1000</code>, with the length of the range of <code>1</code>. (Meaning only user ID <code>0</code> is mapped to <code>1000</code>. user ID <code>1</code> isn't mapped to <code>1001</code> with this.)</p> <p>If a process tried to access a file, its user and group IDs are mapped to the initial user namespace (for permission checking).</p> <p>When a process retrieves file user and group IDs (via <code>stat(2)</code>), the IDs are mapped in the opposite direction (i.e. to ID's within the namespace).</p> <p>The file <code>/proc/$PID/setgroups</code> contains either <code>allow</code> or <code>deny</code> (literally) to enable or disable the permission to call the <code>setgroups(2)</code> syscall within a user namespace. This prevented an unprivileged process to create a new namespace where the user had all the privileges. The user would be able to drop groups with <code>setgroups(2)</code> to gain access files previously not accessible.</p>"},{"location":"notes/containers/namespaces/#control-group-cgroup","title":"Control Group (cgroup)","text":"<p>cgroups was a dedicated kernel feature to support resource limiting, prioritization, accounting, and controlling.</p> <p>With the <code>cgroups</code> namespace, we can prevent leaking host information into a namespace.</p> <p>Not really sure what cgroup really is. Will expand this with the demo later.</p>"},{"location":"notes/containers/namespaces/#composing-namespaces","title":"Composing Namespaces","text":"<p>Namespaces are composable, making it possible to have isolated <code>pid</code> namespaces which share the same network interface (which apparently is done in Kubernetes Pods).</p> <p>As an example, let's create a new <code>pid</code> namespace:</p> <pre><code>$ sudo unshare -fp --mount-proc\n# ps aux\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot           1  0.0  0.0   7728  4452 pts/2    S    18:25   0:00 -bash\nroot           6  0.0  0.0   9876  3352 pts/2    R+   18:26   0:00 ps aux\n</code></pre> <p>The <code>setns(2)</code> syscall (with its appropriate wrapper program <code>nsenter</code>) can be used to join the namespace. First find the <code>pid</code> we want to join with:</p> <pre><code># export PID=$(pgrep -u root bash)\n</code></pre> <p>Now we can join the namespace:</p> <pre><code># sudo nsenter --pid=/proc/$PID/ns/pid unshare --mount-proc\n# ps aux\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot           1  0.0  0.0   7728  4488 pts/2    S    18:25   0:00 -bash\nroot          10  0.0  0.0  15764  7268 pts/2    S    18:26   0:00 sudo nsenter --pid=/proc/1/ns/pid unshare --mount-proc\nroot          11  0.0  0.0   5360   740 pts/2    S    18:26   0:00 nsenter --pid=/proc/1/ns/pid unshare --mount-proc\nroot          12  0.0  0.0   7720  4480 pts/2    S    18:26   0:00 -bash\nroot          17  0.0  0.0   9876  3320 pts/2    R+   18:26   0:00 ps aux\n#\n</code></pre> <p>We are now in the same <code>pid</code> namespace. Cool!</p>"},{"location":"notes/containers/oci/","title":"Open Contianer Initiative (OCI)","text":"<p>https://opencontainers.org/</p> <p>The mission of the Open Container Initiative (OCI) is to promote a set of common, minimal, open standards and specifications around container technology.</p> <p>OCI is an open governance structure (i.e. project) to create open industry standards around container formats and runtime.</p> <p>OCI contains two specifications:</p> <ol> <li>Runtime Specification (runtime-spec)</li> <li>Image Specification (image-spec)</li> </ol> <p>Runtime Specification outlines how to run a \"filesystem bundle\" that is unpacked on a disk. High level, an OCI implementation would download an OCI image and unpack it into an OCI Runtime filesystem bundle. This would then be run by an OCI Runtime.</p> <p>This workflow should provide the ability to run an image with no additional arguments (a common expectation from users of container engines like Docker and rkt)</p> <pre><code>docker run example.com/org/app:v1.0.0\nrkt run example.com/org/app,version=v1.0.0\n</code></pre> <p>In order to do this, the OCI Image Format contains the needed info to launch the application on the target platform. This includes arguments, command, env variables, etc. The specification defines how to create an OCI Image.</p> <p>The creation of the image is usually done by a build system and outputs:</p> <ul> <li>image manifest - contains metadata about the contents and dependencies of the image. Including the content-addressable (TODO - define this) identity of one or more filesystem serialization archives that will be unpacked to make up the final funnable filesystem. (TODO - explain all of this)</li> <li>filesystem (layer) serialization - TODO</li> <li>image configuration - includes info such as app arguments, environments, etc.</li> </ul> <pre><code>TODO Link all the terms above.\n</code></pre>"},{"location":"notes/containers/oci/#image-spec","title":"Image Spec","text":"<p>Ref: https://github.com/opencontainers/image-spec</p> <p>OCI Image Specification</p>"},{"location":"notes/data_structures/advanced-topics/","title":"Topological Sort","text":"<ol> <li>Identify all nodes with no incoming edges</li> <li>Add to order</li> <li>Remove all outgoing edges</li> <li>Repeat</li> </ol>"},{"location":"notes/data_structures/advanced-topics/#dijkstras-algorithm","title":"Dijkstra's Algorithm","text":"<p>Finds shortest path from a to b</p>"},{"location":"notes/data_structures/advanced-topics/#setup","title":"Setup","text":"<ol> <li>Create <code>weight</code> datastructure. Stores for every node <code>x</code> the weight from <code>a</code> to <code>x</code>. Everything should be infinite except <code>a</code> which should be <code>0</code>.</li> <li>Create <code>previous</code> datastructure. Stores for every node <code>x</code> the previous node that leads to the current weight. Should be null for everything</li> <li>Create <code>remaining</code> priority queue. Prioritize on lowest weight. Should start with <code>a</code>.</li> </ol>"},{"location":"notes/data_structures/advanced-topics/#algorithm","title":"Algorithm","text":"<ol> <li>Take the lowest node (<code>y</code>) from <code>remaining</code> (first time it is <code>a</code>)</li> <li>For every neighbor, check the current <code>weight</code> with <code>y</code>'s weight + the weight from <code>y</code> to neighbor. If y's path is better, update <code>weight</code> and <code>previous</code>.</li> <li>Remove <code>y</code>.</li> <li>Repeat.</li> </ol> <p>Why a priority queue?</p> <p>Because the shortest path has the opportunity for providing a quicker way to other paths. If <code>b</code> is <code>3</code> and <code>c</code> is <code>70</code>, it doesn't make sense to check <code>c</code> because <code>b</code> might have a shorter path to <code>c</code>. Then the check on <code>c</code> is useless because <code>c</code> wasn't the shortest.</p> <p>By checking the shortest first, we guarantee when we get to node <code>x</code>, there are no other paths to <code>x</code> that would be shorter, because every other weight is higher.</p>"},{"location":"notes/data_structures/implementations/","title":"Implementations","text":"<pre><code>class Node {\nint val;\n\nNode left;\nNode right;\n\nconstructor\n}\n</code></pre>"},{"location":"notes/data_structures/implementations/#bfs","title":"BFS","text":""},{"location":"notes/data_structures/implementations/#iterative","title":"Iterative","text":"<pre><code>int val = 3;\n\nLinkedList&lt;Node&gt; queue = new LinkedList&lt;Node&gt;();\n\nqueue.add(root);\n\n\nwhile(queue.isNotEmpty()) {\nNode x = queue.pop();\nif (x == val) {\nreturn x;\n}\n\nqueue.add(x.left);\nqueue.add(x.right);\n}\n</code></pre>"},{"location":"notes/data_structures/implementations/#dfs","title":"DFS","text":""},{"location":"notes/data_structures/implementations/#iterative_1","title":"Iterative","text":"<pre><code>int val = 3;\n\nStack&lt;Node&gt; stack = new Stack&lt;Node&gt;();\n\nqueue.push(root);\n\n\nwhile(queue.isNotEmpty()) {\nNode x = queue.pop();\nif (x == val) {\nreturn x;\n}\n\nqueue.push(x.left);\nqueue.push(x.right);\n}\n</code></pre>"},{"location":"notes/data_structures/implementations/#recursive","title":"Recursive","text":"<pre><code>int val = 3;\n\nStack&lt;Node&gt; stack = new Stack&lt;Node&gt;();\n\nqueue.push(root);\n\n\nwhile(queue.isNotEmpty()) {\nNode x = queue.pop();\nif (x == val) {\nreturn x;\n}\n\nqueue.push(x.left);\nqueue.push(x.right);\n}\n\nprivate Node search(Node node) {\nif (node.x == val) {\nreturn x;\n} }\n</code></pre>"},{"location":"notes/data_structures/recursion-and-dynamic-programming/","title":"Approaches","text":""},{"location":"notes/data_structures/recursion-and-dynamic-programming/#bottom-up-approach","title":"Bottom-Up Approach","text":"<p>Solve for a simple case (such as a list with one element) and work your way up.</p>"},{"location":"notes/data_structures/recursion-and-dynamic-programming/#top-down-approach","title":"Top-Down Approach","text":"<p>How can we divide the problem for case N into subproblems</p>"},{"location":"notes/data_structures/recursion-and-dynamic-programming/#half-and-half-approach","title":"Half and Half Approach","text":"<p>Solve data by splitting into half.</p>"},{"location":"notes/data_structures/recursion-and-dynamic-programming/#recursive-vs-iterative","title":"Recursive vs Iterative","text":"<p>Recursive can be very space inefficient. It is better to implement a recursive algorithm iteratively. All recursive algorithms can be implemented iteratively.</p> <p>How to do this?</p> <pre><code>int fib(int i) {\nif (i == 0) return 0;\nif (i == 1) return 1;\nreturn fib(i - 1) + fib(i - 2);\n}\n</code></pre> <pre><code>int fib(int i) {\n\nif (i == 0) return 0;\nif (i == 1) return 1;\n\nint acc = 0;\n\nwhile (true) {\n\n}\n}\n</code></pre>"},{"location":"notes/data_structures/recursion-and-dynamic-programming/#dynamic-programming-and-memoization","title":"Dynamic Programming and Memoization","text":"<p>Essentially is a recursive program where subproblems are repeated, so we cache these problems.</p> <p>Memoization is top-down dynamic programming. Others refer DP as bottom up.</p>"},{"location":"notes/data_structures/recursion-and-dynamic-programming/#fibonacci-numbers","title":"Fibonacci Numbers","text":""},{"location":"notes/data_structures/recursion-and-dynamic-programming/#recursive","title":"Recursive","text":"<pre><code>int fib(int i) {\nif (i == 0) return 0;\nif (i == 1) return 1;\nreturn fib(i - 1) + fib(i - 2);\n}\n</code></pre> <p>Runtime? O( 2^n^ ). Every <code>n</code> makes two calls. </p>"},{"location":"notes/data_structures/recursion-and-dynamic-programming/#memoization","title":"Memoization","text":"<pre><code>int fib(int i) {\nreturn fib(i, new int[i + 1])\n}\n\nif fib(int i, int[] memo) {\nif (i == 0 || i == 1) return i;\n\nif (memo[i] == 0) {\nmemo[i] = fib(i - 1, memo) + fib(i - 2, memo);\n}\n\nreturn memo[i];\n}\n</code></pre> <p>Runtime? O( n ). Every <code>n</code> is calculated once</p>"},{"location":"notes/data_structures/recursion-and-dynamic-programming/#bottoms-up-dp","title":"Bottoms Up DP","text":"<pre><code>if fib(int i) {\nif (i == 0 || i == 1) return i;\n\nint[] memo = new int[n];\nmemo[0] = 0;\nmemo[1] = 1;\n\nfor(int j = 2; j &lt; n; j++) {\nmemo[j] = memo[j - 1] + memo[j - 2];\n}\n\nreturn memo[n - 1] + memo[n - 2];\n}\n</code></pre> <p>Can this be done with recursion? No. Because recursion is about breaking a problem down. This is building it up.</p>"},{"location":"notes/data_structures/sort-and-search/","title":"Sorting","text":""},{"location":"notes/data_structures/sort-and-search/#bubble-sort","title":"Bubble Sort","text":"Runtime Average Runtime Worst Memory O( n^2^ ) O( n^2^ ) O(1) <p>Start at the beginning of array and swap if needed. Keep doing this until there are no more swaps.</p>"},{"location":"notes/data_structures/sort-and-search/#selection-sort","title":"Selection Sort","text":"Runtime Average Runtime Worst Memory O( n^2^ ) O( n^2^ ) O(1) <p>Sweep and find the smallest and swap with first position. Repeat.</p>"},{"location":"notes/data_structures/sort-and-search/#merge-sort","title":"Merge Sort","text":"Runtime Average Runtime Worst Memory O(n log(n)) O(n log(n)) O(n) <p>Divide arrays into halves (repeatedly) and then join.</p>"},{"location":"notes/data_structures/sort-and-search/#psuedo-code","title":"Psuedo Code","text":"<pre><code>def mergesort\nmergesort(left)\nmergesort(right)\nmerge(left, right)\n\ndef merge\ncopy array to helper\niterate through left and right, copying the smaller element back into array\ncopy the remaining left (you don't need to copy the remaining right because they're already there)\n</code></pre>"},{"location":"notes/data_structures/sort-and-search/#quick-sort","title":"Quick Sort","text":"Runtime Average Runtime Worst Memory O(n log(n)) O(n^2^) O(log n) <p>Pick a random element and parition the array. Then sort both sides.</p>"},{"location":"notes/data_structures/sort-and-search/#psuedo-code_1","title":"Psuedo Code","text":"<pre><code>def quicksort\npartition (put elements on both sides)\nquicksort left\nquicksort right\n\ndef partition\nchoose pivot\nfind element on left that should be on right\nfind element on right that should be on left\nswap\nreturn center index\n</code></pre>"},{"location":"notes/data_structures/sort-and-search/#radix-sort","title":"Radix Sort","text":"Runtime Average Runtime Worst Memory O(kn) O(kn) O(n log n) <p>Not applicable all the time. Example, sorting integers. Takes advantage that a digit is one of 10 options. k is the number of iterations.</p> <p>So if we're sorting numbers, first sort on units, tens, and then hundreds.</p>"},{"location":"notes/data_structures/sort-and-search/#searching","title":"Searching","text":""},{"location":"notes/data_structures/sort-and-search/#binary-search","title":"Binary Search","text":"<p>... You know it.</p>"},{"location":"notes/data_structures/tree-balance/","title":"AVL","text":""},{"location":"notes/data_structures/tree-balance/#red-black","title":"Red Black","text":"<ol> <li>Every node is either red or black</li> <li>Root is black</li> <li>The leaves which are NULL are black</li> <li>Red must have two black children</li> <li>Every path from a node to its leave must have the same number of black children</li> </ol>"},{"location":"notes/data_structures/tree-balance/#b-trees","title":"B Trees","text":""},{"location":"notes/data_structures/tree-balance/#a","title":"A*","text":""},{"location":"notes/data_structures/trees-and-graphs/","title":"Trees and Graphs","text":"<ul> <li>Complete - Levels are filled. (Bottom is filled left to right)</li> <li>Full - Nodes have either 0 or 2 leaves</li> <li>Perfect - Complete and Full</li> </ul>"},{"location":"notes/data_structures/trees-and-graphs/#binary-tree-traversal","title":"Binary Tree Traversal","text":"<ul> <li>In Order - left, current, right</li> <li>Pre Order - current, left, right</li> <li>Post Order - left, right, current</li> </ul>"},{"location":"notes/data_structures/trees-and-graphs/#binary-heaps","title":"Binary Heaps","text":"<ul> <li>Complete Binary Tree</li> </ul>"},{"location":"notes/data_structures/trees-and-graphs/#insert","title":"Insert","text":"<ul> <li>Insert and the next available space (left to right)</li> <li>Compare with parent. Swap unitl its fine  </li> </ul>"},{"location":"notes/data_structures/trees-and-graphs/#remove-min","title":"Remove min","text":"<ul> <li>Take the last element and put it on top. Swap down (swap with the lower of the two)</li> </ul>"},{"location":"notes/data_structures/trees-and-graphs/#graphs","title":"Graphs","text":"<p>TBD</p> <ul> <li>Adjacency List</li> <li>Adjacency Matrix</li> </ul>"},{"location":"notes/data_structures/trees-and-graphs/#graph-search","title":"Graph Search","text":"<p>BFS - If we want to find the shortest path DFS - If we want to search the whole thing</p>"},{"location":"notes/data_structures/trees-and-graphs/#dfs","title":"DFS","text":""},{"location":"notes/data_structures/trees-and-graphs/#recursive","title":"Recursive","text":"<ul> <li>Call search on each child</li> </ul>"},{"location":"notes/data_structures/trees-and-graphs/#iterative","title":"Iterative","text":"<ul> <li>Stack</li> </ul>"},{"location":"notes/data_structures/trees-and-graphs/#bfs","title":"BFS","text":"<ul> <li>Can not be recursive. Use a queue.</li> </ul>"},{"location":"notes/database/transactions/","title":"Transactions","text":"<p>Read-your-writes consistency - A value written by a process on a data item X will be always available to a successive read operation performed by the same process on data item X.</p>"},{"location":"notes/docker/privileged/","title":"Docker Privileges","text":""},{"location":"notes/golang/intro/","title":"A Tour of Go","text":""},{"location":"notes/golang/intro/#packages-variables-functions","title":"Packages, Variables, Functions","text":""},{"location":"notes/golang/intro/#packages","title":"Packages","text":"<p>A Go program is made of packages.</p> <p>Programs start running in package <code>main</code>.</p> <p>[Convention] Package name is the same as the last element of the import path. For example, <code>\"math/rand\"</code> package comprises of fiels that begin with the statement <code>package rand</code>.</p> <p>Below is an example <code>main</code> package which uses packages with import paths <code>\"fmt\"</code> and <code>\"math/rand\"</code></p> <pre><code>package main\n\nimport (\n\"fmt\"\n\"math/rand\"\n)\n\nfunc main() {\nfmt.Println(\"My favorite number is\", rand.Intn(10))\n}\n</code></pre>"},{"location":"notes/golang/intro/#import","title":"Import","text":"<p>You can group imports into a parenthesized, \"factored\" import statement.</p> <p>You could also write multiple import statements, like:</p> <pre><code>import \"fmt\"\nimport \"math\"\n</code></pre> <p>[Convention] It is good style to use the factored import statement.</p>"},{"location":"notes/golang/intro/#exported-names","title":"Exported Names","text":"<p>When importing a package, you can only refer to its exported names. Any unexported names are not accessible from outside the package.</p> <p>A name is exported if it begins with a capital letter. e.g. <code>Pizza</code>. <code>pizza</code> is unexported.</p> <pre><code>package main\n\nimport (\n\"fmt\"\n\"math\"\n)\n\nfunc main() {\nfmt.Println(math.pi) //Fails because pi, not Pi\n}\n</code></pre>"},{"location":"notes/golang/intro/#function","title":"Function","text":"<pre><code>func add(x int, y int) int {\nreturn x + y\n}\n</code></pre> <p>Note type goes after the variable name. </p> <p>See also: Go's Declaration Syntax.</p> <p>If consecutive function parameters share a type, you can omit the type from all except the last.</p> <pre><code>func add(x, y int) int {\nreturn x + y\n}\n</code></pre> <p>A function can return any number of results</p> <pre><code>func swap(x, y string) (string, string) {\nreturn y, x\n}\n</code></pre> <p>A function's returned values can be named. If they are, they are treated as variables defined in the top of the function.</p> <p>A <code>return</code> statement without arguments returns the named return values. This is know as a naked return.</p> <pre><code>func split(sum int) (x, y int) {\nx = sum * 4 / 9\ny = sum - x\nreturn\n}\n</code></pre>"},{"location":"notes/golang/intro/#variables","title":"Variables","text":"<p><code>var</code> declares a list of variables, with the type being at the end.</p> <p>It can be used at a package or a function level.</p> <pre><code>package main\n\nimport \"fmt\"\n\nvar c, python, java bool\n\nfunc main() {\nvar i int\nfmt.Println(i, c, python, java)\n}\n</code></pre> <p>A <code>var</code> declaration can include initializers, one per variable. If an initializer is present, the type can be omitted.</p> <pre><code>var i, j int = 1, 2\nvar c, python, java = true, false, \"no!\"\n</code></pre> <p>Inside a function, the <code>:=</code> short assignment statement can be used instead of <code>var</code>, with implicit type.</p> <p>Outside a function, the <code>:=</code> is not available because every statement must start with a keyword (<code>var</code>, <code>func</code>, etc).</p>"},{"location":"notes/golang/intro/#zero-value","title":"Zero Value","text":"<p>Variables declared without an explicit initial value are given their zero value. These are:</p> <ul> <li><code>0</code> for numeric types.</li> <li><code>false</code> for boolean type</li> <li><code>\"\"</code> for strings.</li> </ul>"},{"location":"notes/golang/intro/#type-conversion","title":"Type Conversion","text":"<p>The expression <code>T(v)</code> converts the value <code>v</code> to the type <code>T</code>.</p> <pre><code>i := 42\nf := float64(i)\nu := uint(f)\n</code></pre>"},{"location":"notes/golang/intro/#type-inference","title":"Type Inference","text":"<p>When declaring a variable without specifying an explicit type, the variable's type is inferred from the value on the right hand side.</p>"},{"location":"notes/golang/intro/#constants","title":"Constants","text":"<p>Constants are declared using the <code>const</code> keyword. It cannot be declared using the <code>:=</code> syntax.</p>"},{"location":"notes/golang/intro/#flow-control","title":"Flow Control","text":""},{"location":"notes/golang/intro/#for","title":"For","text":"<p>Go has only one looping construct, <code>for</code>.</p> <p>It's basically like Java's <code>for</code> loop. Init statement, condition, and post statement.</p> <pre><code>for i := 0; i &lt; 10; i++ {\nsum += i\n}\n</code></pre> <p>You don't need <code>()</code> surrounding the three components and <code>{}</code> are always required.</p> <p>The init and post statements are optional.</p> <pre><code>for ; sum &lt; 1000; {\nsum += sum\n}\n</code></pre> <p>You can drop the semicolons, and by magic, it becomes a <code>while</code> loop.</p> <pre><code>for sum &lt; 1000 {\nsum += sum\n}\n</code></pre> <p>You can drop the condition and it loops forever.</p> <pre><code>for {\nsum += sum\n}\n</code></pre>"},{"location":"notes/golang/intro/#if","title":"If","text":"<p>Like <code>for</code>, the expression need not be surround by <code>()</code> and <code>{}</code> are required.</p> <pre><code>if x &lt; 0 {\nreturn sqrt(-x) + \"i\"\n}\n</code></pre> <p><code>if</code> statement can start with a short statement to execute before the condition.</p> <pre><code>if v := math.Pow(x, n); v &lt; lim {\nreturn v\n}\n</code></pre> <p>Variables declared by the statement are only in scope until the end of the <code>if</code>.</p> <p>Variables declared by the statement are also available inside any of the <code>else</code> blocks.</p> <pre><code>if v := math.Pow(x, n); v &lt; lim {\nreturn v\n} else {\nfmt.Printf(\"%g &gt;= %g\\n\", v, lim)\n}\n</code></pre>"},{"location":"notes/golang/intro/#switch","title":"Switch","text":"<p>The <code>switch</code> is like in Java, a nicer way to write <code>if/else</code> statements. Unlike Java, it only runs the first matching case. The cases also do not need to be constants.</p> <pre><code>switch os := runtime.GOOS; os {\ncase \"darwin\":\nfmt.Println(\"OS X.\")\ncase \"linux\":\nfmt.Println(\"Linux.\")\ndefault:\nfmt.Printf(\"%s.\\n\", os)\n}\n</code></pre> <p>It evaluates top to bottom, and does not evaluate other cases once a matching case is found.</p> <p>You can write a switch statement without a condition and it'll be interpreted as <code>switch true {...</code>. You can use this to write complex <code>if/else</code> statements.</p> <pre><code>switch {\ncase t.Hour() &lt; 12:\nfmt.Println(\"Good morning!\")\ncase t.Hour() &lt; 17:\nfmt.Println(\"Good afternoon.\")\ndefault:\nfmt.Println(\"Good evening.\")\n}\n</code></pre>"},{"location":"notes/golang/intro/#defer","title":"Defer","text":"<p>A <code>defer</code> statement delays the execution of a function until the surrounding function returns.</p> <pre><code>func main() {\ndefer fmt.Println(\"world\")\n\nfmt.Println(\"hello\")\n}\n</code></pre> <p>In Java, we can consider this to be <code>finally</code>. It's useful for cleaning up after a function. The nice thing about this is that you can declare the clean up function as soon as it is relevant instead of at the end. Nicer organizaiton.</p> <p>Couple traits:</p> <ol> <li>A deferred function\u2019s arguments are evaluated when the defer statement is evaluated. If a variable in the defer statement is changed after the defer statement, it won't reflect in the call of the defer function.</li> <li>Deferred function calls are executed in Last In First Out order after the surrounding function returns.</li> <li>Deferred functions may read and assign to the returning function\u2019s named return values. (Useful for errors.)</li> </ol> <pre><code>func c() (i int) {\ndefer func() { i++ }()\nreturn 1\n}\n</code></pre> <p>This will return <code>2</code>.</p> Panic A built-in function that stops the normal flow of control and begins panicking. If a function invokes <code>panic</code>, everything stops, any deferred functions are executed normally, and returns to the caller. The caller would see function as if it was a <code>panic</code>. Panic bubbles up until all the functions in the goroutine have returned. Program then crashes. Recover A built-in function that regains control of a panicking goroutine. It is only useful in deferred functions. A call to recover will return <code>Nil</code> if the function isn't panicking and will return the value passed to the <code>panic</code> if the function was panicking and then resume normally. <pre><code>package main\n\nimport \"fmt\"\n\nfunc main() {\nf()\nfmt.Println(\"Returned normally from f.\")\n}\n\nfunc f() {\ndefer func() {\nif r := recover(); r != nil {\nfmt.Println(\"Recovered in f\", r)\n}\n}()\nfmt.Println(\"Calling g.\")\ng(0)\nfmt.Println(\"Returned normally from g.\")\n}\n\nfunc g(i int) {\nif i &gt; 3 {\nfmt.Println(\"Panicking!\")\npanic(fmt.Sprintf(\"%v\", i))\n}\ndefer fmt.Println(\"Defer in g\", i)\nfmt.Println(\"Printing in g\", i)\ng(i + 1)\n}\n</code></pre> <p>Would output</p> <pre><code>Calling g.\nPrinting in g 0\nPrinting in g 1\nPrinting in g 2\nPrinting in g 3\nPanicking!\nDefer in g 3\nDefer in g 2\nDefer in g 1\nDefer in g 0\nRecovered in f 4\nReturned normally from f.\n</code></pre> <p>The convention in the Go libraries is that even when a package uses panic internally, its external API still presents explicit error return values.</p>"},{"location":"notes/golang/intro/#pointers","title":"Pointers","text":"Pointer A pointer holds a memory address of a value. <p>The type <code>*T</code> is a pointer to a <code>T</code> value. Its zero value is <code>nil</code>.</p> <pre><code>var p *int\n</code></pre> <p>The <code>&amp;</code> generates a pointer to its operand.</p> <pre><code>i := 42\np = &amp;i //p is a pointer to 42\n</code></pre> <p>The <code>*</code> operator denotes the pointer's underlying value.</p> <pre><code>fmt.Println(*p) // read i through the pointer p\n*p = 21         // set i through the pointer p\n</code></pre> <p>This is known as \"dereferencing\" or \"indirecting\". </p>"},{"location":"notes/golang/intro/#structs","title":"Structs","text":"Struct A <code>struct</code> is a collection of fields. <p>The struct's fields are accessed using a <code>.</code></p> <pre><code>type Vertex struct {\nX int\nY int\n}\n\nfunc main() {\nv := Vertex{1, 2}\nv.X = 4\nfmt.Println(v.X)\n}\n</code></pre> <p>The struct's fields can also be accessed through a struct pointer.</p> <p>If we want to access field <code>X</code> of a struct pointer <code>p</code>, we could do <code>(*p).X</code>, but that is verbose. So it's simplified to <code>p.X</code>.</p> Struct Literal A struct literal represents a newly allocat struct value by listing the values of its fields. <p>You can list a subset of the fields using <code>Name:</code> (and the order doesn't matter).</p> <p>The <code>&amp;</code> prefix returns a pointer to the struct value.</p> <pre><code>v1 = Vertex{1, 2}  // has type Vertex\nv2 = Vertex{X: 1}  // Y:0 is implicit\nv3 = Vertex{}      // X:0 and Y:0\np  = &amp;Vertex{1, 2} // has type *Vertex\n</code></pre>"},{"location":"notes/golang/intro/#arrays","title":"Arrays","text":"<p>The type <code>[n]T</code> is an array of <code>n</code> values of type <code>T</code>.</p> <p>So <code>var a [10]int</code> is an array of 10 ints. An array cannot be resized, so its okay that the size is part of its type. (Or maybe the other way around? The size is part of the type so an array size cannot be changed?)</p>"},{"location":"notes/golang/intro/#slices","title":"Slices","text":"<p>A slice is a dynamically-sized, flexible view into the elements of an array (which is a fixed size).</p> <p>The type <code>[]T</code> is a slice with elements of type <code>T</code>.</p> <p>A slice is formed by declaring a low and high bound - <code>a[low  : high]</code>. It includes the first index and excludes the last one. </p> <p>Consider a slice as a reference to an array, it doesn't store any values on its own. If you change a value in a slice, you modify the array and all other slices looking at it.</p> <p>A slice literal is like an array literal <code>[3]bool{true, true, false}</code> but without the length (so <code>[]bool{true, true, false}</code>). The slice literal creates the same array and a slice of it (returning the slice).</p> <p>You can emit the low and high bounds for a slice and let use default low (<code>0</code>) and high (length of the array). (e.g. <code>a[0:]</code>, <code>a[:5]</code>, <code>a[:]</code>)</p> slice length The number of elements the slice contains slice capacity The number of elements in the underlying array, starting from the beginning of the slice. <p>To get the length and capacity, use <code>len(s)</code> and <code>cap(s)</code>.</p> <p>You can extend the length of a slice if it has enough capacity. Let's say <code>s</code> is a slice of length 1. <code>s = s[:4]</code> would extend the length to 4 (assuming the array is at least 4).</p> <p>The zero value of a slice is <code>nil</code>. The length and cap is <code>0</code> and has no underlying array.</p> <p>You can create slices using the built in <code>make</code> function. It makes a zeroed array with the given length (and optionally, capacity).</p> <pre><code>a := make([]int, 5)  // len(a)=5\nb := make([]int, 0, 5) // len(b)=0, cap(b)=5\n</code></pre> <p>Slices can container any type, including slices.</p> <p>You can append to a slice using the built in <code>append</code> function.</p> <pre><code>func append(s []T, vs ...T) []T\n</code></pre> <p>If the backing array is too small, a new one will be created and the slice will point to the new array.</p> <p>Does this modify the array? Probably??</p>"},{"location":"notes/golang/intro/#range","title":"Range","text":"<p>The <code>range</code> form of a <code>for</code> loop is used to iterate through a slice or a map. The iterator returns two values, the index and a copy of the value at the index.</p> <pre><code>var pow = []int{1, 2, 4, 8, 16, 32, 64, 128}\n\nfor i, v := range pow {\nfmt.Printf(\"2**%d = %d\\n\", i, v)\n}\n</code></pre> <p>If you don't need either of the two variables returned by <code>range</code>, replace it with an <code>_</code>. If you only need the index, drop the second variable.</p> <pre><code>for _, v := range pow {...}\nfor i, _ := range pow {...}\nfor i := range pow {...}\n</code></pre>"},{"location":"notes/golang/intro/#map","title":"Map","text":"<p>Map maps keys to values. The zero value of a map is <code>nil</code>. A <code>nil</code> map has no keys, nor any can be added.</p> <p>The <code>make</code> function returns a map of the given type.</p> <pre><code>m = make(map[string]Vertex)\nm[\"Bell Labs\"] = Vertex{\n40.68433, -74.39967,\n}\n</code></pre> <p>Map literals are like struct literals but require keys.</p> <pre><code>var m = map[string]Vertex{\n\"Bell Labs\": Vertex{\n40.68433, -74.39967,\n},\n\"Google\": Vertex{\n37.42202, -122.08408,\n},\n}\n</code></pre> <p>If the top-level type is just a type name, you don't need to specify the name in the literal</p> <pre><code>var m = map[string]Vertex{\n\"Bell Labs\": {40.68433, -74.39967},\n\"Google\":    {37.42202, -122.08408},\n}\n</code></pre> <ul> <li>Set a value: <code>m[key] = elem</code></li> <li>Get a value: <code>elem = m[key]</code></li> <li>Delete a key: <code>delete(m, key)</code></li> <li>Test if a key is present: <code>elem, ok = m[key]</code>. <code>ok</code> is a boolean indicating if it is present. <code>elem</code> will be the zero value if it is not present.</li> </ul>"},{"location":"notes/golang/intro/#function-values","title":"Function Values","text":"<p>Functions are values and can be stored in variables and passed as parameters.</p> <pre><code>func compute(fn func(float64, float64) float64) float64 {\nreturn fn(3, 4)\n}\n</code></pre> <p>Functions may also be closures, as in referencing variables outside its body.</p> <pre><code>func adder() func(int) int {\nsum := 0\nreturn func(x int) int {\nsum += x\nreturn sum\n}\n}\n</code></pre>"},{"location":"notes/java/concurrency/","title":"Concurrency","text":"<p>parallel streams vs executor service</p> <p>ForkJoinPool</p> <p>CompletableFuture</p>"},{"location":"notes/java/iterable/","title":"Iterable, Iterator","text":"Iterable Something that can generate an iterator Iterator Something that be iterated. <p>The Spliterator API was designed to support efficient parallel traversal in addition to sequential traversal, by supporting decomposition as well as single-element iteration. In addition, the protocol for accessing elements via a Spliterator is designed to impose smaller per-element overhead than Iterator, and to avoid the inherent race involved in having separate methods for hasNext() and next().</p> <p>For mutable sources, arbitrary and non-deterministic behavior may occur if the source is structurally interfered with (elements added, replaced, or removed) between the time that the Spliterator binds to its data source and the end of traversal. For example, such interference will produce arbitrary, non-deterministic results when using the java.util.stream framework.</p>"},{"location":"notes/kubernetes/1-kubernetes/","title":"Kubernetes","text":"<p>Kubernetes is open source container management platform.</p> <p>It</p> <ul> <li>help you run containers at scale</li> <li>provide objects and APIs for building applications</li> </ul>"},{"location":"notes/kubernetes/1-kubernetes/#nodes","title":"Nodes","text":"<p>Nodes are the machines that make up a Kubernetes cluster. These can be physical or virtual.</p> <p>Two types of nodes:</p> <ol> <li>Control-plane (which makes up the Control Plane) is the brains of the cluster</li> <li>Worker-node (which makes up the Data Plane) runs the actual container images (via pods)</li> </ol>"},{"location":"notes/kubernetes/1-kubernetes/#objects","title":"Objects","text":"<p>Kubernetes objects are entities that are used to represent the state of the cluster.</p> <p>The cluster does its best to ensure it exists as defined (by the object). This is the cluster's desired state. The object is a record intent.</p> <p>Kubernetes is always working to make an object's current state equal to the object's desired state.</p> <p>The desired state could describe:</p> <ul> <li>What pods (containers) are running, and on which nodes</li> <li>IP endpoints that map to a logical group of containers</li> <li>How many replicas of a container are running</li> <li>Other stuff</li> </ul> <p>A Pod is a thin wrapper around one or more containers</p> <p>A DaemonSet implements a single instance of a pod on a worker node</p> <p>A Deployment details how to roll out (or roll back) across versions of your application</p> <p>A ReplicaSet ensures a defined number of pods are always running</p> <p>A Job ensures a pod properly runs to completion</p> <p>A Service maps a fixed IP address to a logical group of pods</p> <p>A Label key/value pairs used for association and filtering</p>"},{"location":"notes/kubernetes/1-kubernetes/#architecture","title":"Architecture","text":""},{"location":"notes/kubernetes/1-kubernetes/#control-plane","title":"Control Plane","text":"<ul> <li>One or More API Servers: Entry point for REST / kubectl</li> <li>etcd: Distributed key/value store</li> <li>Controller-manager: Always evaluating current vs desired state</li> <li>Scheduler: Schedules pods to worker nodes</li> </ul>"},{"location":"notes/kubernetes/1-kubernetes/#data-plane","title":"Data Plane","text":"<ul> <li>Made up of worker nodes</li> <li>kubelet: Acts as a conduit between the API server and the node</li> <li>kube-proxy: Manages IP translation and routing</li> </ul>"},{"location":"notes/kubernetes/1-kubernetes/#helm","title":"Helm","text":"<p>Helm is a package manager for kubernetes. It packages multiple kubernetes resources into a single logical deployment unit called a Chart.</p>"},{"location":"notes/kubernetes/1-kubernetes/#health-checks","title":"Health Checks","text":"<p>https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/</p> <p>Liveliness probes are used in K8s to know when a prod is alive or dead. K8s will kill and recreate the pod when a liveliness probe doesn't pass</p> <p>Readiness probes are used in K8s to know when a pod is ready to serve traffic. If a readiness probe fails, traffic will not be sent to the pod.</p>"},{"location":"notes/kubernetes/1-kubernetes/#auto-scaling","title":"Auto Scaling","text":"<p>Two forms of auto scaling:</p> <ol> <li>Horizontal Pod Autoscaler (HPA) - scales the pods in a deployment or replica set. It is implemented as a K8s API resource and a controller. </li> <li>The controller manager queries the resource utilization against the metrics specified in each HorizontalPodAutoscaler definition.</li> <li>It obtains the metrics from either the resource metrics API (for per-pod resource metrics), or the custom metrics API (for all other metrics).</li> <li>Cluster Autoscaler (CA) - component that automatically adjusts the size of a Kubernetes Cluster so that all pods have a place to run and there are no unneeded nodes.</li> </ol>"},{"location":"notes/kubernetes/1-kubernetes/#role-based-access-control-rbac","title":"Role-based Access Control (RBAC)","text":"<p>RBAC is a method of regulating access to computer or network resources based on the roles of individual users within an enterprise.</p> <p>The logical components:</p> <ul> <li>Entity - A group/user/service account. The identity representating the application that wants to execute certain operations (actions) and requires permission to do so.</li> <li>Resource - A pod/service/secret that the entity wants to access using the certain operations.</li> <li>Role - Used to define therules for the actions the entity can take on various resources.</li> <li>Role binding - Attaches a role to an entity. This dictates the set of actions permitted by the entity on the specified resources. Two types roles/role bindings:<ol> <li>Role/RoleBinding - authorization in a namespace</li> <li>ClusterRole/ClusterRoleBinding- authorization cluster-wide</li> </ol> </li> <li>Namespace - They provide a unique scope for object names. They are intended to be used in multi-tenant environments to create virutal kubernetes clusters on the same physical cluster.</li> </ul>"},{"location":"notes/kubernetes/1-kubernetes/#amazon-ec2-security-groups-kubernetes-pods","title":"Amazon EC2 Security Groups + Kubernetes pods","text":"<p>We can use Security Groups to define inbound and outbound network traffic to and from pods.</p>"},{"location":"notes/kubernetes/1-kubernetes/#kubernetes-service","title":"Kubernetes Service","text":"<p>Let's say we have nginx running cluster wide. We can talk to these pods directly theoretically, but what happens if a node dies? The pods die, but the deployment will create new ones, with different IPs. How do we get this new IP?</p> <p>This is where kubernetes service comes in.</p> <p>A Kubernetes service is an abstraction that defines logical set of pods running somewhere in your cluster.</p> <p>When created, each Service is assined a unique IP address (aka clusterIP). This address is tied to the lifespan of the Service and will not change while the Service is alive.</p> <p>Pods can be configured to talk to the Service, and that communication will be load-balanced automatically to some pods that are members of the Service.</p>"},{"location":"notes/kubernetes/1-kubernetes/#accessing-the-service","title":"Accessing the Service","text":"<p>Two ways we can find a Service:</p> <ol> <li>environment variables</li> <li>DNS</li> </ol>"},{"location":"notes/kubernetes/1-kubernetes/#environment-variables","title":"Environment Variables","text":"<p>When a pod runs on a node, <code>kubelet</code> adds a set of environment variables for each active Service.</p> <p>What happens if we were to run a pod first and then make it a Service? Environment variables won't be there</p> <p>You'd have to kill the pods and wait for the Deployment to recreate them. At this point, the Service will already have existed and the env variables will be set.</p>"},{"location":"notes/kubernetes/1-kubernetes/#dns","title":"DNS","text":"<p>Kubernetes offers a DNS cluster add-on Service that automatically assigns DNS names to other Services.</p>"},{"location":"notes/kubernetes/1-kubernetes/#exposing-the-service","title":"Exposing the Service","text":"<p>There may be a need to expose a Service onto an external IP address. Kubernetes support this in two ways: <code>NodePort</code> and <code>LoadBalancer</code>.</p>"},{"location":"notes/kubernetes/1-kubernetes/#ingress","title":"Ingress","text":"<p>Ingress exposes HTTP and HTTPS routes from outside the cluster to Services within the cluster.</p> <p>The routing itself is controlled by rules defined on the Ingress resource.</p> <p>Ingress doesn't expose arbitrary ports or protocols. If you want to expose services other than HTTP or HTTPS, use <code>NodePort</code> or <code>LoadBalancer</code>.</p> <p>Ingress Controller is responsible for fulfilling the Ingress, commonly with a load balancer. It may configure your edge router or additional frontends to help handle the traffic.</p> <p>You need an ingress controller to satisfy an ingress. Just having an ingress doesn't do anything.</p>"},{"location":"notes/kubernetes/1-kubernetes/#assigning-pods-to-nodes","title":"Assigning Pods to Nodes","text":"<p>We can configure a pod to only run on specific nodes, or prefer certain nodes.</p> <p>This usually isn't necessary, the scheduler will do a reasonable job of this. There may be specific cases where you want to put a pod in a node with an SSD, or two pods together.</p>"},{"location":"notes/kubernetes/1-kubernetes/#method-1-nodeselector","title":"Method 1 - NodeSelector","text":"<p><code>nodeSelector</code> is a field of PodSpec in the form of a map of key-value pairs.</p> <p>For a pod to be eligible to run on the node, the node must have each of the specified key-value pairs as labels.</p>"},{"location":"notes/kubernetes/1-kubernetes/#method-2-affinity-and-anti-affinity","title":"Method 2 - Affinity and Anti-affinity","text":"<p>The <code>nodeSelector</code> is a very basic way of adding constraints to pods. The affinity/anti-affinity feature extends the types of constraints you can express.</p> <p>Key enhancements:</p> <ul> <li>More expressive language (not a simple AND)</li> <li>You can indicate a rule is a preference rather than a requirement. (If it doesn't meet the rule, the pod will still be scheduled.)</li> <li>You can constrain against labels on other pods running on the nodes (rather than labels on the pod)</li> </ul>"},{"location":"notes/kubernetes/1-kubernetes/#node-affinity","title":"Node Affinity","text":"<p>Two types of node affinity:</p> <ol> <li><code>requiredDuringSchedulingIgnoredDuringExecution</code></li> <li><code>preferredDuringSchedulingIgnoredDuringExecution</code></li> </ol> <p>These are basically hard and soft requirements, respectively.</p> <p>The \"IgnoredDuringExecution\" basically means if a pod's labels change at runtime so that it doesn't meet the rule, it'll still run on the node.</p>"},{"location":"notes/kubernetes/1-kubernetes/#stateful-containers-using-statefulset","title":"Stateful Containers Using StatefulSet","text":"<p>StatefulSet manages the deployment and scaling of a set of Pods.</p> <p>It provides guarantees about the ordering and uniqueness of these Pods. (Not sure what ordering here is, or what it means by unique).</p> <p>This is good for applications that require:</p> <ul> <li>Stable, unique network identifiers</li> <li>Stable, persistent storage</li> <li>Ordered, graceful deployment and scaling</li> <li>Ordered, automated rolling updates</li> </ul>"},{"location":"notes/kubernetes/1-kubernetes/#container-storage-interface-csi","title":"Container Storage Interface (CSI)","text":"<p>(This isn't related directly to stateful containers, but it is relevant when working with storage for the statefule container example).</p> <p>The Container Storage Interface is a standard for exposing arbitrary block and file storage systems to containerized workloads on Container Orchestration Systems (COs) like Kubernetes.</p> <p>Using CSI, 3P storage providers can write and deploy plugins exposing new storage systems in Kubernetes without ever having to touch the core Kubernetes code.</p> <p>Third party for example, Amazon Elastic Block Store (Amazon EBS). Amazon EBS has a CSI driver that provides this interface to allow Amazon EKS to manage the lifecycle of Amazon EBS volumes for persistent volumes.</p>"},{"location":"notes/kubernetes/1-kubernetes/#kubernetes-secrets","title":"Kubernetes Secrets","text":"<p>Kuberbetes can store secrets that pods can access via a mounted volume. K8s store these secrets in a Base64 encoding, but a more secure way is preferred. </p> <p>We can use AWS Key Management Service (KMS) Customer Managed Keys (CMK) to do so.</p>"},{"location":"notes/kubernetes/1-kubernetes/#sealed-secrets","title":"Sealed Secrets","text":"<p>Sealed Secrets provides a mechanism to encrypt a Secret object to that it is sage to store - even to a public repo.</p> <p>It can only be decrypted by the controller running in the K8s cluster.</p> <p>This is composed of two parts:</p> <ol> <li>A cluster-side controller</li> <li>A client-side utility, kubeseal</li> </ol> <p>The steps:</p> <ol> <li>On Start Up<ol> <li>The controller looks for a cluster-wide private/public key pair. If not found, it'll generate a new 4096 bit RSA key pair.</li> <li>The private key is persisted in a Secret object in the controller's namespace.</li> <li>The public key  is made publicly available</li> </ol> </li> <li>During encrpytion<ol> <li>Each value in the original Secret is symmetrically encrypted using AES-256 with a randomly generated session key.</li> <li>The session key is asymmetrically encryped with the controller's public key using SHA256 and the original Secret's namespace/name as the input parameter.<ol> <li>The output string is: length (2 bytes) of encrypted session key + encrypted session key + encrypted Secret</li> </ol> </li> </ol> </li> <li>During deployment of SealedSecret<ol> <li>The controller picks up the secret</li> <li>Unseals it using the private key</li> <li>Creates a Secrete resource.</li> </ol> </li> <li>During decryption<ol> <li>The SealedSecret's name/namepace is used as the input parameter.</li> </ol> </li> </ol> <p>kubeseal is used for creating a SealedSecret custom resource definition (CRD) from a Secret resource definition using the public key.</p>"},{"location":"notes/kubernetes/1-kubernetes/#users","title":"Users","text":"<p>Two types of users:</p> <ol> <li>Normal users (not managed by Kubernetes)</li> <li>Service Accounts (managed by Kubernetes)</li> </ol> <p>From Doc: Kubernetes does not have objects which represent normal user accounts. Normal users cannot be added to a cluster through an API call.</p>"},{"location":"notes/kubernetes/2-components/","title":"Components","text":"Cluster The collection of Kubernetes components. Nodes A worker machine in a cluster that runs containerized applications. Pods A component of the application workload. Control Plane Manages the worker nodes and the Pods in the cluster. <p>When you run Kubernetes you get a cluster.</p> <ul> <li>There is at least one node in a cluster.</li> <li>Nodes host the Pods</li> </ul> <p>Diagram of the cluster:</p> <p></p>"},{"location":"notes/kubernetes/2-components/#control-plane-components","title":"Control Plane Components","text":"<p>The CP makes global decisions about the cluster and detecting/responding to cluster events. This includes:</p> <ul> <li>Scheduling</li> <li>Starting a new Pod when a deployment's <code>replicas</code> field is unsatisfied.</li> </ul>"},{"location":"notes/kubernetes/2-components/#kube-apiserver","title":"kube-apiserver","text":"<p>The API server exposes Kubernetes API and is the front end for the Kubernetes CP.</p> <p>The main implementation is kube-apiserver, which is designed to scale horizontally.</p>"},{"location":"notes/kubernetes/2-components/#etcd","title":"etcd","text":"<p>A consistent and highly-available key value store. This stores Kubernetes cluster data.</p>"},{"location":"notes/kubernetes/2-components/#kube-scheduler","title":"kube-scheduler","text":"<p>A component that watches for newly created Pods with no assigned node and selects a node for them to run on.</p> <pre><code>// TODO Look into scheduling strategies\n</code></pre>"},{"location":"notes/kubernetes/2-components/#kube-controller-manager","title":"kube-controller-manager","text":"<p>A component that runs controller processes.</p> Control loop Watches the shared state of the cluster through the apiserver. It makes changes to attempt to get the current state to match the desired state. Controller Type Description Node controller Monitor and respond to when nodes go down. Job controller Monitor for Job objects that represent one-off tasks and creates Pods to run those tasks Endpoint controller Populates the Endpoint object (joins Services and Pods) Service Account &amp; Token controllers Create default accounts and API access tokens for new namespaces. <pre><code>// TODO Link various terminology, like Services, Pods, Job, etc.\n</code></pre>"},{"location":"notes/kubernetes/2-components/#cloud-controller-manager","title":"cloud-controller-manager","text":"<p>A component that embeds cloud-specific control logic.</p> <p>This enables you to link your cluster to your cloud provider's API and separate the components that interact with your cloud platform from those that just needs your cluster.</p> <p>This may not be needed if you're running the cluster on your own machine.</p> <p>Some possible controllers:</p> Controller Type Description Node controller Checks the cloud provider to determine if a node has been deleted after it stops responding. Route controller Setting up routes in the cloud infrastructure. Service controller Creating, updating, deleting cloud provider load balancers."},{"location":"notes/kubernetes/2-components/#node-components","title":"Node Components","text":"<p>These are the components that run on every node.</p>"},{"location":"notes/kubernetes/2-components/#kubelet","title":"kubelet","text":"<p>An agent that ensures containers are running in a Pod.</p> <p>It takes in a set of PodSpecs and sees those containers defined in them are running and healthy.</p> <p>It does not manage any containers not created by Kubernetes.</p>"},{"location":"notes/kubernetes/2-components/#kube-proxy","title":"kube-proxy","text":"<p>A network proxy. It maintains network rules on nodes.</p> <p>This allows network communication to your Pods from network sessions inside or outside of your cluster.</p> <p>It implements part of the Kubernetes Service concept.</p> <pre><code>// TODO Services Networking\n</code></pre>"},{"location":"notes/kubernetes/2-components/#container-runtime","title":"Container Runtime","text":"<p>The software responsible for running containers.</p> <ul> <li>Docker</li> <li>containerd</li> <li>CRI-O</li> <li>any implementation of the Kubernetes CRI</li> </ul>"},{"location":"notes/kubernetes/2-components/#addons","title":"Addons","text":"<pre><code>// TODO\n</code></pre>"},{"location":"notes/kubernetes/3-api/","title":"Kubernetes API","text":"<p>This API is a RESTful programmatic interface provided via HTTP.</p>"},{"location":"notes/kubernetes/3-api/#api-terminology","title":"API Terminology","text":"<ul> <li>Resource type - the name used in the URL</li> <li>Kind - the object schema, the representation in JSON</li> <li>Collection - A list of instances of a resource type</li> <li>Resource - A single instance of the resource type</li> </ul> <p>The resource types are scoped by either:</p> <ul> <li>cluster - <code>/apis/GROUP/VERSION/*</code></li> <li>namespace - <code>/apis/GROUP/VERSION/namespaces/NAMESPACE/*</code></li> </ul> <p>Retrieving collections and resources look like:</p> <ul> <li>Cluster-scoped resources</li> <li><code>GET /apis/GROUP/VERSION/RESOURCETYPE</code> - return the collection of resources of the resource type</li> <li><code>GET /apis/GROUP/VERSION/RESOURCETYPE/NAME</code> - return the resource with NAME under the resource type</li> <li>Namespace-scoped resources</li> <li><code>GET /apis/GROUP/VERSION/RESOURCETYPE</code> - return the collection of all instances of the resource type across all namespaces</li> <li><code>GET /apis/GROUP/VERSION/namespaces/NAMESPACE/RESOURCETYPE</code> - return collection of all instances of the resource type in NAMESPACE</li> <li><code>GET /apis/GROUP/VERSION/namespaces/NAMESPACE/RESOURCETYPE/NAME</code> - return the instance of the resource type with NAME in NAMESPACE</li> </ul> <pre><code>TODO HTTP Codes, Error, etc.\n</code></pre>"},{"location":"notes/kubernetes/4-scheduling/","title":"Scheduling, Preemption, Eviction","text":"Scheduling Making sure Pods are matches to Nodes so kubelet can run them. Preemption Terminating Pods with lower priority so higher priority Pods can be scheduled. Eviction Terminating one or more Pods on Nodes."},{"location":"notes/kubernetes/4-scheduling/#kubernetes-scheduler","title":"Kubernetes Scheduler","text":""},{"location":"notes/machine_learning/01-introduction/","title":"Introduction","text":""},{"location":"notes/machine_learning/01-introduction/#what-is-machine-learning","title":"What is Machine Learning?","text":"<p>Field of study that gives computers the ability to learn without being explicitly programmed</p> <p>Learning Problem - A computer program is said to learn from experience E with respect to some task T and some performance P if P improves with E.</p> <p>The 2 most broad classification of machine learning algorithms:</p> <ol> <li>Supervised Learning</li> <li>Unsupervised Learning</li> </ol>"},{"location":"notes/machine_learning/01-introduction/#supervised-learning","title":"Supervised Learning","text":"<p>In this type of learning, we provide the right answers, and the computer will learn to try to give more right answers.</p> <p>Ex - Predict the cost of a house based on the square footage</p> <p>This is a regression problem - predicting continuous valued output (i.e. the price). If we were to perform a supervised learning, we would provide a sample of house prices and its square footage.\\</p> <p>Ex - See if breast cancer is malignant based on the tumor size</p> <p>This is a classification problem - we are trying to determine a discrete valued output (e.g yes or no, 1 or 2 or 3, etc). We are trying to see if the person has a malignant tumor or not.</p>"},{"location":"notes/machine_learning/01-introduction/#unsupervised-learning","title":"Unsupervised Learning","text":"<p>In this type of learning, we provide data without the answers. In supervised learning, we may provide yes and no, or some sort of answers, but in this, the data we provide is unlabelled.</p> <p>\"Here is some data, can you find some structure in the data?\"</p> <p>This learning may recognize, for example, that our data has two main clusters. This is a clustering algorithm.</p> <p>Ex - Google News Stories</p> <p>Google news will cluster together various articles about the same topic. It may find a CNN article MSNBC video, Fox News article all about global warming bill passing in congress.</p>"},{"location":"notes/machine_learning/01-introduction/#another-classification-cocktail-party-algorithm","title":"Another classification - Cocktail Party Algorithm","text":"<p>Two speakers at the party, and two microphones. Both microphones pick up both speakers, but each microphone is closer to one of the speakers.</p> <p>The algorithm will listen to both mics and separate out the two audio sources.</p>"},{"location":"notes/machine_learning/02-model-and-cost-function/","title":"Model and Cost Function","text":""},{"location":"notes/machine_learning/02-model-and-cost-function/#model-representation","title":"Model Representation","text":"<p>In supervised learning, we have a dataset - called training dataset.</p> <p>We feed our training set to a learning algorithm which will then output a function - called <code>h</code> , our hypothesis function. <code>h</code> then can take in <code>x</code> and output <code>y</code>.</p> <p>Some Notation</p> \\[ \\begin{align*} x^{(i)} &amp;&amp;&amp; \\text{Input variable/feature where }i\\text{ is the index} \\\\ y^{(i)} &amp;&amp;&amp; \\text{Ouput/Target variable/feature }i\\text{ is the index} \\\\ (x^{(i)}, y^{(i)}) &amp;&amp;&amp; \\text{Training example}\\\\ (x^{(i)}, y^{(i)}); i = 1, \\ldots,m &amp;&amp;&amp; \\text{Training set}\\\\ X &amp;&amp;&amp; \\text{Space of input values}\\\\ Y &amp;&amp;&amp; \\text{Space of output values}\\\\ \\end{align*} \\] <p>For supervised learning, our goal is to learn a function \\(h:X \\rightarrow Y\\) so that \\(h(x)\\) is a good predictor for the corresponding value of \\(y\\). <code>h</code> is the hypothesis.</p> <p>How do we represent <code>h</code>?</p> \\[ \\begin{align*} h_\\theta(x) &amp;= \\theta_0 + \\theta_1x\\\\ h(x) &amp;&amp; \\text{Shorthand}\\\\ \\end{align*} \\] <p>The above is a linear regression with one variable or univariate linear regression.</p>"},{"location":"notes/machine_learning/02-model-and-cost-function/#cost-function","title":"Cost Function","text":"<p>Let's say we have a training set and a hypothesis of \\(h_\\theta(x) = \\theta_0+\\theta_1x\\). The \\(\\theta_i\\)'s are parameters. With various values of \\(\\theta_i\\)'s, we will get various hypothesis.</p> <p>Reminder - this is a regression problem. We cannot do this classification problems.</p> \\[ \\begin{align*} \\theta_0&amp;=1.5 &amp; \\theta_1&amp;=0\\\\ \\theta_0&amp;=0 &amp; \\theta_1&amp;=0.5\\\\ \\theta_0&amp;=1 &amp; \\theta_1&amp;=0.5\\\\ \\end{align*} \\] <p>We want to come up with the values for these parameters so that \\(h_\\theta(x)\\) is as close to \\(y\\) for our training examples \\((x,y)\\). This is a minimization problem. We want to find \\(\\theta_0\\) and \\theta_1$ to minimize:</p> \\[ \\frac{1}{2m}\\sum^m_{i=1}(h_\\theta(x^{(i)}) - y^{(i)})^2\\\\ \\] <p>By convention, we redefine our problem to minimize a cost function:</p> \\[ J(\\theta_0,\\theta_1) = \\frac{1}{2m}\\sum^m_{i=1}(h_\\theta(x^{(i)}) - y^{(i)})^2\\\\ \\min_{\\theta_0\\theta_1} J(\\theta_0,\\theta_1)\\\\ \\] <p>To break this down:</p> \\[ \\begin{align*} J(\\theta_0,\\theta_1) &amp;= \\frac{1}{2m}\\sum^m_{i=1}(h_\\theta(x^{(i)}) - y^{(i)})^2\\\\ &amp;= \\frac{1}{2}\\frac{1}{m}\\sum^m_{i=1}(h_\\theta(x^{(i)}) - y^{(i)})^2\\\\ &amp;= \\frac{1}{2}\\frac{1}{m}\\sum^m_{i=1}(\\text{difference between predicted and actual})^2\\\\ &amp;= \\frac{1}{2}\\frac{1}{m}\\sum^m_{i=1}(\\text{error})^2\\\\ &amp;= \\frac{1}{2}\\frac{1}{m}(\\text{sum of error squared})\\\\ &amp;= \\frac{1}{2}(\\text{mean of error squared})\\\\ &amp;= \\frac{1}{2}\\bar{x} &amp; \\bar{x}\\text{ is the mean of the squares of errors}\\\\ \\end{align*} \\] <p>This cost function is called the squared error function or mean squared error. The \\(\\frac{1}{2}\\) is there to simplify the calculus. The squared and one half cancels out. It probably the most commonly used cost function. It should be a pretty reasonable thing to try for linear regression.</p> <p>To summarize:</p> \\[ \\begin{align*} \\text{Hypothesis} &amp;&amp;&amp; h_\\theta(x)=\\theta_0+\\theta_1x\\\\ \\text{Parameteres} &amp;&amp;&amp; \\theta_0,\\theta_1\\\\ \\text{Cost Function} &amp;&amp;&amp; J(\\theta_0,\\theta_1) = \\frac{1}{2m}\\sum^m_{i=1}(h_\\theta(x^{(i)}) - y^{(i)})^2\\\\ \\text{Goal} &amp;&amp;&amp; \\min_{\\theta_0,\\theta_1} J(\\theta_0,\\theta_1) \\end{align*} \\] <p>Let's take a closer look at the cost function \\(J(\\theta_0,\\theta_1)\\) and the hypothesis function \\(h_\\theta(x)\\).</p> <ul> <li>\\(h_\\theta(x)\\) - For fixed \\(\\theta_0,\\theta_1\\), this is a function of \\(x\\).</li> <li>\\(J(\\theta_0,\\theta_1)\\) - function of the parameters \\(\\theta_0,\\theta_1\\).</li> </ul> <p>We want to minimize the cost function. It is important to note that this is a linear regression so \\(h_\\theta(x)\\) and \\(J(\\theta_0,\\theta_1)\\) are continuous functions.</p>"},{"location":"notes/machine_learning/03-parameter-learning/","title":"03 parameter learning","text":"<ul> <li>Parameter Learning<ul> <li>Gradient Descent</li> <li>Gradient Descent For Linear Regression</li> </ul> </li> </ul>"},{"location":"notes/machine_learning/03-parameter-learning/#parameter-learning","title":"Parameter Learning","text":""},{"location":"notes/machine_learning/03-parameter-learning/#gradient-descent","title":"Gradient Descent","text":"<p>Gradient descent can be used to find the minimum of functions, including our cost function.</p> <p>General plan</p> <ol> <li>Start with some \\(\\theta_0,\\theta_1\\)</li> <li>Keep changing \\(\\theta_0,\\theta_1\\) to reduce \\(J(\\theta_0,\\theta_1)\\) until we hopefully end up at a minimum</li> </ol> <p>It will not necessary find the lowest value, it can lead to a local minimum.</p> <p>Generally, repeat the following until convergence: $$ \\theta_j := \\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta_0,\\theta_1)\\text{ (for j = 0 and j = 1)} $$ \\(:=\\) is assignment. \\(=\\) is declaring the two are the same.</p> <p>To be strictly correct, we want to update all \\(\\theta_j\\) simultaneously. If we executed the above twice, for <code>j=0</code> and <code>j=1</code>, the computations of \\(\\theta_1\\) will be using the new value of \\(\\theta_0\\). So technically, this is how we would perform gradient descent: $$ \\begin{align} temp0 &amp;:= \\theta_0-\\alpha\\frac{\\partial}{\\partial\\theta_0}J(\\theta_0,\\theta_1)\\ temp1 &amp;:= \\theta_1-\\alpha\\frac{\\partial}{\\partial\\theta_1}J(\\theta_0,\\theta_1)\\ \\theta_0 &amp;:= temp0\\ \\theta_1 &amp;:= temp1\\ \\end{align} $$ Intuitively, let's break down the update: $$ \\begin{align} \\theta_j &amp;&amp;&amp; \\text{The parameter being updated}\\ \\frac{\\partial}{\\partial\\theta_j}J(\\theta_0,\\theta_1) &amp;&amp;&amp; \\text{The slope of the cost function. The rate at which the cost function increases as we increase }\\theta_j\\ -\\alpha &amp;&amp;&amp; \\text{The negative moves in the opposite direction of the slope. }\\alpha\\text{ dictates the size of the step }\\theta_j\\text{ will change.}\\ \\end{align} $$</p> <ul> <li>If \\(\\alpha\\) is too large, the function may fail to converge. It may take a huge step and pass the minimum. It can diverge, or just go back and forth two places.</li> <li>If \\(\\alpha\\) is too small, the gradient descent can be slow.</li> </ul> <p>As we approach a local minimum, gradient descent will automatically take smaller steps. Why? The derivative gets smaller and smaller as we get closer and closer. This means the total change in \\(\\theta_j\\) gets smaller as well.</p>"},{"location":"notes/machine_learning/03-parameter-learning/#gradient-descent-for-linear-regression","title":"Gradient Descent For Linear Regression","text":"<p>Let's apply gradient descent to our cost function for linear regression. $$ \\begin{align} \\frac{\\partial}{\\partial\\theta_j}J(\\theta_0,\\theta_1) &amp;= \\frac{\\partial}{\\partial\\theta_j}\\frac{1}{2m}\\sum^m_{i=1}(h_\\theta(x^{(i)}) - y^{(i)})^2\\  &amp;= \\frac{\\partial}{\\partial\\theta_j}\\frac{1}{2m}\\sum^m_{i=1}(\\theta_0+\\theta_1x^{(i)} - y^{(i)})^2\\ \\end{align} $$ We need to evaluate this partial derivative for \\(j=0\\) and \\(j=1\\): $$ \\begin{align} \\frac{\\partial}{\\partial\\theta_0}J(\\theta_0,\\theta_1) &amp;= \\frac{\\partial}{\\partial\\theta_0}\\frac{1}{2m}\\sum^m_{i=1}(h_\\theta(x^{(i)}) - y^{(i)})^2\\ &amp;= \\frac{1}{2m}\\sum^m_{i=1}\\left(\\frac{\\partial}{\\partial\\theta_0}(h_\\theta(x^{(i)}) - y^{(i)})^2\\right)\\ &amp;= \\frac{1}{2m}\\sum^m_{i=1}\\left(2\\times(h_\\theta(x^{(i)}) - y^{(i)})\\times\\frac{\\partial}{\\partial\\theta_0}\\left(h_\\theta(x^{(i)}) - y^{(i)}\\right)\\right)\\ &amp;= \\frac{1}{m}\\sum^m_{i=1}\\left((h_\\theta(x^{(i)}) - y^{(i)})\\times\\left(\\frac{\\partial}{\\partial\\theta_0}h_\\theta(x^{(i)}) - \\frac{\\partial}{\\partial\\theta_0}y^{(i)}\\right)\\right)\\ &amp;= \\frac{1}{m}\\sum^m_{i=1}\\left((h_\\theta(x^{(i)}) - y^{(i)})\\times\\left(\\frac{\\partial}{\\partial\\theta_0}h_\\theta(x^{(i)}) - 0\\right)\\right)\\ &amp;= \\frac{1}{m}\\sum^m_{i=1}\\left((h_\\theta(x^{(i)}) - y^{(i)})\\times\\frac{\\partial}{\\partial\\theta_0}h_\\theta(x^{(i)})\\right)\\ &amp;= \\frac{1}{m}\\sum^m_{i=1}\\left((h_\\theta(x^{(i)}) - y^{(i)})\\times\\frac{\\partial}{\\partial\\theta_0}(\\theta_0+\\theta_1x^{(i)})\\right)\\ &amp;= \\frac{1}{m}\\sum^m_{i=1}\\left((h_\\theta(x^{(i)}) - y^{(i)})\\times1\\right)\\ &amp;= \\frac{1}{m}\\sum^m_{i=1}\\left(h_\\theta(x^{(i)}) - y^{(i)}\\right)\\ \\end{align} $$</p> \\[ \\begin{align*} \\frac{\\partial}{\\partial\\theta_1}J(\\theta_0,\\theta_1) &amp;= \\frac{\\partial}{\\partial\\theta_1}\\frac{1}{2m}\\sum^m_{i=1}(h_\\theta(x^{(i)}) - y^{(i)})^2\\\\ &amp;= \\frac{1}{2m}\\sum^m_{i=1}\\left(\\frac{\\partial}{\\partial\\theta_1}(h_\\theta(x^{(i)}) - y^{(i)})^2\\right)\\\\ &amp;= \\frac{1}{2m}\\sum^m_{i=1}\\left(2\\times(h_\\theta(x^{(i)}) - y^{(i)})\\times\\frac{\\partial}{\\partial\\theta_1}\\left(h_\\theta(x^{(i)}) - y^{(i)}\\right)\\right)\\\\ &amp;= \\frac{1}{m}\\sum^m_{i=1}\\left((h_\\theta(x^{(i)}) - y^{(i)})\\times\\left(\\frac{\\partial}{\\partial\\theta_1}h_\\theta(x^{(i)}) - \\frac{\\partial}{\\partial\\theta_1}y^{(i)}\\right)\\right)\\\\ &amp;= \\frac{1}{m}\\sum^m_{i=1}\\left((h_\\theta(x^{(i)}) - y^{(i)})\\times\\left(\\frac{\\partial}{\\partial\\theta_1}h_\\theta(x^{(i)}) - 0\\right)\\right)\\\\ &amp;= \\frac{1}{m}\\sum^m_{i=1}\\left((h_\\theta(x^{(i)}) - y^{(i)})\\times\\frac{\\partial}{\\partial\\theta_1}h_\\theta(x^{(i)})\\right)\\\\ &amp;= \\frac{1}{m}\\sum^m_{i=1}\\left((h_\\theta(x^{(i)}) - y^{(i)})\\times\\frac{\\partial}{\\partial\\theta_1}(\\theta_0+\\theta_1x^{(i)})\\right)\\\\ &amp;= \\frac{1}{m}\\sum^m_{i=1}\\left((h_\\theta(x^{(i)}) - y^{(i)})\\times(0+x^{(i)})\\right)\\\\ &amp;= \\frac{1}{m}\\sum^m_{i=1}\\left((h_\\theta(x^{(i)}) - y^{(i)})\\times x^{(i)}\\right)\\\\ \\end{align*} \\] <p>With these derivatives figured out we can replace it in our gradient descent update: $$ \\begin{align} \\theta_0 &amp;:= \\theta_0-\\alpha\\frac{1}{m}\\sum^m_{i=1}\\left(h_\\theta(x^{(i)}) - y^{(i)}\\right)\\ \\theta_1 &amp;:= \\theta_1-\\alpha\\frac{1}{m}\\sum^m_{i=1}\\left((h_\\theta(x^{(i)}) - y^{(i)})\\times x^{(i)}\\right)\\ \\end{align} $$ \"Batch\" Gradient Descent - \"batch\" refers to gradient descent using all the training examples. Some other gradient descents may not look at the entire training set.</p> <p>There is another solution that doesn't need the repetitive approach of gradient descent and rather calculates the minimum straight out, it is called normal equations method. Gradient descent scales better with large data sets.</p>"},{"location":"notes/machine_learning/04-multivariate-linear-regression/","title":"04 multivariate linear regression","text":"<ul> <li>4 Multivariate Linear Regression<ul> <li>Multiple Features</li> <li>Gradient Descent for Multiple Variables</li> <li>Gradient Descent in Practice<ul> <li>Feature Scaling</li> <li>Mean Normalization</li> <li>Learning Rate</li> </ul> </li> <li>Features and Polynomial Regression</li> </ul> </li> </ul>"},{"location":"notes/machine_learning/04-multivariate-linear-regression/#4-multivariate-linear-regression","title":"4 Multivariate Linear Regression","text":""},{"location":"notes/machine_learning/04-multivariate-linear-regression/#multiple-features","title":"Multiple Features","text":"<p>In original linear regression example our hypothesis was in the form of \\(h_\\theta(x) = \\theta_0+\\theta_1x\\). There was a single variable - \\(x\\). What if we had multiple variables (or features)? $$ \\begin{align} m &amp;= \\text{number of examples}\\ n &amp;= \\text{number of features}\\ x^{(i)} &amp;= \\text{input (features) of }i^{th}\\text{ training example}\\ x^{(i)}_j &amp;= \\text{value of feature }j\\text{ in }i^{th}\\text{ training example}\\ \\end{align} $$ Example - Predicting price of a house</p> size # of bedrooms # of floors age price 2104 5 1 45 460 1416 3 2 40 232 1534 3 2 30 315 852 2 1 36 178 ... ... ... ... ... \\[ \\begin{align*} m &amp;= 47\\\\ n &amp;= 4\\\\ x^{(2)} &amp;= \\begin{bmatrix} 1416\\\\ 3\\\\ 2\\\\ 40\\\\ \\end{bmatrix}\\\\ x^{(2)}_3 &amp;= 2 \\end{align*} \\] <p>What would our new hypothesis look like? We can't use a single \\(x\\). It need to be $$ h_\\theta(x)=\\theta_0+\\theta_1x_1+\\theta_2x_2+\\theta_3x_3+\\theta_4x_4 $$ In general, our hypothesis is now in the form $$ h_\\theta(x)=\\theta_0+\\theta_1x_1+\\theta_2x_2+\\dots+\\theta_nx_n $$ To make notation a bit easier, let's have \\(x_0=1\\) (or \\(x_0^{(i)}=1\\)): $$ x = \\begin{bmatrix} x_0\\ x_1\\ x_2\\ \\vdots\\ x_n \\end{bmatrix} \\in\\R^{n+1}\\qquad \\theta = \\begin{bmatrix} \\theta_0\\ \\theta_1\\ \\theta_2\\ \\vdots\\ \\theta_n \\end{bmatrix} \\in\\R^{n+1}\\ $$</p> \\[ \\begin{align*} h_\\theta(x)&amp;=\\theta_0x_0+\\theta_1x_1+\\theta_2x_2+\\dots+\\theta_nx_n\\\\ &amp;=\\begin{bmatrix} \\theta_0 \\theta_1\\dots\\theta_n \\end{bmatrix}\\begin{bmatrix} x_0\\\\ x_1\\\\ \\vdots\\\\ x_n\\\\ \\end{bmatrix}\\\\ &amp;=\\theta^\\intercal x \\end{align*} \\] <p>This is multivariate linear regression.</p>"},{"location":"notes/machine_learning/04-multivariate-linear-regression/#gradient-descent-for-multiple-variables","title":"Gradient Descent for Multiple Variables","text":"<p>Let's review the notation: $$ \\begin{align} \\text{Hypothesis} &amp;&amp; h_\\theta(x)=\\theta^\\intercal x=\\theta_0x_0+\\theta_1x+\\dots+\\theta_nx_n\\ \\text{Parameteres} &amp;&amp; \\theta_0,\\theta_1,\\ldots,\\theta_n = \\theta \\in \\R^{n+1}\\ \\text{Cost Function} &amp;&amp; J(\\theta_0,\\theta_1,\\ldots,\\theta_n) = J(\\theta) = \\frac{1}{2m}\\sum^m_{i=1}(h_\\theta(x^{(i)}) - y^{(i)})^2\\ \\text{Goal} &amp;&amp; \\min_{\\theta} J(\\theta)\\end{align} $$ Gradient descent would then be repeating the following $$ \\theta_j := \\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)\\text{ (simultaneously for }j = 0\\ldots n\\text{)} $$ Previously for \\(n=1\\): $$ \\begin{align} \\theta_0 &amp;:= \\theta_0-\\alpha\\frac{1}{m}\\sum^m_{i=1}\\left(h_\\theta(x^{(i)}) - y^{(i)}\\right)\\ \\theta_1 &amp;:= \\theta_1-\\alpha\\frac{1}{m}\\sum^m_{i=1}\\left((h_\\theta(x^{(i)}) - y^{(i)})\\times x^{(i)}\\right)\\ \\end{align} $$ Now for \\(n\\geq1\\): $$ \\theta_j := \\theta_j-\\alpha\\frac{1}{m}\\sum^m_{i=1}\\left((h_\\theta(x^{(i)}) - y^{(i)})\\times x^{(i)}_j\\right)\\ $$ Since we have \\(x_0^{(i)}=1\\),  the above statement is true for all values of \\(j := 0\\ldots n\\) (again, this is for linear regression)</p>"},{"location":"notes/machine_learning/04-multivariate-linear-regression/#gradient-descent-in-practice","title":"Gradient Descent in Practice","text":""},{"location":"notes/machine_learning/04-multivariate-linear-regression/#feature-scaling","title":"Feature Scaling","text":"<p>Idea - Make sure features are on a similar scale</p> <p>Example - house pricing</p> <ul> <li>\\(x_1=\\) size (0-2000)</li> <li>\\(x_2=\\) number of bedrooms (1-5)</li> </ul> <p>Because the range of one is much higher, the contour gets really stretched in a direction. (And gradient descent would reach the optimal for one feature way before the other.) This may result in one feature oscillating while gradient descent is working on the other feature.</p> <p>Instead if you feature scale - or divide by the range:</p> <ul> <li>\\(x_1=\\) size/2000</li> <li>\\(x_2=\\) number of bedrooms/5</li> </ul> <p>you'll have both features between 0 and 1.</p> <p>Get every feature into approximately a \\(-1 \\leq x_i \\leq 1\\) range.</p> <p>It doesn't have to be exactly 1 - it could be plus minus 3 or something. As long as it is not plus minus 100, or plus minus 0.000001</p>"},{"location":"notes/machine_learning/04-multivariate-linear-regression/#mean-normalization","title":"Mean Normalization","text":"<p>Another tactic is to perform mean normalization, replacing \\(x_j\\) with \\(x_j - \\mu_j\\) to make features have approximately zero mean (except for \\(x_0=1\\)): $$ \\begin{align} x_1 &amp;= \\frac{size-1000}{2000}\\ x_2 &amp;= \\frac{# bedrooms-2}{5}\\ \\vdots\\ x_j &amp;= \\frac{x_j-\\mu_j}{s_j}\\ \\end{align} $$ \\(\\mu_j\\) is the average of all the values for feature j and \\(s_i\\) is the range of values or \\(s_i\\) is the standard deviation.</p>"},{"location":"notes/machine_learning/04-multivariate-linear-regression/#learning-rate","title":"Learning Rate","text":"<p>How to choose \\(\\alpha\\)?</p> <p>Before we answer this, how do we know gradient descent is working? Track \\(J(\\theta)\\) in relation to the number of iterations.</p> <ul> <li>\\(J(\\theta)\\) should decrease after every iteration.</li> <li>If the graph is looking flat, it most likely converged</li> <li>We can automatically declare convergence if \\(J(\\theta)\\) decreases by less than \\(\\epsilon\\) in one iteration. (e.g. \\(\\epsilon=10^{-3}\\) - the value of this varies)</li> <li>If \\(J(\\theta)\\) is increasing, it mean it is not working, choose a smaller \\(\\alpha\\).</li> <li>If \\(J(\\theta)\\) is oscillating, it mean it is not working, choose a smaller \\(\\alpha\\).</li> <li>Choosing a too small \\(\\alpha\\) make cause convergence to take forever though.</li> </ul>"},{"location":"notes/machine_learning/04-multivariate-linear-regression/#features-and-polynomial-regression","title":"Features and Polynomial Regression","text":"<p>Example - house pricing $$ h_\\theta=\\theta_0 + \\theta_1 \\times frontage + \\theta_2 \\times depth $$ you can create your own feature (e.g. I want to create a feature for area (frontage x depth)): $$ h_\\theta=\\theta_0 + \\theta_1 \\times area $$ Similar we can also not be limited to linear regression, we can do quadratic, or other polynomial regression: $$ h_\\theta=\\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3 $$ This can be redefined to be a linear regression problem: $$ \\begin{align} h_\\theta &amp;= \\theta_0 + \\theta_1 size + \\theta_2 size^2 + \\theta_3 size^3\\ &amp;= \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_3\\ x_1 &amp;= size\\ x_2 &amp;= size^2\\ x_3 &amp;= size^3\\ \\end{align} $$ Each power is a new feature. One feature is the square of the area. Another is the cube of the area.</p> <p>Feature scaling becomes super important here!</p>"},{"location":"notes/machine_learning/05-computing-parameters-analytically/","title":"05 computing parameters analytically","text":"<ul> <li>5 Computing Parameters Analytically<ul> <li>Normal Equation<ul> <li>General Definition</li> <li>Non-Invertibility</li> </ul> </li> </ul> </li> </ul>"},{"location":"notes/machine_learning/05-computing-parameters-analytically/#5-computing-parameters-analytically","title":"5 Computing Parameters Analytically","text":""},{"location":"notes/machine_learning/05-computing-parameters-analytically/#normal-equation","title":"Normal Equation","text":"<p>Gradient descent solved for \\(\\theta\\) iteratively, getting closer and closer. Normal equation will give us a method to solve for \\(\\theta\\) analytically.</p> <p>We do this by taking the derivative and setting it to 0.</p> <p>For \\(\\theta \\in \\R^1\\), this is pretty simple: $$ J(\\theta) = a\\theta^2 + b\\theta + c\\ \\frac{\\partial}{\\partial \\theta} J(\\theta) = \\dots = 0 $$ and then solve for \\(\\theta\\).</p> <p>For our multivariate linear regression \\(\\theta \\in \\R^{n+1}\\): $$ J(\\theta_0, \\theta_1, \\ldots, \\theta_n) = \\frac{1}{2m} \\sum^{m}{i=1}(h\\theta(x^{(i)})-y^{(i)})^2\\ \\frac{\\partial}{\\partial\\theta_j} J(\\theta) = \\dots = 0 \\text{ (for every }j\\text{)} $$ This calculus is rather involved so I am not going to work it out right now, but let's take a look at the end result with an example:</p> \\(x_0\\) Size (feet squared)\\(x_1\\) # of bedrooms\\(x_2\\) # of floors\\(x_3\\) age of home\\(x_4\\) price ($1000) \\(y\\) 1 2104 5 1 45 460 1 1416 3 2 40 232 1 1534 3 2 30 315 1 852 2 1 36 178 <p>Take the features and output and put it into matrices: $$ X=\\begin{bmatrix} 1 &amp; 2104 &amp; 5 &amp; 1 &amp; 45\\ 1 &amp; 1416 &amp; 3 &amp; 2 &amp; 40\\ 1 &amp; 1534 &amp; 3 &amp; 2 &amp; 30\\ 1 &amp; 852 &amp; 2 &amp; 1 &amp; 36\\ \\end{bmatrix} \\qquad \\theta=\\begin{bmatrix} \\theta_0\\ \\theta_1\\ \\theta_2\\ \\theta_3\\ \\theta_4\\ \\end{bmatrix} \\qquad y=\\begin{bmatrix} 460\\ 232\\ 315\\ 178\\ \\end{bmatrix} $$ \\(X\\) is a \\(m \\times n\\) matrix and \\(y\\) is a \\(m\\) dimensional matrix. Given the above: $$ \\theta = (X^\\intercal X)^{-1}X^\\intercal y $$</p>"},{"location":"notes/machine_learning/05-computing-parameters-analytically/#general-definition","title":"General Definition","text":"<p>Let's say we have \\(m\\) examples \\((x^{(1)}, y^{(1)}), \\ldots, (x^{(m)}, y^{(m)})\\) and \\(n\\) features. $$ x^{(i)} = \\begin{bmatrix} x_0^{(i)}\\ x_1^{(i)}\\ \\vdots\\ x_n^{(i)}\\ \\end{bmatrix} \\in \\R^{n+1} \\text{ training sample} \\qquad X = \\begin{bmatrix} (x^{(1)})^\\intercal\\ (x^{(2)})^\\intercal\\ \\vdots\\ (x^{(m)})^\\intercal\\ \\end{bmatrix} \\text{ (design matrix)} $$ In \\(X\\), each column is a feature, each row is a sample/input. We can find \\(\\theta\\): $$ \\theta = (X^\\intercal X)^{-1}X^\\intercal y $$</p> <p>TODO - derive the above.</p> <p>In this approach, we do not need feature scaling or mean normalization.</p> <p>When to choose gradient descent vs normal equation?</p> Gradient Descent Normal Equation Need to choose \\(\\alpha\\) No need to choose \\(\\alpha\\) Needs iterations No need to iterate Scales well with large \\(n\\). Slow with large \\(n\\). \\(O(kn^2)\\) \\(O(n^3)\\) to calculate \\((X^\\intercal X)^{-1}\\) <p>As long as \\(n\\) isn't too large, normal equation is a good method.</p> <p>TODO - derive the big O.</p>"},{"location":"notes/machine_learning/05-computing-parameters-analytically/#non-invertibility","title":"Non-Invertibility","text":"\\[ \\theta = (X^\\intercal X)^{-1}X^\\intercal y \\] <p>What if \\(X^\\intercal X\\) is non-invertible?</p> <ul> <li>Redundant features (linearly dependent)</li> <li>Too many features (e.g. \\(m \\leq n\\)).</li> <li>Delete features, or use regularization</li> </ul>"},{"location":"notes/machine_learning/06-classification-and-representation/","title":"06 classification and representation","text":"<ul> <li>Classification and Representation<ul> <li>Classification</li> <li>Hypothesis Representation<ul> <li>Interpretation of Hypothesis Output</li> </ul> </li> <li>Decision Boundary<ul> <li>Non-linear Decision Boundary</li> </ul> </li> </ul> </li> </ul>"},{"location":"notes/machine_learning/06-classification-and-representation/#classification-and-representation","title":"Classification and Representation","text":""},{"location":"notes/machine_learning/06-classification-and-representation/#classification","title":"Classification","text":"<p>Here, \\(y\\) is a discrete value $$ y \\in {0,1} $$ \\(0\\) is negative class and \\(1\\) is positive class. This is a two class problem.</p> <p>There is also multi-class problem: $$ y \\in {0,1,2,3,4} $$ One thing we could try, we can take a similar approach to linear regression for logistic regression, specifically have the model \\(h_\\theta(x)=\\theta^\\intercal x\\):</p> <ul> <li>If \\(h_\\theta(x) \\geq 0.5\\), predict \\(y=1\\).</li> <li>If \\(h_\\theta(x) &lt; 0.5\\), predict \\(y=0\\).</li> </ul> <p>It could work in some cases: $$ \\begin{bmatrix} 1 &amp; 0\\ 2 &amp; 0\\ 7 &amp; 1\\ 8 &amp; 1\\ 9 &amp; 1\\ \\end{bmatrix} $$ but if we add an outlier, it may move the 0.5 so that \\(7\\) is considered \\(0\\). TODO add more details. So linear regression may have been lucky. Classification isn't a linear function. Not surprising since the hypothesis could ouput values above 1 or less than 0.</p> <p>We'll talk about logistic regression: \\(0 \\leq h_\\theta(x) \\leq 1\\) (which is a classification algorithm).</p>"},{"location":"notes/machine_learning/06-classification-and-representation/#hypothesis-representation","title":"Hypothesis Representation","text":"<p>What function will we use to rep our hypothesis for a classification problem?</p> <p>For linear regression, our model was \\(h_\\theta(x) = \\theta^\\intercal x\\).</p> <p>For the logistic regression, we'll modify this to: $$ \\begin{align} h_\\theta(x) &amp;= g(\\theta^\\intercal x)\\ g(z) &amp;= \\frac{1}{1 + e^{-z}} \\text{ where } z \\in \\R \\end{align} $$ \\(g(z)\\) is called a sigmoid function or logistic function (the terms are interchangeable). This is why this regression is called logistic regression. The final hypothesis function then looks like: $$ h_\\theta(x) = \\frac{1}{1 + e^{- \\theta^\\intercal x}} $$ <code>TODO Include graph of logistic function</code></p> <p>Why do we do this? The logistic function has asymptotes at \\(0\\) and \\(1\\). That way, \\(0 \\leq h_\\theta(x) \\leq 1\\).</p>"},{"location":"notes/machine_learning/06-classification-and-representation/#interpretation-of-hypothesis-output","title":"Interpretation of Hypothesis Output","text":"<ul> <li>$h_\\theta(x) = $ estimated probability that \\(y=1\\) on input \\(x\\).</li> <li>\\(h_\\theta(x) = P(y=1|x;\\theta)\\)</li> <li>\\(P(y=1|x;\\theta) + P(y=0|x;\\theta) = 1\\) since \\(y \\in \\{0,1\\}\\)</li> </ul>"},{"location":"notes/machine_learning/06-classification-and-representation/#decision-boundary","title":"Decision Boundary","text":"<p>Given the interpretation: $$ \\begin{align} y=1 &amp;&amp; \\text{ if } &amp;&amp; h_\\theta(x) &amp; \\geq 0.5\\ &amp;&amp; &amp;&amp; \\frac{1}{1 + e^{- \\theta^\\intercal x}} &amp; \\geq 0.5\\ &amp;&amp; &amp;&amp; 2 &amp; \\geq 1 + e^{- \\theta^\\intercal x}\\ &amp;&amp; &amp;&amp; 1 &amp; \\geq e^{- \\theta^\\intercal x}\\ &amp;&amp; &amp;&amp; ln(1) &amp; \\geq - \\theta^\\intercal x\\ &amp;&amp; &amp;&amp; 0 &amp; \\geq - \\theta^\\intercal x\\ &amp;&amp; &amp;&amp; \\theta^\\intercal x &amp; \\geq 0\\ \\end{align} $$</p> \\[ \\begin{align*} y=0 &amp;&amp; \\text{ if } &amp;&amp; h_\\theta(x) &amp; &lt; 0.5\\\\ &amp;&amp; &amp;&amp; \\frac{1}{1 + e^{- \\theta^\\intercal x}} &amp; &lt; 0.5\\\\ &amp;&amp; &amp;&amp; 2 &amp; &lt; 1 + e^{- \\theta^\\intercal x}\\\\ &amp;&amp; &amp;&amp; 1 &amp; &lt; e^{- \\theta^\\intercal x}\\\\ &amp;&amp; &amp;&amp; ln(1) &amp; &lt; - \\theta^\\intercal x\\\\ &amp;&amp; &amp;&amp; 0 &amp; &lt; - \\theta^\\intercal x\\\\ &amp;&amp; &amp;&amp; \\theta^\\intercal x &amp; &lt; 0\\\\ \\end{align*} \\] <p>Setting \\(y=1\\) to include \\(0.5\\) is arbitrary, it doesn't really matter how we interpret \\(0.5\\) .</p> <p>Example $$ h_\\theta(x) = g(\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2)\\ \\theta = \\begin{bmatrix} -3\\ 1\\ 1\\ \\end{bmatrix} $$ Let's figure out when \\(y=1\\) and \\(y=0\\). $$ \\begin{align} y=1 &amp;&amp; \\text{ if } &amp;&amp; \\theta^\\intercal x &amp; \\geq 0\\ &amp;&amp; &amp;&amp; -3 + x_1 + x_2 &amp; \\geq 0\\ &amp;&amp; &amp;&amp; x_1 + x_2 &amp; \\geq 3\\ \\end{align} $$</p> \\[ \\begin{align*} y=0 &amp;&amp; \\text{ if } &amp;&amp; \\theta^\\intercal x &amp; &lt; 0\\\\ &amp;&amp; &amp;&amp; -3 + x_1 + x_2 &amp; &lt; 0\\\\ &amp;&amp; &amp;&amp; x_1 + x_2 &amp; &lt; 3\\\\ \\end{align*} \\] <p>\\(x_1 + x_2 = 3\\) is the decision boundary. On a graph, this is a line separating \\(y=1\\) and \\(y=0\\).</p> <p><code>TODO Include graph</code></p> <p>Decision boundary is a property of the hypothesis, not a property of the dataset.</p> <ul> <li>Looking at a training dataset, we cannot determine the decision boundary.</li> <li>Once we define the hypothesis, we can determine the decision boundary. Choosing the hypothesis often depends on the training dataset, but the actual decision boundary is determined from the hypothesis.</li> <li>We can choose whatever \\(\\theta\\), and then for whatever value we choose, we can find out the decision boundary.</li> </ul> <p>Determining the \\(\\theta\\), and therefore our hypothesis, that best fits our training dataset is a separate task.</p> <p>Another look at \\(\\theta^\\intercal x = 0\\)</p> <p>\\(\\theta^\\intercal x = 0\\) is the decision boundary. Another way to describe this is that the dot product of \\(\\theta\\) and \\(x\\) is 0. $$ \\begin{align} cos(\\text{angle between } \\theta \\text{ and } x) &amp;= \\frac{\\theta \\cdot x}{|\\theta| \\cdot |x|}\\ &amp;= \\frac{0}{|\\theta| \\cdot |x|}\\ &amp;= 0 \\end{align} $$ This means \\(\\theta\\) and \\(x\\) are \\(\\bot\\).</p>"},{"location":"notes/machine_learning/06-classification-and-representation/#non-linear-decision-boundary","title":"Non-linear Decision Boundary","text":"<p>We've mentioned in linear regression that we can provide polynomial regression. We can do this in logistic regression as well. $$ \\begin{align} h_\\theta(x) &amp;= g(\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_1^2 + \\theta_4 x_2^2)\\ \\theta^\\intercal &amp;= \\begin{bmatrix}-1 &amp; 0 &amp; 0 &amp; 1 &amp; 1\\end{bmatrix}\\ y &amp;= 1 \\text{ if } -1 + x_1^2 + x_2^2 \\geq 0\\ \\text{decision boundary} &amp;= -1 + x_1^2 + x_2^2 = 0\\ &amp;= x_1^2 + x_2^2 = 1 \\text{ (a unit circle)} \\end{align} $$</p>"},{"location":"notes/machine_learning/07-logistic-regression-model/","title":"07 logistic regression model","text":"<ul> <li>Logistic Regression Model<ul> <li>Cost Function<ul> <li>Linear Regression Cost Function</li> <li>Logistic Regression Cost Function<ul> <li>Looking at \\(y=1\\)</li> <li>Looking at \\(y=0\\)</li> </ul> </li> </ul> </li> <li>Simplified Cost Function and Gradient Descent<ul> <li>Logistic Regression Cost Function</li> </ul> </li> <li>Advanced Optimization</li> </ul> </li> </ul>"},{"location":"notes/machine_learning/07-logistic-regression-model/#logistic-regression-model","title":"Logistic Regression Model","text":""},{"location":"notes/machine_learning/07-logistic-regression-model/#cost-function","title":"Cost Function","text":"<p>Given: $$ \\begin{align} \\text{training set} &amp;= {(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\ldots, (x^{(m)}, y^{(m)})}\\ x &amp;= \\begin{bmatrix} x_0\\ x_1\\ \\vdots \\ x_n \\end{bmatrix} \\in \\R^{n+1}\\ x_0 &amp;= 1\\ y &amp;\\in {0,1}\\ h_\\theta(x) &amp;= \\frac{1}{1 + e^{-\\theta^\\intercal x}} \\end{align} $$ How do we choose \\(\\theta\\)? Similar to linear regression, we have to minimize the cost function.</p>"},{"location":"notes/machine_learning/07-logistic-regression-model/#linear-regression-cost-function","title":"Linear Regression Cost Function","text":"<p>Let's re-write linear regression cost function: $$ \\begin{align} J(\\theta) &amp;= \\frac{1}{m} \\sum_{i=1}^m \\frac12(h_\\theta(x^{(i)}) - y^{(i)})^2\\ &amp;= \\frac1m \\sum_{i=1}^m Cost(h_\\theta(x^{(i)}), y^{(i)}) &amp; ``\\text{The average cost across the training dataset}\"\\ Cost(a,b) &amp;= \\frac12 (a - b)^2 \\end{align} $$ Can we use the same \\(Cost\\) for logistic regression? No, we can't. This results in a non-convex function, a function with many local minima. This is due to \\(h_\\theta(x) = \\frac1{1+e^{-\\theta^\\intercal x}}\\) not being linear. We need a convex function for logistic regression</p>"},{"location":"notes/machine_learning/07-logistic-regression-model/#logistic-regression-cost-function","title":"Logistic Regression Cost Function","text":"\\[ Cost(a,b) = \\begin{cases} -log(a) &amp; \\text{if $y=1$}\\\\ -log(1-a) &amp; \\text{if $y=0$}\\\\ \\end{cases} \\]"},{"location":"notes/machine_learning/07-logistic-regression-model/#looking-at-y1","title":"Looking at \\(y=1\\)","text":"\\[ cost = \\begin{cases} 0 &amp; \\text{if $a=1$}\\\\ \\infty &amp; \\text{as $a \\rarr 0$}\\\\ \\end{cases} \\] <p><code>TODO Include graph.</code> Note - because we are dealing with logistic functions, \\(0 \\leq a \\leq 1\\).</p> <p>Does \\(\\lim_{a \\rarr 0} cost = \\infty\\) make sense? If we say, for some value of \\(x\\), that \\(h_\\theta(x) = 0\\), then we are saying that there is no chance that \\(y=1\\). If it turns out that \\(y=1\\), then our hypothesis is completely, absolutely wrong.</p>"},{"location":"notes/machine_learning/07-logistic-regression-model/#looking-at-y0","title":"Looking at \\(y=0\\)","text":"\\[ cost = \\begin{cases} 0 &amp; \\text{if $a=0$}\\\\ \\infty &amp; \\text{as $a \\rarr 1$}\\\\ \\end{cases} \\] <p><code>TODO Include graph.</code> Note - because we are dealing with logistic functions, \\(0 \\leq a \\leq 1\\).</p> <p>Does \\(\\lim_{a \\rarr1 } cost = \\infty\\) make sense? If we say, for some value of \\(x\\), that \\(h_\\theta(x) = 1\\), then we are saying that there is no chance that it is not \\(y=1\\). If it turns out that \\(y=0\\), then our hypothesis is completely, absolutely wrong.</p>"},{"location":"notes/machine_learning/07-logistic-regression-model/#simplified-cost-function-and-gradient-descent","title":"Simplified Cost Function and Gradient Descent","text":"\\[ Cost(a,b) = \\begin{cases} -log(a) &amp; \\text{if $y=1$}\\\\ -log(1-a) &amp; \\text{if $y=0$}\\\\ \\end{cases} \\] <p>The cost function can be simplified, if we take advantage of the fact that \\(y \\in \\{0,1\\}\\): $$ Cost(a,b) = -b\\ log(a) + (-(1-b)\\ log(1-a)) $$ Since \\(y \\in \\{0,1\\}\\), one of the log multipliers will be 0 and the other will be 1.</p>"},{"location":"notes/machine_learning/07-logistic-regression-model/#logistic-regression-cost-function_1","title":"Logistic Regression Cost Function","text":"\\[ \\begin{align*} J(\\theta) &amp;= \\frac1m \\sum_{i=1}^m Cost(h_\\theta(x^{(i)}), y^{(i)})\\\\ &amp;= \\frac1m \\sum_{i=1}^m -y^{(i)}log(h_\\theta(x^{(i)})) - (1-y^{(i)})log(1-h_\\theta(x^{(i)}))\\\\ &amp;= -\\frac1m \\sum_{i=1}^m y^{(i)}log(h_\\theta(x^{(i)})) + (1-y^{(i)})log(1-h_\\theta(x^{(i)}))\\\\ \\end{align*} \\] <p>Vectorized: $$ \\begin{align} h &amp;= g(X\\theta)\\ J(\\theta) &amp;= \\frac1m \\cdot (-y^\\intercal log(h) - (1-y)^\\intercal log(1-h)) \\end{align} $$ The above can be derived from the principle of maximum likelihood estimation. <code>TODO Derive this</code>.</p> <p>So how to do we find \\(\\theta\\) that minimizes \\(J(\\theta)\\)? Gradient descent: $$ \\begin{align} &amp; Repeat \\; \\lbrace \\ &amp; \\; \\theta_j := \\theta_j - \\alpha \\dfrac{\\partial}{\\partial \\theta_j}J(\\theta) \\ &amp; \\rbrace \\end{align} $$</p> <p>Let's calculate \\(\\frac{\\partial}{\\partial\\theta_j}J(\\theta) = \\frac1m \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\\\\\\): $$ \\begin{align} \\frac{\\partial}{\\partial \\theta_j} h_\\theta(x) &amp;= \\frac{\\partial}{\\partial \\theta_j} \\frac{1}{1+e^{-\\theta^\\intercal x}}\\ &amp;= \\frac{\\partial}{\\partial \\theta_j}(1+e^{-\\theta^\\intercal x})^{-1}\\ &amp;= -(1+e^{-\\theta^\\intercal x})^{-2} \\frac{\\partial}{\\partial \\theta_j} (1+e^{-\\theta^\\intercal x})\\ &amp;= -(1+e^{-\\theta^\\intercal x})^{-2} \\frac{\\partial}{\\partial \\theta_j} e^{-\\theta^\\intercal x}\\ &amp;= -(1+e^{-\\theta^\\intercal x})^{-2} e^{-\\theta^\\intercal x}  \\frac{\\partial}{\\partial \\theta_j}(-\\theta^\\intercal x)\\ &amp;= (1+e^{-\\theta^\\intercal x})^{-2} e^{-\\theta^\\intercal x}  \\frac{\\partial}{\\partial \\theta_j}(\\theta^\\intercal x)\\ &amp;= (1+e^{-\\theta^\\intercal x})^{-2} e^{-\\theta^\\intercal x}  x_j\\ &amp;= h_\\theta(x)^2 \\times e^{-\\theta^\\intercal x} \\times x_j\\ \\end{align} $$</p> \\[ \\begin{align*} \\frac{\\partial}{\\partial \\theta_j} J(\\theta) &amp;= \\frac{\\partial}{\\partial \\theta_j} \\frac{-1}m \\sum_{i=1}^m y^{(i)}log(h_\\theta(x^{(i)})) + (1-y^{(i)})log(1-h_\\theta(x^{(i)}))\\\\ &amp;= -\\frac1m \\sum_{i=1}^m \\frac{\\partial}{\\partial \\theta_j} \\left( y^{(i)}log(h_\\theta(x^{(i)})) \\right) + \\frac{\\partial}{\\partial \\theta_j} \\left( (1-y^{(i)})log(1-h_\\theta(x^{(i)}))\\right)\\\\ &amp;= -\\frac1m \\sum_{i=1}^m y^{(i)} \\frac{\\partial}{\\partial \\theta_j} \\left( log(h_\\theta(x^{(i)})) \\right) + (1-y^{(i)}) \\frac{\\partial}{\\partial \\theta_j} \\left( log(1-h_\\theta(x^{(i)}))\\right)\\\\ &amp;= -\\frac1m \\sum_{i=1}^m \\frac{y^{(i)}}{h_\\theta(x^{(i)}) } \\frac{\\partial}{\\partial \\theta_j} \\left( h_\\theta(x^{(i)}) \\right) + \\frac{(1-y^{(i)})}{1 - h_\\theta(x^{(i)})} \\frac{\\partial}{\\partial \\theta_j}\\left( 1-h_\\theta(x^{(i)})\\right)\\\\ &amp;= -\\frac1m \\sum_{i=1}^m \\frac{y^{(i)}}{h_\\theta(x^{(i)}) } \\frac{\\partial}{\\partial \\theta_j} \\left( h_\\theta(x^{(i)}) \\right) - \\frac{(1-y^{(i)})}{1 - h_\\theta(x^{(i)})} \\frac{\\partial}{\\partial \\theta_j}\\left( h_\\theta(x^{(i)})\\right)\\\\ &amp;= -\\frac1m \\sum_{i=1}^m \\frac{\\partial h_\\theta(x^{(i)})}{\\partial\\theta_j} \\left[ \\frac{y^{(i)}}{h_\\theta(x^{(i)})} - \\frac{(1-y^{(i)})}{1 - h_\\theta(x^{(i)})} \\right]\\\\ &amp;= -\\frac1m \\sum_{i=1}^m \\frac{\\partial h_\\theta(x^{(i)})}{\\partial\\theta_j} \\left[ \\frac{y^{(i)}(1 - h_\\theta(x^{(i)})) - h_\\theta(x^{(i)})(1-y^{(i)})}{h_\\theta(x^{(i)})(1 - h_\\theta(x^{(i)}))} \\right]\\\\ &amp;= -\\frac1m \\sum_{i=1}^m \\frac{\\partial h_\\theta(x^{(i)})}{\\partial\\theta_j} \\left[ \\frac{y^{(i)} - h_\\theta(x^{(i)})}{h_\\theta(x^{(i)})(1 - h_\\theta(x^{(i)}))} \\right]\\\\ &amp;= \\frac1m \\sum_{i=1}^m \\frac{\\partial h_\\theta(x^{(i)})}{\\partial\\theta_j} \\left[ \\frac{h_\\theta(x^{(i)}) - y^{(i)}}{h_\\theta(x^{(i)})(1 - h_\\theta(x^{(i)}))} \\right]\\\\ &amp;= \\frac1m \\sum_{i=1}^m h_\\theta(x^{(i)})^2 e^{-\\theta^\\intercal x} \\left[ \\frac{h_\\theta(x^{(i)}) - y^{(i)}}{h_\\theta(x^{(i)})(1 - h_\\theta(x^{(i)}))} \\right] x_j^{(i)}\\\\ &amp;= \\frac1m \\sum_{i=1}^m \\left[ \\frac{h_\\theta(x^{(i)})^2}{h_\\theta(x^{(i)})(1 - h_\\theta(x^{(i)}))} \\right] e^{-\\theta^\\intercal x} (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\\\\ &amp;= \\frac1m \\sum_{i=1}^m \\left[ \\frac{ \\frac{1}{1+e^{-\\theta^\\intercal x}} }{1 - \\frac{1}{1+e^{-\\theta^\\intercal x}}} \\right] e^{-\\theta^\\intercal x} (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\\\\ &amp;= \\frac1m \\sum_{i=1}^m \\left[ \\frac{ \\frac{1}{1+e^{-\\theta^\\intercal x}} }{\\frac{e^{-\\theta^\\intercal x}}{1+e^{-\\theta^\\intercal x}}} \\right] e^{-\\theta^\\intercal x} (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\\\\ &amp;= \\frac1m \\sum_{i=1}^m \\frac{1}{e^{-\\theta^\\intercal x}} e^{-\\theta^\\intercal x} (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\\\\ &amp;= \\frac1m \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\\\\ \\end{align*} \\] <p>Our updated gradient descent: $$ \\begin{align} &amp; Repeat \\; \\lbrace \\ &amp; \\; \\theta_j := \\theta_j - \\alpha \\frac1m \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) x_j \\ &amp; \\rbrace \\end{align} $$ Vectorized gradient descent: <code>TODO Think about this</code> $$ \\theta := \\theta - \\frac{\\alpha}{m} X^\\intercal(g(X\\theta) - \\vec{y}) $$ This looks very similar to linear regression gradient descent! What is the difference between the two, then? The \\(h(\\theta)\\).</p> <ul> <li>Linear Regression - \\(h_\\theta(x)=\\theta^\\intercal x\\)</li> <li>Logistic Regression - \\(h_\\theta(x)= \\frac{1}{1 + e^{-\\theta^\\intercal x}}\\)</li> </ul> <p>One last note, feature scaling applies for logistic regression as well.</p>"},{"location":"notes/machine_learning/07-logistic-regression-model/#advanced-optimization","title":"Advanced Optimization","text":"<p>There are other ways to find \\(\\theta\\) that minimizes \\(J(\\theta)\\):</p> <ul> <li>Conjugate Gradient</li> <li>BFGS</li> <li>L-BFGS</li> </ul> <p>These are more sophisticated algorithms compared to gradient descent, but usually runs faster than it and we do not need to pick a step size (\\(\\alpha\\)).</p> <p>For more details, check the slides/video.</p>"},{"location":"notes/machine_learning/08-multiclass-classification/","title":"08 multiclass classification","text":"<ul> <li>8 Multiclass Classification<ul> <li>One Versus All</li> </ul> </li> </ul>"},{"location":"notes/machine_learning/08-multiclass-classification/#8-multiclass-classification","title":"8 Multiclass Classification","text":"<p>Multiclassification - \\(y \\in \\{0,1,2,3,4\\}\\). It is not only a boolean classification. E.g. does a patient have a malignant tumor is a binomial classification (yes or no).</p> <p><code>TODO - Include graphs</code></p>"},{"location":"notes/machine_learning/08-multiclass-classification/#one-versus-all","title":"One Versus All","text":"<p>We assign \\(y=1\\) for one specific class and \\(y=0\\) for the remaining class and then do normal logistic regression. We would then have as many logistic regression models as we do have classes.</p> \\[ h_\\theta^{(i)}(x) = P(y=i|x;\\theta) \\quad (i=1,2,3,4,\\ldots,n) \\] <p>Train a logistic regression classifier \\(h_\\theta^{(i)}(x)\\) for each class \\(i\\) to predict the probability that \\(y=i\\).</p> <p>On a new input \\(x\\), to make a prediction, pick the class \\(i\\) that \\(\\max_i h_\\theta^{(i)}(x)\\).</p>"},{"location":"notes/machine_learning/09-solving-overfitting/","title":"09 solving overfitting","text":"<ul> <li>9 Solving the Problem of Overfitting<ul> <li>The Problem of Overfitting<ul> <li>Addressing Overfitting</li> </ul> </li> <li>Cost Function</li> <li>Regularized Linear Regression<ul> <li>Gradient Descent</li> <li>Normal Equation<ul> <li>Non-Invertibility</li> </ul> </li> </ul> </li> <li>Regularized Logistic Regression</li> </ul> </li> </ul>"},{"location":"notes/machine_learning/09-solving-overfitting/#9-solving-the-problem-of-overfitting","title":"9 Solving the Problem of Overfitting","text":""},{"location":"notes/machine_learning/09-solving-overfitting/#the-problem-of-overfitting","title":"The Problem of Overfitting","text":"<p><code>TODO - Include graphs</code></p> <p>Overfitting - if we have too many features, the hypothesis may fit the training set very well (\\(J(\\theta) \\approx 0\\)), but fails to generalize to new examples.</p> <p>A sample may roughly follow a quadratic relation, but if we throw enough multi-polynomials at it, we could get a wild graph that goes through exactly every training example.</p>"},{"location":"notes/machine_learning/09-solving-overfitting/#addressing-overfitting","title":"Addressing Overfitting","text":"<p>We could try to plot the data and eyeball it? We can't do this when there are a lot of features, it's almost impossible to visualize/graph.</p> <p>The options:</p> <ol> <li>Reduce the number of features</li> <li>Manually select which features to keep</li> <li>Use a model selection algorithm (to choose the features for us)</li> <li>Regularization</li> <li>Reduce the value of parameters (\\(\\theta_j\\))</li> <li>Works well when we have a lot features (each of which contribute to a bit to predicting \\(y\\))</li> </ol>"},{"location":"notes/machine_learning/09-solving-overfitting/#cost-function","title":"Cost Function","text":"<p>Intuition - a higher polynomial may overfit. What if we penalize higher values of \\(\\theta_j\\)?</p> <p>Example of a penalty: $$ \\min_\\theta \\frac1{2m}\\left[ \\sum_{i=0}^m (h_\\theta(x^{(i)}) - y^{(i)})^2 + 1000 \\times \\theta_3^2 + 1000 \\times \\theta_4^2\\right] $$ This forces \\(\\theta_3\\) and \\(\\theta_4\\) to be smaller. This will result in a simpler hypothesis, and less prone to overfitting. We arbritarily chose the two thetas above to penalize, but it is hard to pick which ones to penalize for every case, so, to generalize, we add a penalty for all of them.</p> <p>Cost Function (Linear Regression) (Regularized) $$ J(\\theta) = \\frac1{2m}\\left[ \\sum_{i=0}^m (h_\\theta(x^{(i)}) - y^{(i)})^2 + \\lambda \\sum_{j=1}^m \\theta_j^2 \\right] $$</p> <ul> <li>\\(\\lambda\\) - regularization parameter</li> <li>\\(\\lambda \\sum_{j=1}^m \\theta_j^2\\) - regularization term</li> <li>We are not penalizing \\(\\theta_0\\) by convention. (Note the \\(j=1\\) on the \\(\\sum\\) in the regularization term)</li> </ul> <p>What if we choose a really large \\(\\lambda\\)? Theta will go to \\(0\\), \\(h_\\theta(x) = \\theta_0\\). \"Underfitting\"</p>"},{"location":"notes/machine_learning/09-solving-overfitting/#regularized-linear-regression","title":"Regularized Linear Regression","text":"<p>So with regularization, we are trying to solve: $$ J(\\theta) = \\frac1{2m}\\left[ \\sum_{i=0}^m (h_\\theta(x^{(i)}) - y^{(i)})^2 + \\lambda \\sum_{j=1}^m \\theta_j^2 \\right] \\Bigg| \\min_\\theta J(\\theta) $$</p>"},{"location":"notes/machine_learning/09-solving-overfitting/#gradient-descent","title":"Gradient Descent","text":"<p>Previous Gradient Descent</p> <p>With regularization, our new gradient descent looks like: $$ \\begin{align} &amp; \\text{Repeat}\\ \\lbrace \\newline &amp; \\ \\ \\ \\ \\theta_0 := \\theta_0 - \\alpha\\ \\frac{1}{m}\\ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \\newline &amp; \\ \\ \\ \\ \\theta_j := \\theta_j - \\alpha\\ \\left[ \\left( \\frac{1}{m}\\ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \\right) + \\frac{\\lambda}{m}\\theta_j \\right] &amp;\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ j \\in \\lbrace 1,2...n\\rbrace\\newline &amp; \\rbrace \\end{align} $$ The second term can be rewritten: $$ \\theta_j := \\theta_j \\left(1 - \\alpha \\frac{\\lambda}{m} \\right) - \\alpha\\ \\frac{1}{m}\\ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} $$</p> Term Effect \\(1 - \\alpha \\frac {\\lambda}{m}\\) Can be evaluated to a value a little less than one. This effectively shrinks \\(\\theta_j\\) each iteration \\(\\alpha\\ \\frac{1}{m}\\ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\\) Performs the gradient descent"},{"location":"notes/machine_learning/09-solving-overfitting/#normal-equation","title":"Normal Equation","text":"<p>Previously, given: $$ X = \\begin{bmatrix} (x^{(1)})^\\intercal \\ \\vdots \\ (x^{(m)})^\\intercal \\ \\end{bmatrix} \\quad y= \\begin{bmatrix} y^1\\ \\vdots\\ y^m \\end{bmatrix}\\ $$ we can calculate: $$ \\theta= (X^\\intercal X)^{-1}X^\\intercal y $$ Let's take our new \\(J(\\theta)\\), calculate \\(\\frac{\\partial}{\\partial \\theta_j} J(\\theta) = 0\\):</p> <p><code>TODO - Solve this</code></p> <p>This will give us: $$ \\begin{align}&amp; \\theta = \\left( X^TX + \\lambda \\cdot L \\right)^{-1} X^Ty \\newline&amp; \\text{where}\\ \\ L = \\begin{bmatrix} 0 &amp; &amp; &amp; &amp; \\newline &amp; 1 &amp; &amp; &amp; \\newline &amp; &amp; 1 &amp; &amp; \\newline &amp; &amp; &amp; \\ddots &amp; \\newline &amp; &amp; &amp; &amp; 1 \\newline\\end{bmatrix}\\end{align} $$</p>"},{"location":"notes/machine_learning/09-solving-overfitting/#non-invertibility","title":"Non-Invertibility","text":"<p>If \\(m &lt; n\\), then \\(X^\\intercal X\\) is non-invertible. If \\(m=n\\), then \\(X^\\intercal X\\) may be non-invertible. However, with regularization, if \\(\\lambda &gt; 0\\), it can be proved that \\(\\left( X^TX + \\lambda \\cdot L \\right)\\) is not non-invertible. Another benefit of regularization.</p>"},{"location":"notes/machine_learning/09-solving-overfitting/#regularized-logistic-regression","title":"Regularized Logistic Regression","text":"<p>Similarly, we can do the same regularization with logistic regression.</p> <p>Cost Function (Logisitc Regression) (Regularized)</p> \\[ J(\\theta) = - \\left[ \\frac1m \\sum_{i=0}^m y^{(i)}log(h_\\theta(x^{(i)})) + (1-y^{(i)})log(1-h_\\theta(x^{(i)}) \\right] + \\frac{\\lambda}{2m} \\sum_{j=1}^m \\theta_j^2 \\] <p>Gradient Descent</p> \\[ \\begin{align*} &amp; \\text{Repeat}\\ \\lbrace \\newline &amp; \\ \\ \\ \\ \\theta_0 := \\theta_0 - \\alpha\\ \\frac{1}{m}\\ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \\newline &amp; \\ \\ \\ \\ \\theta_j := \\theta_j - \\alpha\\ \\left[ \\left( \\frac{1}{m}\\ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \\right) + \\frac{\\lambda}{m}\\theta_j \\right] &amp;\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ j \\in \\lbrace 1,2...n\\rbrace\\newline &amp; \\rbrace \\end{align*} \\]"},{"location":"notes/machine_learning/10-neural-networks/","title":"10 neural networks","text":"<ul> <li>Neural Networks<ul> <li>Motivations<ul> <li>Non-Linear Hypothesis</li> <li>Neurons and the Brain<ul> <li>The \"One Learning Algorithm\" Hypothesis</li> </ul> </li> </ul> </li> <li>Model Representations<ul> <li>Neuron Model: A Logistic Unit<ul> <li>Neural Network</li> <li>Vectorized Representation</li> </ul> </li> </ul> </li> <li>Intuition - Neural Networks Learns Its Own Features</li> <li>Application</li> </ul> </li> </ul>"},{"location":"notes/machine_learning/10-neural-networks/#neural-networks","title":"Neural Networks","text":""},{"location":"notes/machine_learning/10-neural-networks/#motivations","title":"Motivations","text":""},{"location":"notes/machine_learning/10-neural-networks/#non-linear-hypothesis","title":"Non-Linear Hypothesis","text":"<p>Let's say we have a non-linear classification problem. We have previously defined a way to represent this with logistic regression by combining terms. E.g. If we have \\(x_1\\) and \\(x_2\\), we can introduce higher polynomial terms but computing new features to be \\(x_1 x_2\\), \\(x_1^2\\), \\(x_1^2 x_2\\), etc. Our hypothesis would look something like:</p> \\[ h_\\theta(x) = g(\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_1 x_2 + \\theta_4 x_1^2 + \\dots ) \\] <p>This is fine for small number of features. What happens if the number of features are large? Let's say \\(n=100\\). If we wanted to include all the quadratic terms, we have to combine all the \\(x_i\\)'s. This would result the features \\(x_1 x_2, x_1, x_3, \\ldots, x_1 x_{100}, x_2 x_3, \\dots\\). \\({100 \\choose 2} = 4950\\), meaning we'd have almost 5K features! If we includes cubic terms, this get's even more ridiculously big. This makes our computations way more complex.</p> <p>We could limit the types of combinations we would include, but that would limit our possible hypotheses. This approach doesn't seem to be a good when there are a lot of features.</p> <p>Example Where n is Large - Computer Vision</p> <p>In computer vision, our input is a picture and our output could be some classification of the picture. The input is specifically represented as an array of numbers, each of which is a pixel. This means that for a 50x50 picture, we have 2500 features. (If this was in RBG, each pixel would be 3 numbers and the number of features would be 7500).</p> <p>Sure, the number of features are large, but is it a non-linear hypothesis? It's a bit difficult to imagine, but for picture recognition, it is unlikely that a linear relationship exists between pixels to distinguish certain objects.</p>"},{"location":"notes/machine_learning/10-neural-networks/#neurons-and-the-brain","title":"Neurons and the Brain","text":"<p>Neural networks mimics how the brain learns.</p> <ul> <li>It was used widely in the 80's and 90's, after which it kinda saw a decrease.</li> <li>There has been a recent resurgence - especially with the progression of computers being able to handle the computational complexity that neural networks required.</li> </ul>"},{"location":"notes/machine_learning/10-neural-networks/#the-one-learning-algorithm-hypothesis","title":"The \"One Learning Algorithm\" Hypothesis","text":"<p>There was an experiment that rewired the auditory cortex, which received signals from the ears and interprets sound, to be connected to the eyes instead. The auditor cortex learned to see. This suggests that the brain is compartmentalized by specific learning algorithms - we think that the brain has a single learning algorithm. Any part of the brain could</p>"},{"location":"notes/machine_learning/10-neural-networks/#model-representations","title":"Model Representations","text":""},{"location":"notes/machine_learning/10-neural-networks/#neuron-model-a-logistic-unit","title":"Neuron Model: A Logistic Unit","text":"<p>A neuron is a unit of computation that takes inputs and then produces an output. In neural networks, we use the same logistic function as classification, and we call it a sigmoid (logistic) activation function.</p> <p><code>TODO - Include Diagram</code></p> <p>The diagram of a single neuron can be expressed as \\([x_0 x_1 x_2] \\rarr [\\dots] \\rarr h_\\theta(x)\\).</p>"},{"location":"notes/machine_learning/10-neural-networks/#neural-network","title":"Neural Network","text":"<p>A neural network is a group of different neurons strung together. An example:</p> \\[ [x_0 x_1 x_2] \\rarr [a_1^{(2)} a_2^{(2)} a_3^{(2)}] \\rarr h_\\Theta(x) \\] Term Description \\([x_0 x_1 x_2]\\) Layer 1, or input layer \\([x_0 x_1 x_2]\\) Layer 2, a hidden layer \\(h_\\Theta(x)\\) Layer 3, or output layer <p>Some notation:</p> \\[ \\begin{align*} &amp; a_i^{(j)} = \\text{\"activation\" of unit $i$ in layer $j$} \\newline &amp; \\Theta^{(j)} = \\text{matrix of weights controlling function mapping from layer $j$ to layer $j+1$}\\end{align*} \\] <p>\"Activation\" essentially means the value that is computed and outputted by the neuron.</p> <p>Given this notation, we can calcualte the values of the activation nodes as:</p> \\[ \\begin{align*} a_1^{(2)} &amp;= g(\\Theta_{10}^{(1)}x_0 + \\Theta_{11}^{(1)}x_1 + \\Theta_{12}^{(1)}x_2 + \\Theta_{13}^{(1)}x_3) \\newline a_2^{(2)} &amp;= g(\\Theta_{20}^{(1)}x_0 + \\Theta_{21}^{(1)}x_1 + \\Theta_{22}^{(1)}x_2 + \\Theta_{23}^{(1)}x_3) \\newline a_3^{(2)} &amp;= g(\\Theta_{30}^{(1)}x_0 + \\Theta_{31}^{(1)}x_1 + \\Theta_{32}^{(1)}x_2 + \\Theta_{33}^{(1)}x_3) \\newline h_\\Theta(x) = a_1^{(3)} &amp;= g(\\Theta_{10}^{(2)}a_0^{(2)} + \\Theta_{11}^{(2)}a_1^{(2)} + \\Theta_{12}^{(2)}a_2^{(2)} + \\Theta_{13}^{(2)}a_3^{(2)}) \\newline \\end{align*} \\] <p>Each layer has its own matrix of weights - \\(\\Theta^{(j)}\\).</p> <p>If network has \\(s_j\\) units in layer \\(j\\) and \\(s_{j+1}\\) units in layer \\(j+1\\), then \\(\\Theta^{(j)}\\) will be of dimension \\(s_{j+1} \\times (s_j + 1)\\). Why add 1 to \\(s_j\\)? That is the bias unit (\\(x_0 = 1\\)). This gets added to every layer. It may or may not be shown in the diagrams.</p> <p>So in the above example, \\(\\Theta^{(1)} \\in \\R^{3 \\times 4}\\). Layer 1 has 3 units and layer has 3 units, hence 3 by 4.</p> <p>For a \\(\\Theta\\), each row represents the next layers activation and each column represents the current layer's activation.</p>"},{"location":"notes/machine_learning/10-neural-networks/#vectorized-representation","title":"Vectorized Representation","text":"<p>We currently have this representation:</p> \\[ \\begin{align*} a_1^{(2)} &amp;= g(\\Theta_{10}^{(1)}x_0 + \\Theta_{11}^{(1)}x_1 + \\Theta_{12}^{(1)}x_2 + \\Theta_{13}^{(1)}x_3) \\newline a_2^{(2)} &amp;= g(\\Theta_{20}^{(1)}x_0 + \\Theta_{21}^{(1)}x_1 + \\Theta_{22}^{(1)}x_2 + \\Theta_{23}^{(1)}x_3) \\newline a_3^{(2)} &amp;= g(\\Theta_{30}^{(1)}x_0 + \\Theta_{31}^{(1)}x_1 + \\Theta_{32}^{(1)}x_2 + \\Theta_{33}^{(1)}x_3) \\newline h_\\Theta(x) = a_1^{(3)} &amp;= g(\\Theta_{10}^{(2)}a_0^{(2)} + \\Theta_{11}^{(2)}a_1^{(2)} + \\Theta_{12}^{(2)}a_2^{(2)} + \\Theta_{13}^{(2)}a_3^{(2)}) \\newline \\end{align*} \\] <p>Let's refactor it (calculating layer 2 as the example):</p> \\[ \\begin{align*} z_k^{(2)} &amp;= \\Theta_{k,0}^{(1)} x_0 +  \\Theta_{k,1}^{(1)} x_1 + \\dots +  \\Theta_{k,n}^{(1)} x_n \\newline a_1^{(2)} &amp;= g(z_1^{(2)}) \\newline a_2^{(2)} &amp;= g(z_2^{(2)}) \\newline a_3^{(2)} &amp;= g(z_3^{(2)}) \\newline \\end{align*} \\] <p>We can vaguely see all the values of \\(\\Theta\\) in the system of equations to be a matrix operation: \\(\\Theta^{(1)}x\\). Let's say \\(x = a^{(1)}\\). Then we can say:</p> \\[ \\begin{align*} x = \\begin{bmatrix} x_0 \\newline x_1 \\newline \\vdots \\newline x_n \\end{bmatrix} &amp;z^{(j)} = \\begin{bmatrix} z_1^{(j)} \\newline z_2^{(j)} \\newline \\vdots \\newline z_n^{(j)} \\end{bmatrix} \\end{align*} \\] <p>which we then can generalize:</p> \\[ \\begin{align*} z^{(j)} &amp;= \\Theta^{(j-1)}a^{(j-1)} \\\\ a^{(j)} &amp;= g(z^{(j)}) &amp;\\text{$g$ is an element-wise operation.} \\end{align*} \\] <p><code>TODO - Organize the flow of this</code></p> <p>The above operation is used to calculate every layer, even the output layer. The output layer will produce an array of a single element.</p> <p>The process of computing \\(h(x)\\) is called forward propagation.</p>"},{"location":"notes/machine_learning/10-neural-networks/#intuition-neural-networks-learns-its-own-features","title":"Intuition - Neural Networks Learns Its Own Features","text":"<p>If we only look at the llast 2 layers (ignore the other layers), we have: $$ h_\\theta(x) = g(\\Theta_{10}^{(2)}a_0^{(2)} + \\Theta_{11}^{(2)}a_1^{(2)} + \\Theta_{12}^{(2)}a_2^{(2)} + \\Theta_{13}^{(2)}a_0^{(3)} $$ This is essentially logistic regression with features \\(a\\)!</p> <p>The feature \\(a\\) is computed from another set of features (\\(x\\)).</p> <p>Essentially, neural networks takes input features, use those to learn its own features, and uses that to get the hypothesis.</p> <p>Neural networks isn't contrained by the input features or polynomial features. It can learn whatever features it wants.</p>"},{"location":"notes/machine_learning/10-neural-networks/#application","title":"Application","text":""},{"location":"notes/math/bitwise-operations/","title":"Bitwise Operations Tips/Tricks","text":""},{"location":"notes/math/bitwise-operations/#how-do-you-negate-a-number-ignoring-leading-zeroes","title":"How do you negate a number, ignoring leading zeroes?","text":"<p>Let's say you have unsigned, 8 bit integer: <code>5</code>. How can we get the inverse of this? (<code>~5</code>)</p> <p><code>5</code> in binary is <code>101</code>, so the inverse would be <code>010</code> or <code>2</code>.</p> <p>If we were to do the bitwise operation inverse, we would get something different. Since it is a 8 bit integer, <code>5</code> is actually <code>00000101</code> and the inverse would be <code>11111010</code>.</p> <p>So how do we do this? <code>~5 &amp; ((1 &lt;&lt; 3) - 1)</code></p> <p>We take <code>1</code>, shift it over by however many digits we want to inverse and subtract 1. This gives us leadings zeroes with a specific number of tailing ones. We then intersect this with the inverse. This essentially get's rid of the leading ones that result from the inverse.</p>"},{"location":"notes/math/bitwise-operations/#how-do-you-do-a-bitwise-equals-operation","title":"How do you do a bitwise equals operation?","text":"<p>Let's say we have <code>101110</code> and <code>101001</code>. How can we get a binary value that shows which digits are equal? In this case, <code>111000</code>?</p> <p>You can do a XOR and negate!</p>"},{"location":"notes/networking/cidr/","title":"Classless Inter-Domain Routing (CIDR)","text":"CIDR Method for IP routing and for allocating IP addresses <p>Notation: <code>&lt;IP Address&gt;/&lt;Decimal Number&gt;</code></p> <p>The decimal number is the number of leading bits that represent the network mask - aka the prefix for an IP address.</p> <p>This is all in terms of IPv4.</p> <p>An IP has 32 bits.</p> <p>Ex: <code>10.0.0.0/16</code></p> <p>The IP address can be represented as : <code>00001010 00000000 0000000 0000000</code></p> <p>The subnet mask is <code>11111111 11111111 00000000 0000000</code> or <code>255.255.0.0</code></p> <p>This means there are 16 bits available for the block, or a range of 2^16 addresses.</p>"},{"location":"notes/networking/cidr/#if-we-have-16-bits-available-and-we-want-x-subnets-what-is-the-range-for-each-one","title":"If we have 16 bits available, and we want X subnets, what is the range for each one?","text":"<p>If we have 8, then each one would have \\(\\frac{2^{16}}{8} = \\frac{2^{16}}{2^3} = 2^{13}\\) addresses, or 13 bits each. A block would have a 19 bit mask:</p> <ol> <li><code>00001010 00000000 00000000 0000000</code> or <code>10.0.0.0/19</code></li> <li><code>00001010 00000000 00100000 0000000</code> or <code>10.0.32.0/19</code></li> <li><code>00001010 00000000 01000000 0000000</code> or <code>10.0.64.0/19</code></li> <li><code>00001010 00000000 01100000 0000000</code> or <code>10.0.96.0/19</code></li> <li><code>00001010 00000000 10000000 0000000</code> or <code>10.0.128.0/19</code></li> <li><code>00001010 00000000 10100000 0000000</code> or <code>10.0.160.0/19</code></li> <li><code>00001010 00000000 11000000 0000000</code> or <code>10.0.192.0/19</code></li> <li><code>00001010 00000000 11100000 0000000</code> or <code>10.0.224.0/19</code></li> </ol> <p>If we have \\(X\\) subnets, then each one would have:</p> \\[ \\begin{align*} \\frac{2^{16}}{X} &amp;= \\frac{2^{16}}{2^{log_2(X)}} \\\\ &amp;= 2^{16 - log_2(X)} \\end{align*} \\] <p>Or \\(16 - log_2(X)\\) bits each. A block would have \\(16 + log_2(X)\\) bit mask. Since the bit mask may not be an integer due to the log, we need to take the ceiling of the log. This is to ensure there are enough \"groups\" of blocks for X.</p> <p>TLDR: Each subnet has \\(16 - Y\\) bits, where \\(2^Y \\geq X &gt; 2^{Y-1}\\)</p>"},{"location":"notes/networking/dns/","title":"DNS Concepts","text":"<p>Some notes for myself as I familiarize myself with networking. I used Digital Ocean's informative article as a resource.</p>"},{"location":"notes/networking/dns/#terminology","title":"Terminology","text":"Domain Name System (DNS) A system that resolves human friendly names to addresses Domain Name Human friendly name that is associated to a resource. <p>Ex: <code>google.com</code></p> IP Address \"Network addressable location\". IP addresses must be unique within its network. IPv4 is the most common form of addresses, and is written with 4 sets of numbers, each having up to 3 digits. <p>192.198.1.10</p> Top Level Domain (TLD) The most general portion of the domain. <p>Ex: <code>com</code>, <code>org</code>, <code>io</code></p> <p>ICANN (Internet Corporation for Assigned Names and Numbers) give control to these TLD to specific parties, which then distributes domains under the TLD.</p> Hosts Computers/Services accessible through domain <p>Domain owners often expose their webserveres through their bare domain e.g. <code>google.com</code> and also through the host definition <code>www</code>, e.g. <code>www.google.com</code>. There can also be other host definitions, such as <code>api</code> (<code>api.google.com</code>) for API's or <code>files</code> (<code>files.google.com</code>) for ftp.</p> SubDomain A domain that is a part of a larger domain <p><code>google.com</code> is a subdomain of <code>com</code>.</p> <p>It looks similar to hosts, but <code>www.google.com</code> points to a resource/computer/service, and does not divide the <code>google.com</code> domain (which is what subdomains do).</p> Fully Qualified Domain Name Absolute domain name. Ends with a dot to indicate the root of the DNS heirarchy. <p><code>mail.google.com.</code></p> Name Server A computer that translates domain names to IP addresses. <p>Can be authorative, giving the answer to a domain they own. Else, they point to another server, serve cached, or other server's data.</p> Zone File A text file that holds the mappings between domain names and IP addresses. Stored in name servers, it defines resources for the subdomain (or where to go to see the definition) Records A single mapping between a resource and a name residing in a zone file. This can map a domain to an IP address, define the name server for a domain, etc. Root Servers The top servers of the DNS heirarchical structure. These are controlled by various organizations, delegated by ICANN. There are only a handful of these root servers, but are mirrored due to the high traffic flow to resolve names. Each mirror share the same IP address. These servers"},{"location":"notes/networking/rpc-vs-rest/","title":"RPC vs REST","text":"<p>My notes from Google's blog post on REST vs RPC.</p>"},{"location":"notes/networking/rpc-vs-rest/#rpc","title":"RPC","text":"Procedure a.k.a functions. Is the dominant construct for organizing computer code.  Remote Procedure Call (RPC) Is when a computer program causes a procedure (function, subroutine) to execute in a different address space. (This is usually on a different computer on a shared network). This procedure is coded as if it were a normal (local) procedure call, without the programmer explicitly coding the details for the remote interaction. <p>Here is an example of a RPC through HTTP:</p> <pre><code>POST /SendUserMessage HTTP/1.1\nHost: api.example.com\nContent-Type: application/json\n\n{\"userId\": 501, \"message\": \"Hello!\"}\n</code></pre> <p>All modern programming languages use procedures as their central programming construct to produce and consume APIs. Procedures therefore has been the dominant model for designing APIs (in the from of RPC's).</p> <p>Most times when developers are creating API's, it is because their application is implemented as many distributed components. API's are needed to communicate between these components to function. (Another reason is that a service is being used by multiple components).</p> <p>RPC's are often used because it prioritizes ease of programming for both clients and the server while being efficient. Making a RPC is syntatically the same as calling a normal function (as if it is was local), and learning the functions of a remote API is similar to learning a new programming library. RPC's are also usually efficient, the data passed between client and server usually being binary and encourages small messages.</p>"},{"location":"notes/networking/rpc-vs-rest/#so-why-not-rpc","title":"So Why Not RPC?","text":"<p>Two commons with software development:</p> <ol> <li>Difficult to change - a lot of (not new) products use legacy code and for a good reason - it is difficult to change. Usually due to assumptions made on the interface or behavior requires a lot of rework of the code. This often leads to the decision that it isn't worth modifying the software but rather using as it and implementing work arounds</li> <li>Difficult to integrate - A service's first implementation of API's usually serve the most basic functionality. However as it develops, there is value in supporting further integrations with other systems (for 3P integration, mobile support, etc). This is inherently hard because the service needs to provide the support with API's, and the integrating application/service needs to provide their own robust API's.</li> </ol>"},{"location":"notes/networking/rpc-vs-rest/#rest","title":"REST","text":"REpresentational State Transfer (REST) A model for API's. It is an architectural style that helped design HTTP (and the world wide web). It defines a set of constraints for how the architecture of an \"Internet-scale distributed hypermedia\" should behave. Hypertext Transfer Protocol (HTTP) An application layer protocol for \"distributed, collaborative, hypermedia information systems\". It is the foundation of data communication for the world wide web. <p>HTTP is the only commercially important REST API, so for simplicity's sake, we will focus on HTTP and not other REST implementations.</p> <p>The HTTP model is the inverse of the RPC model. In the RPC model, we are aware of procedures, while the entities are hidden behind these procedures. In the HTTP model, we are aware of the entities, while the behaviors of the system are hidden behind the entities (these are side-effects of the creation, update, deletion of these entities).</p> <p>Every address on the world wide web exposes the exact same API - HTTP. That means to navigate the web, we only need to learn a single API! This characteristic allowed the development of a web browser.</p> <p>There are some API's that claim to be RESTful but layer proprietary concepts on top of HTTP. They use HTTP as a lower level transport layer instead of using HTTP directly as designed. There's a lot of variability in how people use the term \"REST\" in the context of API's, it's hard to know what they mean unless you're familiar with them.</p> <p>There's a lot less to learn about API's that use HTTP than those API's that use RPC. RPC is basically learning a programming library, meaning you have to familiarize yourself with various signatures. API's that use HTTP is basically learning a database schema. You just have to learn the table name, columns, and what each means. That is considerably less learning than a programming library. An API that uses HTTP is mostly defined by its data model.</p> <p>What about querying data? HTTP doesn't itself provide the functionality beside the basic CRUD operations, so you may need to learn additional information on querying, but it is still less than RPCs. (Query syntax is usually simpler here.)</p> <p>An API that uses HTTP simply and directly, it will only need to document a couple of things:</p> <ol> <li>A limited number of fixed, well-known URLs. Analogous to table names</li> <li>The information model of each of its resource. Analogous to column names.</li> <li>An indication of the supported subset of HTTP (few APi's implement every feature of the protocol)</li> <li>(Optional) Some sort of query syntaqx that enables efficient access to resource data without retrieving the whole item.</li> </ol>"},{"location":"notes/networking/rpc-vs-rest/#why-http","title":"Why HTTP?","text":"<ol> <li>Ease of integration - An application only needs to know one API (HTTP). The data may be different across API's but the means of access is the same. One problem solved with this is management of resources across systems. HTTP provides a standard way of identifying a resource by URL (e.g. http://myapp.gapuchi.com/resource/id/7). This URL is uniquely across the web. RPC's provide identifiers that are unique to their system, meaning users need to define the identity such that it is unique outside of the application.</li> <li>Ease of change - RPC's are popular because of the ease of integration between applications - this also allows the assumptions on use-case or tech to flow from applications too. The introduction of HTTP/REST breaks that flow by forcing a translation from implementation procedures to entity models. This entity model should/is likely to be a conceptual representation of some part of the problem domain. How effective the API decouples the caller from the callee does depend on the skill of the design, but it does introduce some form of decoupling. The entity model usually goes under less changes compared to prodecures - more and more functionality gets added rather than the data itself being changed.</li> </ol>"},{"location":"notes/networking/rpc-vs-rest/#why-not-http","title":"Why Not HTTP?","text":"<p>Entity-based API's introduces cost in the form of design and implementation complexity and processing overhead. If efficiency is your first priority, RPC may be a better choice.</p> <p>It is easy to create an HTTP API that doesn't take advantage of HTTPs. Some mistakes could be:</p> <ol> <li>Using local ID's rather than URLS to encode references to entities. If clients need to substitute a variable in a URI template to form the URL, then it lost the benefit of HTTP uniform interface. The only common case for URI templates are for encoding queries.</li> <li>Putting version identifiers in all URls. If all your URLs include version identifiers, you are probably using local identifiers instead of URLs to represent relationships, which is the first mistake.</li> <li>Confusing identity with lookup. All entities have an immutable identity in the form of an URI. It is also a common to reference an entity by its mutable characteristics. It is important not to confuse an entity's own URI with alias URIs used to reference the same entity via a lookup on its name or other mutable characteristics.</li> </ol>"},{"location":"notes/networking/rpc-vs-rest/#so-what-to-choose","title":"So What To Choose?","text":"<p>Depends on priorities.</p> <p>If your goal is to enable communication between two different components that you own and control and processing efficiency is a major concern, then RPC is a good fit.</p> <p>If your goal is to make your software more malleable by breaking it down into components that are better isolated from each other's assumptions, or to open up your system for future integrations by other teams, then HTTP might be the move.</p>"},{"location":"notes/networking/rpc-vs-rest/#references","title":"References","text":"<ol> <li>https://cloud.google.com/blog/products/application-development/rest-vs-rpc-what-problems-are-you-trying-to-solve-with-your-apis</li> <li>https://www.smashingmagazine.com/2016/09/understanding-rest-and-rpc-for-http-apis/</li> <li>https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol</li> <li>https://en.wikipedia.org/wiki/Representational_state_transfer</li> <li>https://en.wikipedia.org/wiki/Remote_procedure_call</li> </ol>"},{"location":"notes/networking/ssh/","title":"SSH","text":"<p><code>ssh -f -N -L 8080:localhost:8080 foo.com</code></p> <ul> <li><code>-f</code> - background</li> <li><code>-N</code> - don't execute command on destination</li> <li><code>-L</code> - Port forwarding</li> </ul> <pre><code> -L [bind_address:]port:host:hostport\n        Specifies that connections to the given TCP port or Unix socket on the local (client) host are to be forwarded to the given host and port, or Unix socket, on the remote side.  This works by allocating a socket to listen to either a TCP port on the local side, optionally bound to the specified bind_address, or to a Unix socket.  Whenever a connection is made to the local port or socket, the connection is forwarded over the secure channel, and a connection is made to either host port hostport, or the Unix socket remote_socket, from the remote machine.\n\n        Port forwardings can also be specified in the configuration file.  Only the superuser can forward privileged ports.  IPv6 addresses can be specified by enclosing the address in square brackets.\n\n        By default, the local port is bound in accordance with the GatewayPorts setting.  However, an explicit bind_address may be used to bind the connection to a specific address.  The bind_address of ``localhost'' indicates that the listening port be bound for local use only, while an empty address or `*' indicates that the port should be available from all interfaces.\n</code></pre> <ul> <li>port - The port on the client.</li> <li>host - The host on the destination.</li> <li>hostport - The port on the destination.</li> </ul> <pre><code>// TODO Define host\n// TODO Define socket\n// TODO Define localhost in context of the command above\n</code></pre>"},{"location":"notes/rust/03.1-variables-mutability/","title":"Variable and Mutability","text":"<p><code>let</code> declares a variable. This is immutable by default. If you want to make it mutable, add <code>mut</code> keyword:</p> <pre><code>let x = 5;\nlet mut y = 6;\n\nx = 7; //Compile Error\ny = 7; //No error\n</code></pre> <p><code>const</code> creates a constant. This can never change, and must be set to a constant expression, not something that has to be determined at runtime.</p> <pre><code>const MAX_POINTS: u32 = 100_000;\n</code></pre> <p>Shadowing is when you declare a new variable with the same name as a previous one. (The first is shadowed by the second variable.) You shadow by using <code>let</code> repeatedly:</p> <pre><code>let x = 5;\nlet x = 7;\nlet x = \"howdy\";\n</code></pre> <p>This is different from <code>mut</code> because the latter doesn't use <code>let</code>, and because of this shadowing allows us to create the variable with a different type. This wouldn't work:</p> <pre><code>let mut x = 5;\nx = 7; //No error\nx = \"howdy\"; //Error\n</code></pre>"},{"location":"notes/rust/03.2-data-types/","title":"Data Types","text":"<p>Rust is statically typed, which means it knows all the types at compile time. The compiler can infer (usually) what type a variable is, but there are cases where it cannot.</p> <p>An example is parsing a string:</p> <pre><code>let guess: u32 = \"42\".parse().expect(\"Not a number!\");\n</code></pre> <p>Without the declared type, compiler will throw an error.</p>"},{"location":"notes/rust/03.2-data-types/#scalar-types","title":"Scalar Types","text":"<p>Scalar types represent a single value. Rust has four primary scalar types:</p> <ol> <li>integer</li> <li>floating point numbers</li> <li>boolean</li> <li>characters</li> </ol>"},{"location":"notes/rust/03.2-data-types/#compound-types","title":"Compound Types","text":"<p>Compound types can group multiple values into one type. Rust has two primary compound types:</p> <ol> <li>Tuple</li> <li>Array</li> </ol>"},{"location":"notes/rust/03.3-functions/","title":"Functions","text":"<ul> <li>Statement - instructions that perform some action and do not return a value.</li> <li>Expression - evaluate to a resulting value.</li> </ul> <p>This is a statement:</p> <pre><code>let x = 5;\n</code></pre> <p>This is an expression:</p> <pre><code>5\n</code></pre> <p>Statements do not return values. Therefore, you can\u2019t assign a let statement to another variable.</p> <pre><code>let x = (let y = 6); //Error\n</code></pre> <p>Calling a function is an expression (<code>hello()</code>), calling a macro is an expression (<code>println!(\"Guess the number!\")</code>), and the block used to create new scopes <code>{}</code> is an expression:</p> <pre><code>{\nlet x = 5;\nx - 2\n}\n</code></pre> <p>The above expression evaluates to <code>3</code>.</p> <p>Expressions do not include semi-colons. If you add a semi-colon, it becomes a statement and will not return a value.</p>"},{"location":"notes/rust/03.5-control-flow/","title":"Control Flow","text":""},{"location":"notes/rust/03.5-control-flow/#if-expressions","title":"<code>if</code> Expressions","text":"<p><code>if</code> statements are pretty common:</p> <pre><code>fn main() {\nlet number = 3;\n\nif number &lt; 5 {\nprintln!(\"condition was true\");\n} else {\nprintln!(\"condition was false\");\n}\n}\n</code></pre> <p>but in rust, they are expressions!</p> <pre><code>fn main() {\nlet condition = true;\nlet number = if condition { 5 } else { 6 };\n\nprintln!(\"The value of number is: {}\", number);\n}\n</code></pre>"},{"location":"notes/rust/03.5-control-flow/#loop","title":"<code>loop</code>","text":"<p><code>loop</code> runs code repeatedly until there is a command to break:</p> <pre><code>fn main() {\nlet mut counter = 0;\n\nlet result = loop {\ncounter += 1;\n\nif counter == 10 {\nbreak counter * 2;\n}\n};\n\nprintln!(\"The result is {}\", result);\n}\n</code></pre> <p>The <code>break</code> keyword can be followed by an expression that is returned from the loop. A <code>;</code> follows the <code>loop</code> block because it is a statement of assigning a variable.</p>"},{"location":"notes/rust/03.5-control-flow/#while","title":"<code>while</code>","text":"<p><code>while</code> loop is straighforward:</p> <pre><code>fn main() {\nlet mut number = 3;\n\nwhile number != 0 {\nprintln!(\"{}!\", number);\n\nnumber -= 1;\n}\n\nprintln!(\"LIFTOFF!!!\");\n}\n</code></pre>"},{"location":"notes/rust/03.5-control-flow/#for","title":"<code>for</code>","text":"<p><code>for</code> loop is straightforward:</p> <pre><code>fn main() {\nfor number in (1..4).rev() {\nprintln!(\"{}!\", number);\n}\nprintln!(\"LIFTOFF!!!\");\n}\n</code></pre>"},{"location":"notes/rust/04-ownership/","title":"Ownership","text":"<p>Ownership Rules:</p> <ol> <li>Each value in Rust has a variable called its owner.</li> <li>There can only be one owner at a time.</li> <li>When the owner goes out of scope, the value will be dropped.</li> </ol>"},{"location":"notes/rust/04-ownership/#variable-scope","title":"Variable Scope","text":"<pre><code>let s = \"hello\";\n</code></pre> <p>The variable is valid from the point at which it\u2019s declared until the end of the current scope.</p> <pre><code>{\n//s is invalid\nlet s = \"hello\"; //s is valid\n//s is valid\n} //end of scope, s is invalid\n</code></pre>"},{"location":"notes/rust/04-ownership/#the-string-type-an-example","title":"The <code>String</code> Type - An Example","text":"<p>The data types mentioned above are stored on the stack and are popped off when moved out of scope. Let's take a look at an example of something stored on the heap.</p> <p>There are string literals, but there are cases where we can't use a literal. Rust has <code>String</code> type for this case. We can create one from a literal:</p> <pre><code>let s = String::from(\"hello\");\n</code></pre> <p>Unlike literals, this can be mutated:</p> <pre><code>let mut s = String::from(\"hello\");\n\ns.push_str(\", world!\"); // push_str() appends a literal to a String\n\nprintln!(\"{}\", s); // This will print `hello, world!`\n</code></pre> <p>Why can this be mutated but not literals? This can be explained by how these are stored.</p>"},{"location":"notes/rust/04-ownership/#memory-and-allocation","title":"Memory and Allocation","text":"<p>With a string literal, we know the contents at compile time. The text is hardcoded directly into the final executable. We can do this because a literal is immuatable. We cannot allocate memory for each text that we do not know the size of, or those that might change.</p> <p>We need allocate memory on the heap to allow storage of unknown memory that may be changing. So</p> <ol> <li>The memory must be requested from the memory allocator at runtine.</li> <li>The memory needs to be returned to the allocator when we're done with the <code>String</code>.</li> </ol> <p><code>String::from</code> does the first part for us. (This basically happens for all languages).</p> <p>The second part is different. Rust doesn't have a garbage collector like other languages, that clean up for them. We need to do this ourselves.</p> <p>Well, \"by ourselves\" really means Rust. The memory is automatically returned once the variable that owns it goes out of scope.</p> <pre><code>fn main() {\n{\nlet s = String::from(\"hello\"); // s is valid from this point forward\n\n// do stuff with s\n}                                  // this scope is now over, and s is no longer valid\n}\n</code></pre> <p>When a variable goes out of scope, Rust calls a special function, <code>drop</code>. The author of <code>String</code> puts the code to return the memory in this method. Rust calls it automatically.</p>"},{"location":"notes/rust/04-ownership/#ways-variables-and-data-interact-move","title":"Ways Variables and Data Interact: Move","text":"<p>Multiple variables can interact with the same data:</p> <pre><code>let x = 5;\nlet y = x;\n</code></pre> <p><code>5</code> is bound to <code>x</code> and a copy is bound to <code>y</code>. This data is known and stored onto the stack.</p> <pre><code>fn main() {\nlet s1 = String::from(\"hello\");\nlet s2 = s1;\n}\n</code></pre> <p>In this case, <code>s1</code> isn't copied to <code>s2</code>, because it isn't stored on the stack.</p> <p>A <code>String</code> is made up of three things:</p> <ol> <li>A pointer to the memory that holds the content of the string</li> <li>Length</li> <li>Capacity</li> </ol> <p>These three are stored on the stack. The content of the string is stored on the heap. When we assign <code>s1</code> to <code>s2</code>, the <code>String</code> data is copied, meaning the pointer, length, and capacity are assigned to <code>s2</code>.</p> <p>When a variable goes out of scope, Rust calls <code>drop</code>. It is a bug to drop the same memory twice. This is called a double free error. Freeing memory twice can lead to memory corruption, which can potentially lead to security vulnerabilities. So what happens with <code>s1</code> and <code>s2</code>, since they both look at the same location in memory?</p> <p>Rust ensures memory safety by invalidating <code>s1</code>:</p> <pre><code>fn main() {\nlet s1 = String::from(\"hello\");\nlet s2 = s1;\n\nprintln!(\"{}, world!\", s1); //Error\n}\n</code></pre> <p>Instead of a shallow copy, where the pointer is copied, this is a move because <code>s1</code> is invalidated. <code>s1</code> was moved to <code>s2</code>. Rust will never automatically deep copy your data, as this is expensive.</p>"},{"location":"notes/rust/04-ownership/#ways-variables-and-data-interact-clone","title":"Ways Variables and Data Interact: Clone","text":"<p>If we want to do a deep copy, we can use a common method called clone:</p> <pre><code>fn main() {\nlet s1 = String::from(\"hello\");\nlet s2 = s1.clone();\n\nprintln!(\"s1 = {}, s2 = {}\", s1, s2);\n}\n</code></pre>"},{"location":"notes/rust/04-ownership/#stack-only-data-copy","title":"Stack-Only Data: Copy","text":"<p>You know what's weird:</p> <pre><code>fn main() {\nlet x = 5;\nlet y = x;\n\nprintln!(\"x = {}, y = {}\", x, y);\n}\n</code></pre> <p>The above doesn't error. Didn't <code>x</code> move to <code>y</code>? Well this these data types have known size at compile time and are stored on the stack, the copies are made quickly. No need to invalidate the previous variable. There is no such thing as a shallow copy because the actual value gets copied in the stack.</p> <p>Rust has a <code>Copy</code> trait that we can put on data types such as integers. If a type has a <code>Copy</code> trait, the older variable is still usable after reassignment. Rust won't let us annotate a type with <code>Copy</code> trait if the type or any part of it has implemented the <code>Drop</code> trait.</p>"},{"location":"notes/rust/04-ownership/#ownership-and-functions","title":"Ownership and Functions","text":"<p>Passing a value to the function similar is assigning:</p> <pre><code>fn main() {\nlet s = String::from(\"hello\");  // s comes into scope\n\ntakes_ownership(s);             // s's value moves into the function...\n// ... and so is no longer valid here\n\nlet x = 5;                      // x comes into scope\n\nmakes_copy(x);                  // x would move into the function,\n// but i32 is Copy, so it\u2019s okay to still\n// use x afterward\n\n} // Here, x goes out of scope, then s. But because s's value was moved, nothing\n// special happens.\n\nfn takes_ownership(some_string: String) { // some_string comes into scope\nprintln!(\"{}\", some_string);\n} // Here, some_string goes out of scope and `drop` is called. The backing\n// memory is freed.\n\nfn makes_copy(some_integer: i32) { // some_integer comes into scope\nprintln!(\"{}\", some_integer);\n} // Here, some_integer goes out of scope. Nothing special happens.\n</code></pre> <ul> <li><code>s</code> is moved to <code>some_string</code>. We cannot use <code>s</code> after this.</li> </ul>"},{"location":"notes/rust/04-ownership/#return-values-and-scope","title":"Return Values and Scope","text":"<pre><code>fn main() {\nlet s1 = gives_ownership();         // gives_ownership moves its return\n// value into s1\n\nlet s2 = String::from(\"hello\");     // s2 comes into scope\n\nlet s3 = takes_and_gives_back(s2);  // s2 is moved into\n// takes_and_gives_back, which also\n// moves its return value into s3\n} // Here, s3 goes out of scope and is dropped. s2 goes out of scope but was\n// moved, so nothing happens. s1 goes out of scope and is dropped.\n\nfn gives_ownership() -&gt; String {             // gives_ownership will move its\n// return value into the function\n// that calls it\n\nlet some_string = String::from(\"hello\"); // some_string comes into scope\n\nsome_string                              // some_string is returned and\n// moves out to the calling\n// function\n}\n\n// takes_and_gives_back will take a String and return one\nfn takes_and_gives_back(a_string: String) -&gt; String { // a_string comes into\n// scope\n\na_string  // a_string is returned and moves out to the calling function\n}\n</code></pre> <p>What if we want to let a function use a value but not take ownership? We can return the original variable back:</p> <pre><code>fn main() {\nlet s1 = String::from(\"hello\");\n\nlet (s2, len) = calculate_length(s1);\n\nprintln!(\"The length of '{}' is {}.\", s2, len);\n}\n\nfn calculate_length(s: String) -&gt; (String, usize) {\nlet length = s.len(); // len() returns the length of a String\n\n(s, length)\n}\n</code></pre> <p>It is extra code and an extra process. For these cases, Rust has a concept called references.</p>"},{"location":"notes/rust/04-ownership/#references-and-borrowing","title":"References and Borrowing","text":"<p>Here's how a function would take a parameter as a reference without taking ownership:</p> <pre><code>fn main() {\nlet s1 = String::from(\"hello\");\n\nlet len = calculate_length(&amp;s1);\n\nprintln!(\"The length of '{}' is {}.\", s1, len);\n}\n\nfn calculate_length(s: &amp;String) -&gt; usize {\ns.len()\n}\n</code></pre> <p>We pass <code>&amp;s1</code> to the function and the function definition takes <code>&amp;String</code>.</p> <p>The <code>&amp;</code> are references (and <code>*</code> is a dereference operator, more on that later).</p> <p><code>s: &amp;String</code> means that <code>s</code> is a reference to a String. Once it goes out of scope, the value it reference does not, because <code>s</code> doesn't own it.</p> <p>Having references as function parameters is called borrowing. Because the function doesn't own it, it cannot modify it.</p> <p>References are immutable, like variables are by default.</p>"},{"location":"notes/rust/04-ownership/#mutable-references","title":"Mutable References","text":"<p>To make a reference mutable, we have to:</p> <pre><code>fn main() {\nlet mut s = String::from(\"hello\");\n\nchange(&amp;mut s);\n}\n\nfn change(some_string: &amp;mut String) {\nsome_string.push_str(\", world\");\n}\n</code></pre> <p>Couple of things:</p> <ol> <li>Change <code>s</code> to be <code>mut</code></li> <li>Create mutable reference, <code>&amp;mut s</code></li> <li>Change the function to accept a mutable reference, <code>some_string: &amp;mut String</code></li> </ol> <p>You can have only one mutable reference to a particular piece of data:</p> <pre><code>fn main() {\nlet mut s = String::from(\"hello\");\n\nlet r1 = &amp;mut s;\nlet r2 = &amp;mut s; //Error\n\nprintln!(\"{}, {}\", r1, r2);\n}\n</code></pre> <p>This restriction prevents data races from occurring.</p> <p>We can use <code>{}</code> to create a new scope to allow multiple mutable references, just not at the same time:</p> <pre><code>fn main() {\nlet mut s = String::from(\"hello\");\n\n{\nlet r1 = &amp;mut s;\n} // r1 goes out of scope here, so we can make a new reference with no problems.\n\nlet r2 = &amp;mut s;\n}\n</code></pre> <p>You cannot combine mutable and immutable references:</p> <pre><code>fn main() {\nlet mut s = String::from(\"hello\");\n\nlet r1 = &amp;s;\nlet r2 = &amp;s;\nlet r3 = &amp;mut s; //Error\n\nprintln!(\"{}, {}, and {}\", r1, r2, r3);\n}\n</code></pre> <p>A reference's scope starts from where it is introduced to where it is last used.</p> <p>So this is fine:</p> <pre><code>fn main() {\nlet mut s = String::from(\"hello\");\n\nlet r1 = &amp;s; // no problem\nlet r2 = &amp;s; // no problem\nprintln!(\"{} and {}\", r1, r2);\n// r1 and r2 are no longer used after this point\n\nlet r3 = &amp;mut s; // no problem\nprintln!(\"{}\", r3);\n}\n</code></pre>"},{"location":"notes/rust/04-ownership/#to-summarize","title":"To Summarize","text":"<ol> <li>You can either have one mutable or any number of immutable references.</li> <li>References must always be valid.</li> </ol>"},{"location":"notes/rust/04-ownership/#the-slice-type","title":"The Slice Type","text":"<p>An example - Write a function that takes a string and returns the first word it finds in that string. If no word is found, then the whole string should be returned.</p> <p>The signature of the function:</p> <pre><code>fn first_word(s: &amp;String) -&gt; ?\n</code></pre> <p>We have one parameter that takes in a reference to a string. We do not want ownership, so that's fine. What do we return?</p> <p>One example is to return an index:</p> <pre><code>fn first_word(s: &amp;String) -&gt; usize {\nlet bytes = s.as_bytes(); //Convert a string into an array to check every element\n\nfor (i, &amp;item) in bytes.iter().enumerate() { //Create an iterator\nif item == b' ' { //Compare  to the byte literal space\nreturn i;\n}\n}\n\ns.len()\n}\n</code></pre> <p>The only problem here - the <code>usize</code> returned here only has meaning in the context of <code>&amp;String</code>. We have no guarantee that it will be valid in the future. Something could modify the <code>&amp;String</code>:</p> <pre><code>fn main() {\nlet mut s = String::from(\"hello world\");\n\nlet word = first_word(&amp;s); // word will get the value 5\n\ns.clear(); // this empties the String, making it equal to \"\"\n\n// word still has the value 5 here, but there's no more string that\n// we could meaningfully use the value 5 with. word is now totally invalid!\n}\n</code></pre> <p>This compiles without any issues. We need to worry about keeping <code>word</code> in sync with <code>s</code>. Plus if we decided to get the second word from the string, it becomes more complicated, having to return the start and end indices.</p> <p>The solution? String slices</p>"},{"location":"notes/rust/04-ownership/#string-slices","title":"String Slices","text":"<p>Slice references a sequence of elements in a collection, instead of a whole collection. It does not have ownership.</p> <p>A string slice is a reference to part of a <code>String</code></p> <pre><code>fn main() {\nlet s = String::from(\"hello world\");\n\nlet hello = &amp;s[0..5];\nlet world = &amp;s[6..11];\n}\n</code></pre> <p>With Rust's range syntax <code>..</code>, you can drop the value before the dots if you want to start at the 0 index. If you want to include the last byte, you can drop the value after <code>..</code>. The type that signifies \u201cstring slice\u201d is written as <code>&amp;str</code>.</p> <p>A function to find the first word:</p> <pre><code>fn first_word(s: &amp;String) -&gt; &amp;str {\nlet bytes = s.as_bytes();\n\nfor (i, &amp;item) in bytes.iter().enumerate() {\nif item == b' ' {\nreturn &amp;s[0..i];\n}\n}\n\n&amp;s[..]\n}\n</code></pre> <p>Rust compiler ensures that references to the string remain valid. So now this would error at compile time:</p> <pre><code>fn main() {\nlet mut s = String::from(\"hello world\");\n\nlet word = first_word(&amp;s);\n\ns.clear(); // error!\n\nprintln!(\"the first word is: {}\", word);\n}\n</code></pre> <p>Rust doesn't let you have a mutable reference if you already have an immutable reference. <code>clear</code> needs a mutable reference (because it is modifying the string), but we passed an immutable reference to <code>first_word</code>.</p>"},{"location":"notes/rust/04-ownership/#string-literals-are-slices","title":"String Literals Are Slices","text":"<pre><code>let s = \"Hello, world!\";\n</code></pre> <p>Recall string literals being stored inside the binary. The type of <code>s</code> here is <code>&amp;str</code>: it\u2019s a slice pointing to that specific point of the binary. This is also why string literals are immutable; <code>&amp;str</code> is an immutable reference.</p>"},{"location":"notes/rust/04-ownership/#string-slices-as-parameters","title":"String Slices as Parameters","text":"<p>One improvement to the signature:</p> <pre><code>fn first_word(s: &amp;String) -&gt; &amp;str {\n</code></pre> <p>can be written as:</p> <pre><code>fn first_word(s: &amp;str) -&gt; &amp;str {\n</code></pre> <p>This allows us to use the same function for <code>&amp;String</code> and <code>&amp;str</code>.</p> <p>If we have a string slice, we can pass it directly. If we have a string, we can pass a slice of the whole string.</p> <pre><code>fn main() {\nlet my_string = String::from(\"hello world\");\n\n// first_word works on slices of `String`s\nlet word = first_word(&amp;my_string[..]);\n\nlet my_string_literal = \"hello world\";\n\n// first_word works on slices of string literals\nlet word = first_word(&amp;my_string_literal[..]);\n\n// Because string literals *are* string slices already,\n// this works too, without the slice syntax!\nlet word = first_word(my_string_literal);\n}\n</code></pre>"},{"location":"notes/rust/04-ownership/#other-slices","title":"Other Slices","text":"<p>We can take a slice of arrays besides strings:</p> <pre><code>let a = [1, 2, 3, 4, 5];\nlet slice = &amp;a[1..3];\n</code></pre> <p>The slice has the type <code>&amp;[i32]</code>.</p>"},{"location":"notes/rust/05-structs/","title":"Using Structs to Structure Related Data","text":"<p>A struct is a custom data type. It is like an object's data attributes if you're thinking about object-oriented programming.</p>"},{"location":"notes/rust/05-structs/#defining-and-creating-structs","title":"Defining and Creating Structs","text":"<p>Structs are similar to tuples. They both can contain elements of different types. In struct, these elements are named. To define the struct:</p> <pre><code>struct User {\nusername: String, //This is a field\nemail: String,\nsign_in_count: u64,\nactive: bool,\n}\n</code></pre> <p>We create an instance of a struct by defining each of the fields.</p> <pre><code>let user1 = User {\nemail: String::from(\"someone@example.com\"),\nusername: String::from(\"someusername123\"),\nactive: true,\nsign_in_count: 1,\n};\n</code></pre> <p>The order doesn't matter, because the fields are named. (An advantage over tuples.)</p> <p>We can use dot notation to get specific attributes from a struct (<code>user1.email</code>). If this is mutable we can change it via this way of accessing:</p> <pre><code>user1.email = String::from(\"anotheremail@example.com\")\n</code></pre> <p>The entire struct must be mutable. We cannot mark specific fields as mutable.</p>"},{"location":"notes/rust/05-structs/#using-the-field-init-shorthand-when-variables-and-fields-have-the-same-name","title":"Using the Field Init Shorthand when Variables and Fields Have the Same Name","text":"<p>Let's say we have a function:</p> <pre><code>fn build_user(email: String, username: String) -&gt; User {\nUser {\nemail: email,\nusername: username,\nactive: true,\nsign_in_count: 1,\n}\n}\n</code></pre> <p>we can just simply have it to be:</p> <pre><code>fn build_user(email: String, username: String) -&gt; User {\nUser {\nemail,\nusername,\nactive: true,\nsign_in_count: 1,\n}\n}\n</code></pre>"},{"location":"notes/rust/05-structs/#creating-instances-from-other-instances-with-struct-update-syntax","title":"Creating Instances From Other Instances With Struct Update Syntax","text":"<p>There will be cases where we want to create a struct with most of an old struct's field with some changed. We can use the struct update syntax.</p> <p>Instead of:</p> <pre><code>let user2 = User {\nemail: String::from(\"another@example.com\"),\nusername: String::from(\"anotherusername567\"),\nactive: user1.active,\nsign_in_count: user1.sign_in_count,\n};\n</code></pre> <p>we can have:</p> <pre><code>let user2 = User {\nemail: String::from(\"another@example.com\"),\nusername: String::from(\"anotherusername567\"),\n..user1\n};\n</code></pre> <p>The <code>..</code> specifies that the remaining fields not set should have the same values as the fields in the given instance.</p>"},{"location":"notes/rust/05-structs/#using-tuple-structs-without-named-fields-to-create-different-types","title":"Using Tuple Structs without Named Fields to Create Different Types","text":"<p>You can define structs that look like tupes, called tupled structs. They do not have names associated to the fields, rather they types associated to the fields. This is useful when you want to give a tuple a meaning, and make it a different type from other tupes, where field names are redundant.</p> <pre><code>fn main() {\nstruct Color(i32, i32, i32);\nstruct Point(i32, i32, i32);\n\nlet black = Color(0, 0, 0);\nlet origin = Point(0, 0, 0);\n}\n</code></pre>"},{"location":"notes/rust/05-structs/#unit-like-structs-without-any-fields","title":"Unit-Like Structs Without Any Fields","text":"<p>You can have structs without any fields. This is useful for when you want to implement a trait that doesn't any data itself.</p>"},{"location":"notes/rust/05-structs/#ownership-of-struct-data","title":"Ownership of Struct Data","text":"<p>The examples above, the fields are owned by the struct. We can have structs with fields that are owned by something else, but to do so we need to use lifetimes. Lifetimes esnure that the data references by a struct is valid for as long as the struct is. This will be further explained later.</p>"},{"location":"notes/rust/05-structs/#an-example-program","title":"An Example Program","text":"<p>Example Programs</p>"},{"location":"notes/rust/05-structs/#method-syntax","title":"Method Syntax","text":""},{"location":"notes/rust/05-structs/#defining-methods","title":"Defining Methods","text":"<p>Let's modify the example in the previous section:</p> <pre><code>[derive(Debug)]\nstruct Rect {\nwidth: u32,\nheight: u32,\n}\n\nimpl Rect {\nfn area(&amp;self) -&gt; u32 {\nself.width * self.height\n}\n}\n\nfn main() {\nlet rect1 = Rect {\nwidth: 30,\nheight: 50,\n};\n\nprintln!(\n\"The area of the rectangle is {} square pixels.\",\nrect1.area()\n);\n}\n</code></pre> <p>To define the function within a context of <code>Rect</code>, we have to define an <code>impl</code> (implementation) block. We move the <code>area</code> function to this block and change the param to be <code>self</code>.</p> <p>We use <code>self</code> instead of <code>rect: &amp;Rect</code> because Rust knows the type for <code>&amp;self</code>. (We still need to pass in a reference because methods can take ownership, reference immutably, or reference mutably.)</p> <p>Having a method that takes ownership is rare. Usually we see this only when the method transforms <code>self</code> into something else and you want to prevent the caller from using the original.</p>"},{"location":"notes/rust/05-structs/#methods-with-more-parameters","title":"Methods with More Parameters","text":"<p>If you want to use more parameters:</p> <pre><code>impl Rect {\nfn area(&amp;self) -&gt; u32 {\nself.width * self.height\n}\n\nfn can_hold(&amp;self, other: &amp;Rectangle) -&gt; bool {\nself.width &gt; other.width &amp;&amp; self.height &gt; other.height\n}\n}\n</code></pre>"},{"location":"notes/rust/05-structs/#associated-functions","title":"Associated Functions","text":"<p>We can define functions that do not take in <code>self</code> in the <code>impl</code> block. These are called associated functions because they are associated with the struct. They are functions, not methods because they are not associated with an instance. <code>String::from</code> is an example.</p> <p>Associated functions are often used for constructors:</p> <pre><code>impl Rect {\nfn square(size: u32) -&gt; Rect {\nRect {\nwidth: size,\nheight: size,\n}\n}\n}\n</code></pre> <p>To call an associated function, we use <code>::</code> - <code>let sq = Rect::square(3);</code></p>"},{"location":"notes/rust/05-structs/#multiple-impl-blocks","title":"Multiple Impl Blocks","text":"<p>We have multiple <code>impl</code> blocks, and all will be considered. Not sure why we'd want to do this, but it is possible.</p>"},{"location":"notes/rust/06-enums/","title":"Enums and Pattern Matching","text":""},{"location":"notes/rust/06-enums/#defining-an-enum","title":"Defining an Enum","text":"<pre><code>enum IpAddrKind {\nV4,\nV6,\n}\n</code></pre>"},{"location":"notes/rust/06-enums/#enum-values","title":"Enum Values","text":"<p>We can create instances like this:</p> <pre><code>let four = IpAddrKind::V4;\nlet six = IpAddrKind::V6;\n</code></pre> <p>We can store additional data inside enums:</p> <pre><code>enum IpAddr {\nV4(String),\nV6(String),\n}\n\nlet home = IpAddr::V4(String::from(\"127.0.0.1\"));\n\nlet loopback = IpAddr::V6(String::from(\"::1\"));\n</code></pre> <p>One cool advantage, each instance can have different types of data associated with it:</p> <pre><code>enum IpAddr {\nV4(u8, u8, u8, u8),\nV6(String),\n}\n\nlet home = IpAddr::V4(127, 0, 0, 1);\n\nlet loopback = IpAddr::V6(String::from(\"::1\"));\n</code></pre> <p>There is a standard library for this!</p> <p>Another example of an enum with a wide variety of types in its variants:</p> <pre><code>enum Message {\nQuit,\nMove { x: i32, y: i32 },\nWrite(String),\nChangeColor(i32, i32, i32),\n}\n</code></pre> <ul> <li><code>Quit</code> has no data associated with it at all</li> <li><code>Move</code> has a struct associated with it</li> <li><code>Write</code> has a string.</li> <li><code>ChangeColor</code> has 3 <code>i32</code>.</li> </ul> <p>You can just create structs for the variants above, but they wouldn't be grouped together:</p> <pre><code>struct QuitMessage;\nstruct MoveMessage {\nx: i32,\ny: i32,\n}\nstruct WriteMessage(String);\nstruct ChangeColorMessage(i32, i32, i32);\n</code></pre> <p>but it's more annoying to create a function that takes these 4 types. With an enum, its a single type, <code>Message</code>.</p> <p>Another similarity - we can define methods on enums using <code>impl</code>.</p> <pre><code>impl Message {\nfn call(&amp;self) {\n//method\n}\n}\n\nlet m = Message::Write(String::from(\"hello\"))\nm.call()\n</code></pre>"},{"location":"notes/rust/06-enums/#the-option-enum-and-its-advantage-over-null-values","title":"The <code>Option</code> Enum and Its Advantage Over Null Values","text":"<p>Basically, the argument for <code>Option</code> in Scala. Rust has defined its own Option:</p> <pre><code>enum Option&lt;T&gt; {\nSome(T),\nNone,\n}\n</code></pre> <p><code>Option&lt;T&gt;</code> is an enum, and <code>Some(T)</code> and <code>None</code> are variants of the enum. (<code>&lt;T&gt;</code> is the syntax for generics. Later chapter.)</p>"},{"location":"notes/rust/06-enums/#the-match-control-flow-operator","title":"The <code>match</code> Control Flow Operator","text":"<p>Basically the <code>match</code> in Scala.</p> <pre><code>enum Coin {\nPenny,\nNickel,\nDime,\nQuarter,\n}\n\nfn value_in_cents(coin: Coin) -&gt; u8 {\nmatch coin {\nCoin::Penny =&gt; 1,\nCoin::Nickel =&gt; 5,\nCoin::Dime =&gt; 10,\nCoin::Quarter =&gt; 25,\n}\n}\n</code></pre>"},{"location":"notes/rust/06-enums/#pattern-that-bind-to-value","title":"Pattern that Bind to Value","text":"<p>We can extract values using <code>match</code>, kinda like how we can extract values from <code>case class</code>es in Scala.</p> <p>Let's say we have</p> <pre><code>enum UsState {\nAlabama,\nAlaska,\n// --snip--\n}\n\nenum Coin {\nPenny,\nNickel,\nDime,\nQuarter(UsState),\n}\n</code></pre> <p>We can extract the <code>UsState</code>:</p> <pre><code>fn value_in_cents(coin: Coin) -&gt; u8 {\nmatch coin {\nCoin::Penny =&gt; 1,\nCoin::Nickel =&gt; 5,\nCoin::Dime =&gt; 10,\nCoin::Quarter(state) =&gt; {\nprintln!(\"State quarter from {:?}!\", state);\n25\n}\n}\n}\n</code></pre>"},{"location":"notes/rust/06-enums/#matching-with-optiont","title":"Matching with <code>Option&lt;T&gt;</code>","text":"<pre><code>fn plus_one(x: Option&lt;i32&gt;) -&gt; Option&lt;i32&gt; {\nmatch x {\nNone =&gt; None,\nSome(i) =&gt; Some(i + 1),\n}\n}\n\nlet five = Some(5);\nlet six = plus_one(five);\nlet none = plus_one(None);\n</code></pre>"},{"location":"notes/rust/06-enums/#matches-are-exhaustive","title":"Matches Are Exhaustive","text":"<p>Unlike Scala, matches in Rust has to be exhaustive. There will be a compile error if it isn't:</p> <pre><code>fn plus_one(x: Option&lt;i32&gt;) -&gt; Option&lt;i32&gt; {\nmatch x {\nSome(i) =&gt; Some(i + 1),\n}\n} //Won't compile\n</code></pre>"},{"location":"notes/rust/06-enums/#the-_-placeholder","title":"The <code>_</code> Placeholder","text":"<p>Similar to Scala, <code>_</code> can be used as a catch all:</p> <pre><code>let some_u8_value = 0u8;\nmatch some_u8_value {\n1 =&gt; println!(\"one\"),\n3 =&gt; println!(\"three\"),\n5 =&gt; println!(\"five\"),\n7 =&gt; println!(\"seven\"),\n_ =&gt; (),\n}\n</code></pre>"},{"location":"notes/rust/06-enums/#concise-control-flow-with-if-let","title":"Concise Control Flow with <code>if let</code>","text":"<p>Rust combines <code>if</code> and <code>let</code> to allow a more concise way to handle values that match one pattern while ignoring the rest.</p> <p>For example, this is pretty wordy:</p> <pre><code>let some_value = Some(u08);\nmatch some_value {\ncase Some(3) =&gt; println!(\"triple\"),\n_ =&gt; (),\n}\n</code></pre> <p>We only care for <code>Some(3)</code>. We can use <code>if let</code>:</p> <pre><code>if let Some(3) = some_value {\nprintln!(\"triple\");\n}\n</code></pre> <p><code>if let</code> takes a pattern and an expression separated by an <code>=</code>.</p> <p>You can use <code>else</code> in addition:</p> <pre><code>let mut count = 0;\nif let Coin::Quarter(state) = coin {\nprintln!(\"State quarter from {:?}!\", state);\n} else {\ncount += 1;\n}\n</code></pre>"},{"location":"notes/rust/07-managing-projects/","title":"Managing Growing Projects with Packages, Crates, and Modules","text":"<ul> <li>So far we've written code in one module in one file.</li> <li>As code gets bigger, we can split our code into multiple modules and then in multiple files.</li> <li>Package contains multiple binary crater and optionally one library crate. (Why only one library? Idk).</li> <li>As your project grows, you can split code into different crates.</li> <li>This leads to the concept of scope. The context where code is written has a set of names that are defined as in scope. You can create scopes and change which names are in and out of the scope. You can't have two itesm with the same name in the same scope.</li> </ul> <p>Rust provides introduces various tools:</p> Packages A Cargo feature that lets you build, test, and share crates Crates A tree of modules that produces a library or executable Modules, use Lets you control the organization, scope, and privacy of paths Paths A way of naming an item, such as a struct, function, or module"},{"location":"notes/rust/07-managing-projects/#packages-and-crates","title":"Packages and Crates","text":"Crate A binary or library crate root A source file that the Rust compiler starts from and makes up the root module of your crate. Package One or more crates that provide a set of functionality. It contains a *Cargo.toml* file that explains how to build these crates. <p>A package:</p> <ol> <li>Must contain at least one crate (either a library crate or binary crate)</li> <li>Cannot contain more than one library crate</li> <li>Can contain as many binary crates as you want</li> </ol> <p>Let's create a new project:</p> <pre><code>~ $ cargo new my-new-project\n     Created binary (application) `my-new-project` package\n~ $ ls my-new-project \nCargo.toml src\n~ $ ls my-new-project/src\nmain.rs\n~ $ cat my-new-project/Cargo.toml [package]\nname = \"my-new-project\"\nversion = \"0.1.0\"\nauthors = [\"Spongebob Squarepants &lt;bob.sponge@krustykrab.com&gt;\"]\nedition = \"2018\"\n\nSee more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html\n\n[dependencies]\n~ $\n</code></pre> <p>Couple of things to note here:</p> <ol> <li>There is a Cargo.toml file, indicating that this is a package.</li> <li>Cargo.toml has no mention of <code>src/main.rs</code>. Cargo follows the convention of:<ul> <li><code>src/main.rs</code> - crate root of a binary crate with the same name as the package.</li> <li><code>src/lib.rs,</code> - crate root of a library crate with the same name as the package.</li> </ul> </li> <li>Cargo passes the crate root files to <code>rustc</code> to build the library or binary.</li> <li>This package only has <code>src/main.rs</code> so it only contains a binary crate named <code>my-project</code>.</li> <li>If the package contains both <code>src/main.rs</code> and <code>src/lib.rs</code>, it has two crates:<ol> <li>A binary crate named <code>my-project</code></li> <li>A library crate named <code>my-project</code></li> </ol> </li> <li>A package can have multiple binary crates by placing files under <code>src/bin</code>. Each file is a separate binary crate.</li> </ol> <p>A crate will group related functionality together in a scope so its easy to share among projects.</p> <p>For example, the <code>rand</code> crate provides the functionality of generating random numbers. We can use this by bringing <code>rand</code> crate into our project's scope. All functionality can be through the crate's name, <code>rand</code>.</p> <p>Keeping a crate's functionality in its own scope prevents conflicts. For example, <code>rand</code> provides a trait <code>Rng</code>. We can also create a struct <code>Rng</code> in our own crate. We can bring in <code>rand</code> as a dependency and the compiler wouldn't be confused on which <code>Rng</code> we're using. In our crate it refers to our struct <code>Rng</code>. If we wanted to use the one in <code>rand</code>, we'd access it by saying <code>rand::Rng</code>.</p>"},{"location":"notes/rust/07-managing-projects/#defining-modules-to-control-scope-and-privacy","title":"Defining Modules to Control Scope and Privacy","text":"<p>Modules let us organize code within a crate into groups for readability and easy reuse. It also controls privacy.</p> <p>Example, a module for restaurant functionality. We create <code>src/lib.rs</code> to create a library crate. Inside this class, we can define modules and functions:</p> <pre><code>// src/lib.rs\nmod front_of_house {\nmod hosting {\nfn add_to_waitlist() {}\n\nfn seat_at_table {}\n}\n\nmod serving {\nfn take_order() {}\n\nfn serve_order() {}\n\nfn take_payment() {}\n}\n}\n</code></pre> <p>We use <code>mod</code> keyword to define a module and use <code>{}</code> to define the mody of the module. </p> <p>Inside a module, we can define other modules and hold definitions for other items, such as structs, enums, constants, traits, or functions.</p> <p>You know how <code>src/lib.rs</code> and <code>src/main.rs</code> are called crate roots? This is because the contents of these files form the a module called <code>crate</code> that is at the root of the module tree.</p> <pre><code>crate\n\u2514\u2500\u2500 front_of_house\n\u251c\u2500\u2500 hosting\n\u2502   \u251c\u2500\u2500 add_to_waitlist\n\u2502   \u2514\u2500\u2500 seat_at_table\n\u2514\u2500\u2500 serving\n\u251c\u2500\u2500 take_order\n\u251c\u2500\u2500 serve_order\n\u2514\u2500\u2500 take_payment\n</code></pre> <p>Things to note:</p> <ol> <li><code>hosting</code> nests inside <code>front_of_house</code></li> <li><code>hosting</code> is siblings with <code>serving</code></li> <li><code>hosting</code> is the child of <code>front_of_house</code></li> <li><code>front_of_house</code> is the parent of <code>hosting</code></li> </ol>"},{"location":"notes/rust/07-managing-projects/#paths-for-referring-to-an-item-in-the-module-tree","title":"Paths for Referring to an Item in the Module Tree","text":"<p>We use paths to find an item in the module tree structure.</p> <p>A path can take two forms:</p> <ol> <li>Absolute path - starts from a crate root by using a crate name or a literal <code>crate</code></li> <li>Relative path - starts from the current module and uses <code>self</code>, <code>super</code>, or an identifier in the current module.</li> </ol> <p>The identifiers are separated by <code>::</code> in a path.</p> <p>So if we wanted to access <code>add_to_waitlist</code> from the root:</p> <pre><code>mod front_of_house { ... }\n\npub fn eat_at_restaurant() {\n//absolute path\ncrate::front_of_house::hosting::add_to_waitlist();\n\n//relative path\nfront_of_house::hosting::add_to_waitlist();\n}\n</code></pre> <p>This actually won't compile because <code>hosting</code> is private.</p> <ul> <li>Modules define privacy boundaries. All items are private by default.</li> <li>Parent modules cannot access private items inside child modules</li> <li>Child modules can access private items in their ancestor modules.<ul> <li>This is because child hides implementation from the parent, but the child is aware of the context they're defined in.</li> </ul> </li> <li>Use <code>pub</code> to make an item public.</li> </ul>"},{"location":"notes/rust/07-managing-projects/#exposing-paths-with-the-pub-keyword","title":"Exposing Paths with the pub Keyword","text":"<p>Let's make that function accessible:</p> <pre><code>mod front_of_house {\npub mod hosting {\npub fn add_to_waitlist() {}\n}\n}\n\npub fn eat_at_restaurant() {\n// Absolute path\ncrate::front_of_house::hosting::add_to_waitlist();\n\n// Relative path\nfront_of_house::hosting::add_to_waitlist();\n}\n</code></pre> <p>Note:</p> <ul> <li>We had to make both the <code>hosting</code> and <code>add_to_waitlist</code> public.</li> <li>We didn't have to make <code>front_of_house</code> public. <code>eat_at_restaurant</code> is siblings with <code>front_of_house</code> so it can access it.</li> </ul>"},{"location":"notes/rust/07-managing-projects/#starting-relative-paths-with-super","title":"Starting Relative Paths with <code>super</code>","text":"<p>tldr - use <code>super</code> to up one module when using relative paths.</p>"},{"location":"notes/rust/07-managing-projects/#making-structs-and-enums-public","title":"Making Structs and Enums Public","text":"<p>We use <code>pub</code> to make structs and enum public. Things to note:</p> <ol> <li>Marking a struct public doesn't make the fields public. We have to mark whichever fields we want to be public with <code>pub</code> as well.</li> <li>If a struct has private fields, it needs a public associated function that constructs an instance of the struct.<ol> <li>Otherwise we can't create an instance outside of the module. (Is this required if we don't want to access it outside of the module? My guess is it is because why else would we mark the struct as <code>pub</code>?)</li> </ol> </li> </ol> <pre><code>mod back_of_house {\npub struct Breakfast {\npub toast: String,\nseasonal_fruit: String,\n}\n\nimpl Breakfast {\npub fn summer(toast: &amp;str) -&gt; Breakfast {\nBreakfast {\ntoast: String::from(toast),\nseasonal_fruit: String::from(\"peaches\"),\n}\n}\n}\n}\n\npub fn eat_at_restaurant() {\n// Order a breakfast in the summer with Rye toast\nlet mut meal = back_of_house::Breakfast::summer(\"Rye\");\n// Change our mind about what bread we'd like\nmeal.toast = String::from(\"Wheat\");\nprintln!(\"I'd like {} toast please\", meal.toast);\n\n// The next line won't compile if we uncomment it; we're not allowed\n// to see or modify the seasonal fruit that comes with the meal\n// meal.seasonal_fruit = String::from(\"blueberries\");\n}\n</code></pre> <ol> <li>Marking an enum public makes all its variants public. You only need to mark the enum as <code>pub</code>.</li> </ol> <pre><code>mod back_of_house {\npub enum Appetizer {\nSoup,\nSalad,\n}\n}\n\npub fn eat_at_restaurant() {\nlet order1 = back_of_house::Appetizer::Soup;\nlet order2 = back_of_house::Appetizer::Salad;\n}\n</code></pre>"},{"location":"notes/rust/07-managing-projects/#bringing-paths-into-scope-with-the-use-keyword","title":"Bringing Paths into Scope with the <code>use</code> Keyword","text":"<p>Instead of declaring the whole path each time we want to use an item, we can bring the path into scope with <code>use</code>.</p> <pre><code>mod front_of_house {\npub mod hosting {\npub fn add_to_waitlist() {}\n}\n}\n\nuse crate::front_of_house::hosting;\n\npub fn eat_at_restaurant() {\nhosting::add_to_waitlist();\nhosting::add_to_waitlist();\nhosting::add_to_waitlist();\n}\n</code></pre> <p>With this, <code>hosting</code> can be treated as if it was defined in the scope</p> <p>You can also use with relative paths.</p>"},{"location":"notes/rust/07-managing-projects/#creating-idiomatic-use-paths","title":"Creating Idiomatic use Paths","text":"<p>Why not specify the <code>use</code> path all the way to <code>add_to_waitlist</code>? This is possible, but the idiomatic way is to bring the module into scope, not the function. This way we can make it apparent that the function isn't defined in the scope.</p> <p>The idiomatic way to bring in strucst, enums, and other items is to use the full path. Weird right?</p> <p>There really isn't a reason, just the convention that formed.</p> <p>The only limitation is that we can't bring two items with the same name into the same scope:</p> <pre><code>use std::fmt;\nuse std::io;\n\nfn function1() -&gt; fmt::Result {\n// --snip--\nOk(())\n}\n\nfn function2() -&gt; io::Result&lt;()&gt; {\n// --snip--\nOk(())\n}\n}\n</code></pre> <p>We clarify <code>Result</code> by using the <code>fmt</code> or <code>io</code> module. We couldn't do </p> <pre><code>use std::fmt::Result;\nuse std::io::Result;\n</code></pre> <p>because Rust wouldn't know which one to use if we were to refer to <code>Result</code>.</p>"},{"location":"notes/rust/07-managing-projects/#providing-new-names-with-the-as-keyword","title":"Providing New Names with the as Keyword","text":"<p>A work around to bring in items with the same name is to rename an item with <code>as</code> keyworkd:</p> <pre><code>use std::fmt::Result;\nuse std::io::Result as IoResult;\n</code></pre>"},{"location":"notes/rust/07-managing-projects/#re-exporting-names-with-pub-use","title":"Re-exporting Names with pub use","text":"<ul> <li><code>use</code> brings a name into the scope, but the name is private</li> <li>If we want to allow external code to access this name in given module, we can slap on a <code>pub</code> in front of <code>use</code></li> </ul> <pre><code>mod front_of_house {\npub mod hosting {\npub fn add_to_waitlist() {}\n}\n}\n\npub use crate::front_of_house::hosting;\n\npub fn eat_at_restaurant() {\nhosting::add_to_waitlist();\nhosting::add_to_waitlist();\nhosting::add_to_waitlist();\n}\n</code></pre> <p>Things to note:</p> <ol> <li>External code can call <code>add_to_waitlist</code> by <code>hosting::add_to_waitlist</code>.</li> <li>External code cannot call <code>add_to_waitlist</code> because <code>front_of_house</code> is not public.</li> </ol> When to use? The internal structure of your code differs from how users would think about the domain. (e.g. users wouldn't not distinguish \"back of house\" and \"front of house\")"},{"location":"notes/rust/07-managing-projects/#using-external-packages","title":"Using External Packages","text":"<p>To use (for example) <code>rand</code> package, we add this line to Cargo.toml:</p> <pre><code>[dependencies]\nrand = \"0.0.5\"\n</code></pre> <p>then to bring <code>rand</code> into scope, we add a <code>use</code> line:</p> <pre><code>use rand::Rng; //Starts with the crate name (rand) and then followed by the item/module etc.\n</code></pre> <p><code>std</code> (standard library) is an external package that is shipped with Rust, so we do not neet to declare it as a dependency, but we do need to declare a <code>use</code> statement if we want to use something from it.</p>"},{"location":"notes/rust/07-managing-projects/#using-nested-paths-to-clean-up-large-use-lists","title":"Using Nested Paths to Clean Up Large <code>use</code> Lists","text":"<pre><code>use std::cmp::Ordering;\nuse std::io;\n</code></pre> <p>can be simplified to:</p> <pre><code>use std::{cmp::Ordering, io};\n</code></pre> <p>and</p> <pre><code>use std::io;\nuse std::io::Write;\n</code></pre> <p>can be simplified to:</p> <pre><code>use std::io::{self, Write};\n</code></pre>"},{"location":"notes/rust/07-managing-projects/#glob-operator","title":"Glob Operator","text":"<p>If we want to bring in all public items in a path, use <code>*</code> (the glob operator):</p> <pre><code>use std::collections::*;\n</code></pre>"},{"location":"notes/rust/07-managing-projects/#separating-modules-into-different-files","title":"Separating Modules into Different Files","text":"<p>We want to split modules into different files when it gets too big.</p> <p>Let's move <code>front_of_house</code> into its own file. We create <code>src/front_of_house.rs</code>:</p> <pre><code>pub mod hosting {\npub fn add_to_waitlist() {}\n}\n</code></pre> <p>and change <code>src/lib.rs</code> to be:</p> <pre><code>mod front_of_house; //The semi-colon instead of a body tells Rust to load the contents from another file with the same name as the module.\n\npub use crate::front_of_house::hosting;\n\npub fn eat_at_restaurant() {\nhosting::add_to_waitlist();\nhosting::add_to_waitlist();\nhosting::add_to_waitlist();\n}\n</code></pre> <p>Let's extract <code>hosting</code> to its own file:</p> <pre><code>// src/front_of_house.rs\npub mod hosting;\n</code></pre> <p>and we create <code>src/front_of_house/hosting.rs</code>:</p> <pre><code>pub fn add_to_waitlist() {}\n</code></pre> <p>A way to think about the structure is to look at the path: <code>crate::front_of_housing::hosting</code> can be converted to <code>src/front_of_housing/hosting.rs</code>.</p>"},{"location":"notes/rust/09-error-handling/","title":"Error Handling","text":"<p>In many occasions, Rust requires you to acknowledge the possibility of an error and take some action before your code will compile.</p> <p>Rust groups errors into 2 main categories:</p> <ol> <li>recoverable - errors you can report to the user and retry the operation</li> <li>unrecoverable - usually bugs. (e.g. index out of bounds)</li> </ol> <p>Rust doesn't have exceptions. It has the type <code>Result&lt;T, E&gt;</code> for recoverable errors and the <code>panic!</code> macro that stops execution when the program encounters an unrecoverable error.</p>"},{"location":"notes/rust/09-error-handling/#unrecoverable-errors-with-panic","title":"Unrecoverable Errors with <code>panic!</code>","text":"<p>When the <code>panic!</code> macro executes, your program will print a failure message, unwind and clean up the stack, and then quit.</p> <p>By default, when a panic occurs, the programs starts unwinding - Rust walks back up the stack and cleans up the data from each funciton it encounters. This is a a lot of work. An alternative is to immediately abort - which ends the program without cleaning it up. The memory that the program uses will need to be cleaned up by the operating system. If you need the binary to be as small as possible, you can switch from unwinding to aborting upon a panic by adding <code>panic = 'abort'</code> to the apporiate <code>[profile]</code> sections. <pre><code>[profile.release]\npanic = 'abort'\n</code></pre></p> <p>An example of <code>panic!</code></p> <pre><code>fn main() {\npanic!(\"crash and burn\");\n}\n</code></pre> <p>The error message will print the location of the <code>panic</code>.</p> <pre><code>$ cargo run\n   Compiling panic v0.1.0 (file:///projects/panic)\n    Finished dev [unoptimized + debuginfo] target(s) in 0.25s\n     Running `target/debug/panic`\nthread 'main' panicked at 'crash and burn', src/main.rs:2:5\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.\n</code></pre>"},{"location":"notes/rust/09-error-handling/#using-a-panic-backtrace","title":"Using a <code>panic!</code> Backtrace","text":"<p>Let's take a look at an example where we do not throw the <code>panic</code>.</p> <pre><code>fn main() {\nlet v = vec![1, 2, 3];\n\nv[99];\n}\n</code></pre> <p>This is essentially an index out of bounds exception in Java.</p> <pre><code>$ cargo run\n   Compiling panic v0.1.0 (file:///projects/panic)\n    Finished dev [unoptimized + debuginfo] target(s) in 0.27s\n     Running `target/debug/panic`\nthread 'main' panicked at 'index out of bounds: the len is 3 but the index is 99', /rustc/5e1a799842ba6ed4a57e91f7ab9435947482f7d8/src/libcore/slice/mod.rs:2806:10\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.\n</code></pre> <p>The location in the error message points to a file that we don't own. This is because the implementation of the vector is throwing the panic.</p> <p>How do we get the stacktrace (or backtrace)? The last line tells us.</p> <p>A backtrace is a list of all the functions that hav ebeen caleed to get to this point.</p> <p>If we set the environment variable, we can view this:</p> <pre><code>thread 'main' panicked at 'index out of bounds: the len is 3 but the index is 99', main.rs:4:5\nstack backtrace:\n   0: _rust_begin_unwind\n   1: core::panicking::panic_fmt\n   2: core::panicking::panic_bounds_check\n   3: &lt;usize as core::slice::SliceIndex&lt;[T]&gt;&gt;::index\n   4: core::slice::&lt;impl core::ops::index::Index&lt;I&gt; for [T]&gt;::index\n   5: &lt;alloc::vec::Vec&lt;T&gt; as core::ops::index::Index&lt;I&gt;&gt;::index\n   6: main::main\n   7: core::ops::function::FnOnce::call_once\nnote: Some details are omitted, run with `RUST_BACKTRACE=full` for a verbose backtrace.\n</code></pre>"},{"location":"notes/rust/09-error-handling/#recoverable-errors-with-result","title":"Recoverable Errors with <code>Result</code>","text":"<p>All errors do not need a program to stop completely.</p> <p><code>Result</code> is an enum is defined as having two variants:</p> <pre><code>enum Result&lt;T, E&gt; {\nOk(T),\nErr(E),\n}\n</code></pre> <p><code>T</code> and <code>E</code> are generics, representing the type for a success and error, respectively.</p> <p>An example of a function that results in a possible failure.</p> <pre><code>use std::fs::File;\n\nfn main() {\nlet f = File::open(\"hello.txt\");\n}\n</code></pre> <p>We know this returns a <code>Result</code> by looking at the the API documentation or asking the compiler.</p> <p>Looking at the API we know that <code>File::open</code> returns <code>std::io::Result&lt;std::fs::File&gt;</code>. Not what we expect? If we look at the defintion of <code>std::io::Result</code>, we learn that is is the same as <code>std::result::Result&lt;std::fs::File, std::io::Error&gt;</code>.</p> <p>So if <code>File::open</code> succeeds, the result will have <code>File</code>, else <code>Error</code>.</p> <p>We can then handle each case:</p> <pre><code>use std::fs::File;\n\nfn main() {\nlet f = File::open(\"hello.txt\");\n\nlet f = match f {\nOk(file) =&gt; file,\nErr(error) =&gt; panic!(\"Problem opening the file: {:?}\", error),\n};\n}\n</code></pre> <p>Note that, like the <code>Option</code> enum, the <code>Result</code> enum and its variants have been brought into scope by the prelude, so we don\u2019t need to specify <code>Result::</code> before the <code>Ok</code> and <code>Err</code> variants in the match arms.</p>"},{"location":"notes/rust/09-error-handling/#matching-on-different-errors","title":"Matching on Different Errors","text":"<p>We may not want to <code>panic!</code> for every failure. Let's say we want to create a file if the file doesn't exist and <code>panic!</code> for other cases, like permission issue.</p> <pre><code>use std::fs::File;\nuse std::io::ErrorKind;\n\nfn main() {\nlet f = File::open(\"hello.txt\");\n\nlet f = match f {\nOk(file) =&gt; file,\nErr(error) =&gt; match error.kind() {\nErrorKind::NotFound =&gt; match File::create(\"hello.txt\") {\nOk(fc) =&gt; fc,\nErr(e) =&gt; panic!(\"Problem creating the file: {:?}\", e),\n},\nother_error =&gt; {\npanic!(\"Problem opening the file: {:?}\", other_error)\n}\n},\n};\n}\n</code></pre> <p><code>std::io::Error</code> has a kind method, which returns <code>ErrorKind</code>, an enum containing variants representing the different kinds of errors that might result from an <code>io</code> operation.</p> <p>The above matches on <code>NotFound</code>, meaning we didn't find the file.</p> <p>That is a lot of <code>match</code> - we'll learn about closures that will allow us to make this more concise:</p> <pre><code>use std::fs::File;\nuse std::io::ErrorKind;\n\nfn main() {\nlet f = File::open(\"hello.txt\").unwrap_or_else(|error| {\nif error.kind() == ErrorKind::NotFound {\nFile::create(\"hello.txt\").unwrap_or_else(|error| {\npanic!(\"Problem creating the file: {:?}\", error);\n})\n} else {\npanic!(\"Problem opening the file: {:?}\", error);\n}\n});\n}\n</code></pre> <p>(This may not make complete sense until we get to closures.) <code>unwrap_or_else</code> and other methods will help us get rid of nested <code>match</code> expressions when handling errors.</p>"},{"location":"notes/rust/09-error-handling/#shortcuts-for-panic-on-error-unwrap-and-expect","title":"Shortcuts for Panic on Error: <code>unwrap</code> and <code>expect</code>","text":"<p><code>match</code> is fine and dandy, but it gets verbose. There are helper methods to define various tasks.</p> <p><code>unwrap</code> is a shortcut method that is implemented just like the <code>match</code> above. It will return the value inside <code>Ok</code> or <code>panic!</code> for <code>Err</code>:</p> <pre><code>use std::fs::File;\n\nfn main() {\nlet f = File::open(\"hello.txt\").unwrap();\n}\n</code></pre> <p>If we run this with a <code>hello.txt</code> file:</p> <pre><code>thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Os { code: 2, kind: NotFound, message: \"No such file or directory\" }', main.rs:4:37\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n</code></pre> <p><code>expect</code> is similar to <code>unwrap</code>, but it also let's us choose the <code>panic!</code> error message:</p> <pre><code>use std::fs::File;\n\nfn main() {\nlet f = File::open(\"hello.txt\").expect(\"Failed to open hello.txt\");\n}\n</code></pre> <p>The error we see on running:</p> <pre><code>thread 'main' panicked at 'Failed to open hello.txt: Os { code: 2, kind: NotFound, message: \"No such file or directory\" }', main.rs:4:37\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n</code></pre> <p>This allows us to give meaningful error messages.</p>"},{"location":"notes/rust/09-error-handling/#propagating-errors","title":"Propagating Errors","text":"<p>Sometimes, you want to handle the error outside of the function. This gives the callers of the function more control.</p> <pre><code>use std::fs::File;\nuse std::io;\nuse std::io::Read;\n\nfn read_username_from_file() -&gt; Result&lt;String, io::Error&gt; {\nlet f = File::open(\"hello.txt\");\n\nlet mut f = match f {\nOk(file) =&gt; file,\nErr(e) =&gt; return Err(e),\n};\n\nlet mut s = String::new();\n\nmatch f.read_to_string(&amp;mut s) {\nOk(_) =&gt; Ok(s),\nErr(e) =&gt; Err(e),\n}\n}\n</code></pre> <p>(This method can be done in a shorter way, we'll get to that.)</p> <p>This method will return the file string on success, but an error if it fails in either opening the file or reading the file. Both errors are covered by the return type.</p> <p>We propagate the errors because we do not know the context of reading a file. Do people want a default string if the reading failed? Do we want to <code>panic!</code>? Who knows. We let the callers of the function decide this.</p> <p>The concept of propagating is so common that Rust provides the <code>?</code> operator to make it easier.</p>"},{"location":"notes/rust/09-error-handling/#a-shortcut-for-propagating-erros-the-operator","title":"A Shortcut for Propagating Erros: the <code>?</code> Operator","text":"<p>Below is the same implementation as our previous example:</p> <pre><code>use std::fs::File;\nuse std::io;\nuse std::io::Read;\n\nfn read_username_from_file() -&gt; Result&lt;String, io::Error&gt; {\nlet mut f = File::open(\"hello.txt\")?;\nlet mut s = String::new();\nf.read_to_string(&amp;mut s)?;\nOk(s)\n}\n</code></pre> <p>What placing <code>?</code> after <code>Result</code> does:</p> <ul> <li>If the value of <code>Result</code> is an <code>Ok</code>, the value inside <code>Ok</code> will get returned from this expression.</li> <li>If the value of <code>Result</code> is an <code>Err</code>, the <code>Err</code> will be returned from the whole function as if we can used the <code>return</code> keyword.</li> </ul> <p>One main difference from using <code>?</code> and the previous <code>match</code> expressions - the errors that have <code>?</code> called on them go through the <code>from</code> function defined in the<code>From</code> trait, which converts errors from one type into another.</p> <p>The returned error type is converted to the error type defined in the return type of the current function. This is useful when a function returns one error type to represent all the ways a function can fail, even if specific parts fails for different reasons. As long as the error types define the <code>from</code> function to convert itself to the returned error type, the <code>?</code> operator handles that conversion.</p> <p>This helps us get rid of a lot of boilerplate code. We can simplify it even more by chaining:</p> <pre><code>use std::fs::File;\nuse std::io;\nuse std::io::Read;\n\nfn read_username_from_file() -&gt; Result&lt;String, io::Error&gt; {\nlet mut s = String::new();\nFile::open(\"hello.txt\")?.read_to_string(&amp;mut s)?;\nOk(s)\n}\n</code></pre> <p>This example is fairly common, so Rust provides an even more convenient way to implement this:</p> <pre><code>use std::fs;\nuse std::io;\n\nfn read_username_from_file() -&gt; Result&lt;String, io::Error&gt; {\nfs::read_to_string(\"hello.txt\")\n}\n</code></pre> <p>Rust provides a <code>fs::read_to_string</code> function that creates a new <code>String</code>, read the contents of a file, puts it into the <code>String</code>, and returns it. (This didn't give us the chance of explaining the error handling obviously so we didn't go with this as our working example.)</p>"},{"location":"notes/rust/09-error-handling/#the-operator-can-be-used-in-functions-that-return-result","title":"The <code>?</code> Operator Can Be Used in Functions That Return <code>Result</code>","text":"<p>The <code>?</code> operator can be used in functions that have a return type of <code>Result</code>. This is because the <code>?</code> operator works in the same way as the <code>match</code> expression - specifically <code>return Err(e)</code> logic. Therefore, the function using <code>?</code> must define <code>Err</code> as a return type to be compatible.</p> <p>Because of this, the following will fail:</p> <pre><code>use std::fs::File;\n\nfn main() {\nlet f = File::open(\"hello.txt\")?;\n}\n</code></pre> <p>with an error message containing:</p> <pre><code>the `?` operator can only be used in an async function that returns `Result` or `Option` (or another type that implements `std::ops::Try`)\n</code></pre> <p>If you encounter this error, you either need to change the return type of the function or handle the <code>Result</code> in another way.</p> <p>The <code>main</code> method is special and has restrictions on what the return type must be. One return type that is valid is <code>()</code> and another is <code>Result&lt;T,E&gt;</code>:</p> <pre><code>use std::error::Error;\nuse std::fs::File;\n\nfn main() -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {\nlet f = File::open(\"hello.txt\")?;\n\nOk(())\n}\n</code></pre> <p>The <code>Box&lt;dyn Error&gt;</code> type is called a trait object. We'll talk more about that later. Basically it just means \"any kind of error\".</p>"},{"location":"notes/rust/09-error-handling/#to-panic-or-not-to-panic","title":"To <code>panic!</code> or Not To <code>panic!</code>","text":"<p>If you call <code>panic!</code>, you're making the decision on behalf of the code calling your code that a situation is unrecoverable, regardless of context. If you choose to return <code>Result</code>, you are giving the calling code options rather than making the decision for them. They can choose to <code>panic!</code> themselves, or handle the <code>Err</code>, or to propagate the <code>Err</code>. Any case, it provides flexibility. Returning <code>Result</code> is a good default choice.</p> <p>There are rare situations where <code>panic!</code> is more appropriate.</p> <p>(To Be Continued)</p>"},{"location":"notes/rust/10-generics/","title":"Generic Types, Traits, and Lifetimes","text":"<p>For the sake of conciseness, I'm not explaining generics here. It is the same concept as in Java. This section will include Rust specific syntax and behaviors.</p>"},{"location":"notes/rust/10-generics/#generic-data-types","title":"Generic Data Types","text":""},{"location":"notes/rust/10-generics/#in-function-definitions","title":"In Function Definitions","text":"<pre><code>fn largest&lt;T&gt;(list: &amp;[T]) -&gt; &amp;T {\nlet mut largest = &amp;list[0];\n\nfor item in list {\nif item &gt; largest {\nlargest = item;\n}\n}\n\nlargest\n}\n\nfn main() {\nlet number_list = vec![34, 50, 25, 100, 65];\n\nlet result = largest(&amp;number_list);\nprintln!(\"The largest number is {}\", result);\n\nlet char_list = vec!['y', 'm', 'a', 'q'];\n\nlet result = largest(&amp;char_list);\nprintln!(\"The largest char is {}\", result);\n}\n</code></pre> <ul> <li><code>fn largest&lt;T&gt;</code> - declares a function called <code>largest</code> that has a generic type, <code>T</code>. </li> <li><code>(list: &amp;[T])</code> - states the method takes in a parameter that is a slice type with the contents of the slice being of type <code>T</code></li> <li><code>-&gt; &amp;T</code> - declares the funtion returns a reference to a <code>T</code> type</li> </ul> <p>This won't compile because there is no guarantee that <code>T</code> has a <code>&gt;</code> method implemented:</p> <pre><code>$ cargo run\n   Compiling chapter10 v0.1.0 (file:///projects/chapter10)\nerror[E0369]: binary operation `&gt;` cannot be applied to type `T`\n --&gt; src/main.rs:5:17\n  |\n5 |         if item &gt; largest {\n  |            ---- ^ ------- T\n  |            |\n  |            T\n  |\n  = note: `T` might need a bound for `std::cmp::PartialOrd`\n\nerror: aborting due to previous error\n\nFor more information about this error, try `rustc --explain E0369`.\nerror: could not compile `chapter10`.\n\nTo learn more, run the command again with --verbose.\n</code></pre> <p>We'll need to use a trait, which we'll get to in a moment.</p>"},{"location":"notes/rust/10-generics/#in-struct-definitions","title":"In Struct Definitions","text":"<p>We can also define structs using generics:</p> <pre><code>struct Point&lt;T&gt; {\nx: T,\ny: T,\n}\n\nfn main() {\nlet integer = Point { x: 5, y: 10 };\nlet float = Point { x: 1.0, y: 4.0 };\n}\n</code></pre>"},{"location":"notes/rust/10-generics/#in-enum-definitions","title":"In Enum Definitions","text":"<p>We can also define enums using generics:</p> <pre><code>enum Result&lt;T, E&gt; {\nOk(T),\nErr(E),\n}\n</code></pre> <p>We say that \"<code>Struct</code> is generic over two types, <code>T</code> and <code>E</code>\".</p>"},{"location":"notes/rust/10-generics/#in-method-definitions","title":"In Method Definitions","text":"<pre><code>struct Point&lt;T&gt; {\nx: T,\ny: T,\n}\n\nimpl&lt;T&gt; Point&lt;T&gt; {\nfn x(&amp;self) -&gt; &amp;T {\n&amp;self.x\n}\n}\n</code></pre> <p>We have to declare <code>&lt;T&gt;</code> after <code>impl</code> so we can say we're defining a method for a generic type. You could also define methods for a specific type:</p> <pre><code>impl Point&lt;f32&gt; {\nfn distance_from_origin(&amp;self) -&gt; f32 {\n(self.x.powi(2) + self.y.powi(2)).sqrt()\n}\n}\n</code></pre> <p>The generics used in a struct doesn't necessarily match those used in the struct's method signatures:</p> <pre><code>struct Point&lt;T, U&gt; {\nx: T,\ny: U,\n}\n\nimpl&lt;T, U&gt; Point&lt;T, U&gt; {\nfn mixup&lt;V, W&gt;(self, other: Point&lt;V, W&gt;) -&gt; Point&lt;T, W&gt; {\nPoint {\nx: self.x,\ny: other.y,\n}\n}\n}\n</code></pre>"},{"location":"notes/rust/10-generics/#performance-of-code-using-generics","title":"Performance of Code Using Generics","text":"<p>Rust implements generics in a way that your code doesn't run any slower using generics types than it would using concrete types.</p> <p>It achieves this by performing monomorphization at compile type. </p> <p>Monomorphization - process of turning generic code into specific code by filling in the concrete types that are used when compiled.</p> <p>Let's take a look at an example with the <code>Option</code> enum:</p> <pre><code>let integer = Some(5);\nlet float = Some(5.0);\n</code></pre> <p>The compiler would see that the <code>Option</code> enum is being used for two types: <code>i32</code> and <code>f64</code>. It expands the definition of <code>Option&lt;T&gt;</code> into <code>Option_i32</code> and <code>Option_f64</code>.</p> <p>The compiled code will look like this, with <code>Option&lt;T&gt;</code> replaced:</p> <pre><code>enum Option_i32 {\nSome(i32),\nNone,\n}\n\nenum Option_f64 {\nSome(f64),\nNone,\n}\n\nfn main() {\nlet integer = Option_i32::Some(5);\nlet float = Option_f64::Some(5.0);\n}\n</code></pre>"},{"location":"notes/rust/10-generics/#traits-defining-shared-behavior","title":"Traits: Defining Shared Behavior","text":"<p>Trait - tells the Rust compiler about a functionality that a type has that can be shared with other types.</p> <p>We use traits to define shared behavior in an abstract way. We can use trait bounds to specific that a generic can be any type that has a certain behavior.</p> <p>This is basically interfaces in Java, with some caveats.</p>"},{"location":"notes/rust/10-generics/#defining-a-trait","title":"Defining a Trait","text":"<p>A type\u2019s behavior consists of the methods we can call on that type. Different types share the same behavior if we can call the same methods on all of those types. Trait definitions are a way to group method signatures together to define a set of behaviors necessary to accomplish some purpose.</p> <pre><code>pub trait Summary {\nfn summarize(&amp;self) -&gt; String;\n}\n</code></pre> <p>The methods have <code>;</code> at the end because the definition/implementation of the method will be defined by the types that implement this trait.</p>"},{"location":"notes/rust/10-generics/#implementing-a-trait-on-a-type","title":"Implementing a Trait on a Type","text":"<p>Implementing a trait on a type is similar to implementing regular methonds. The main difference is after <code>impl</code>, we put the trait name, then use the <code>for</code> keyword, and then specify the name of the type you want to implement the trait for.</p> <pre><code>pub struct NewsArticle {\npub headline: String,\npub location: String,\npub author: String,\npub content: String,\n}\n\nimpl Summary for NewsArticle {\nfn summarize(&amp;self) -&gt; String {\nformat!(\"{}, by {} ({})\", self.headline, self.author, self.location)\n}\n}\n\npub struct Tweet {\npub username: String,\npub content: String,\npub reply: bool,\npub retweet: bool,\n}\n\nimpl Summary for Tweet {\nfn summarize(&amp;self) -&gt; String {\nformat!(\"{}: {}\", self.username, self.content)\n}\n}\n</code></pre> <p>We can then use <code>summarize</code> as if it was defined in the type:</p> <pre><code>let tweet = Tweet {\nusername: String::from(\"horse_ebooks\"),\ncontent: String::from(\n\"of course, as you probably already know, people\",\n),\nreply: false,\nretweet: false,\n};\n\nprintln!(\"1 new tweet: {}\", tweet.summarize());\n</code></pre> <p>We can only implement a trait on a type only if either the trait or the type is local to our crate.</p> <ul> <li>We can implement <code>Display</code> (from the standard library) for <code>Tweet</code>.</li> <li>We can implement <code>Summary</code> for <code>Vec&lt;T&gt;</code>.</li> <li>We cannot implement <code>Display</code> for <code>Vec&lt;T&gt;</code>.</li> </ul> <p>We can't do the third because of coherence, or more specifically the orphan rule (the parent type is not present). This rule is to ensure no one else breaks your code and vice versa. Without this rule, two crates can create an implementation for the same type and Rust wouldn't know what to do.</p>"},{"location":"notes/rust/10-generics/#default-implementations","title":"Default Implementations","text":"<pre><code>pub trait Summary {\nfn summarize(&amp;self) -&gt; String {\nString::from(\"(Read more...)\")\n}\n}\n</code></pre> <p>Rather than a <code>;</code>, we can define the methods in the trait for a default implementation.</p>"},{"location":"notes/rust/10-generics/#traits-as-parameter","title":"Traits as Parameter","text":"<p>We can use traits to define functions:</p> <pre><code>pub fn notify(item: &amp;impl Summary) {\nprintln!(\"Breaking news! {}\", item.summarize());\n}\n</code></pre>"},{"location":"notes/rust/10-generics/#trait-bound-syntax","title":"Trait Bound Syntax","text":"<p>This is a syntatical sugar for trait bound syntax. The below is equivalent:</p> <pre><code>pub fn notify&lt;T: Summary&gt;(item: &amp;T) {\nprintln!(\"Breaking news! {}\", item.summarize());\n}\n</code></pre> <p>The former way is a more concise way, but the latter can express more complicated functions.</p> <p>If we had a function that took in two <code>Summary</code> data types, it would like this:</p> <pre><code>pub fn notify(item1: &amp;impl Summary, item2: &amp;impl Summary) {\n</code></pre> <p>We can pass in an implementation of summary to the first and second.</p> <p>If we wanted to make sure that both arguments are of the same type (that implements <code>Summary</code>), we need to do:</p> <pre><code>pub fn notify&lt;T: Summary&gt;(item1: &amp;T, item2: &amp;T) {\n</code></pre> <p>This ensures that both are of the same type (but implements <code>Summary</code>).</p>"},{"location":"notes/rust/10-generics/#specifying-multiple-trait-bounds-with-the-syntax","title":"Specifying Multiple Trait Bounds with the <code>+</code> Syntax","text":"<pre><code>pub fn notify(item: &amp;(impl Summary + Display)) {\n</code></pre> <p>or </p> <pre><code>pub fn notify&lt;T: Summary + Display&gt;(item: &amp;T) {\n</code></pre>"},{"location":"notes/rust/10-generics/#clearer-trait-bounds-with-where-clauses","title":"Clearer Trait Bounds with <code>where</code> Clauses","text":"<p>A function with multiple generics, each with their own trait bounds, can get pretty verbose and hard to read:</p> <pre><code>fn some_function&lt;T: Display + Clone, U: Clone + Debug&gt;(t: &amp;T, u: &amp;U) -&gt; i32 {\n</code></pre> <p>Instead, Rust has the keyword <code>where</code>:</p> <pre><code>fn some_function&lt;T, U&gt;(t: &amp;T, u: &amp;U) -&gt; i32\n    where T: Display + Clone,\nU: Clone + Debug\n{\n</code></pre> <p>This makes the signature less cluttered, and human readable in a way.</p>"},{"location":"notes/rust/10-generics/#returning-types-that-implement-traits","title":"Returning Types that Implement Traits","text":"<p>We can also use the <code>impl Trait</code> syntax as a return type:</p> <pre><code>fn returns_summarizable() -&gt; impl Summary {\n    Tweet {\n        username: String::from(\"horse_ebooks\"),\n        content: String::from(\n            \"of course, as you probably already know, people\",\n        ),\n        reply: false,\n        retweet: false,\n    }\n}\n</code></pre> <p>This syntax only allows one type to be returned. The following would return an error at compile time:</p> <pre><code>fn returns_summarizable(switch: bool) -&gt; impl Summary {\nif switch {\nNewsArticle {\nheadline: String::from(\n\"Penguins win the Stanley Cup Championship!\",\n),\nlocation: String::from(\"Pittsburgh, PA, USA\"),\nauthor: String::from(\"Iceburgh\"),\ncontent: String::from(\n\"The Pittsburgh Penguins once again are the best \\\n                 hockey team in the NHL.\",\n),\n}\n} else {\nTweet {\nusername: String::from(\"horse_ebooks\"),\ncontent: String::from(\n\"of course, as you probably already know, people\",\n),\nreply: false,\nretweet: false,\n}\n}\n}   </code></pre> <p><code>NewsArticle</code> and <code>Tweet</code> both implement <code>Summary</code> but the function can only return one of these, due to limitation of the compiler. We will get to how we can make this work later.</p>"},{"location":"notes/rust/10-generics/#fixing-the-largest-function-with-trait-bounds","title":"Fixing the largest Function with Trait Bounds","text":"<p>Let's revisit our <code>largest</code> function:</p> <pre><code>fn largest&lt;T&gt;(list: &amp;[T]) -&gt; &amp;T {\nlet mut largest = &amp;list[0];\n\nfor item in list {\nif item &gt; largest {\nlargest = item;\n}\n}\n\nlargest\n}\n</code></pre> <p>We can add a trait bound to allow the use of <code>&gt;</code>:</p> <pre><code>fn largest&lt;T: PartialOrd&gt;(list: &amp;[T]) -&gt; T {\nlet mut largest = list[0];\n\nfor &amp;item in list {\nif item &gt; largest {\nlargest = item;\n}\n}\n\nlargest\n}\n</code></pre> <p>but another issue arises:</p> <pre><code>$ cargo run\n   Compiling chapter10 v0.1.0 (file:///projects/chapter10)\nerror[E0508]: cannot move out of type `[T]`, a non-copy slice\n --&gt; src/main.rs:2:23\n  |\n2 |     let mut largest = list[0];\n  |                       ^^^^^^^\n  |                       |\n  |                       cannot move out of here\n  |                       move occurs because `list[_]` has type `T`, which does not implement the `Copy` trait\n  |                       help: consider borrowing here: `&amp;list[0]`\n\nerror[E0507]: cannot move out of a shared reference\n --&gt; src/main.rs:4:18\n  |\n4 |     for &amp;item in list {\n  |         -----    ^^^^\n  |         ||\n  |         |data moved here\n  |         |move occurs because `item` has type `T`, which does not implement the `Copy` trait\n  |         help: consider removing the `&amp;`: `item`\n\nerror: aborting due to 2 previous errors\n\nSome errors have detailed explanations: E0507, E0508.\nFor more information about an error, try `rustc --explain E0507`.\nerror: could not compile `chapter10`.\n\nTo learn more, run the command again with --verbose.\n</code></pre> <p>Data types stored on the stack implement a <code>Copy</code> trait, which allows us to move <code>list[0]</code> into <code>largest</code>. With generics, we do not know if the data type implements this trait.</p> <p>Quick fix is to add another bound trait:</p> <pre><code>fn largest&lt;T: PartialOrd + Copy&gt;(list: &amp;[T]) -&gt; T {\nlet mut largest = list[0];\n\nfor &amp;item in list {\nif item &gt; largest {\nlargest = item;\n}\n}\n\nlargest\n}\n</code></pre> <p>Other approaches:</p> <ul> <li>If we don't want to limit to <code>Copy</code> we can have it bound by <code>Clone</code>, and then clone the element in the logic. We would potentially be making more heap allocations in this case.</li> </ul> <pre><code>fn largest&lt;T: PartialOrd + Clone&gt;(list: &amp;[T]) -&gt; T {\nlet mut largest = list[0].clone();\n\nfor item in list {\nif item &gt; &amp;largest {\nlargest = item.clone();\n}\n}\n\nlargest\n}\n</code></pre> <ul> <li>We can implement <code>largest</code> to return a reference to <code>T</code> value. We do not need <code>Clone</code> or <code>Copy</code> in this case.</li> </ul> <pre><code>fn largest&lt;T: PartialOrd&gt;(list: &amp;[T]) -&gt; &amp;T {\nlet mut largest = &amp;list[0];\n\nfor item in list.iter() {\nif item &gt; largest {\nlargest = &amp;item;\n}\n}\n\nlargest\n}\n</code></pre>"},{"location":"notes/rust/10-generics/#using-trait-bounds-to-conditionally-implement-methods","title":"Using Trait Bounds to Conditionally Implement Methods","text":"<p>We can conditionally create methods on types using trait bounds on <code>impl</code> blocks.</p> <pre><code>use std::fmt::Display;\n\nstruct Pair&lt;T&gt; {\nx: T,\ny: T,\n}\n\nimpl&lt;T&gt; Pair&lt;T&gt; {\nfn new(x: T, y: T) -&gt; Self {\nSelf { x, y }\n}\n}\n\nimpl&lt;T: Display + PartialOrd&gt; Pair&lt;T&gt; {\nfn cmp_display(&amp;self) {\nif self.x &gt;= self.y {\nprintln!(\"The largest member is x = {}\", self.x);\n} else {\nprintln!(\"The largest member is y = {}\", self.y);\n}\n}\n}\n</code></pre> <p>Here we define <code>new</code> for all <code>Pair&lt;T&gt;</code>, but define <code>cmp_display</code> only for <code>Pair&lt;T&gt;</code> where <code>T</code> implements <code>Display</code> and <code>PartialOrd</code>.</p> <p>We can also conditionally implement a trait for any type that implements another trait. This is called blanket implementations.</p> <p>These are used a lot in the Rust library. An example - implementing the <code>ToString</code> trait for types that implement <code>Display</code> trait.</p> <pre><code>impl&lt;T: Display&gt; ToString for T {\n// --snip--\n}\n</code></pre> <p>Because the standard library has this blanket implementation, we can call <code>to_string</code> on any type that implements the <code>Display</code> trait.</p> <p>Blanket implementations appear in the documentation for the trait in the \u201cImplementors\u201d section.</p>"},{"location":"notes/rust/10-generics/#validating-references-with-lifetimes","title":"Validating References with Lifetimes","text":"<p>Every reference has a lifetime - the scope for which that reference is valid.</p> <p>Most cases, the lifetime is inferred and implicit, just like how types are inferred most of the time. We need to annotate types when mutliple types are possible).</p> <p>Similar to this, Rust requires us to annotate lifetimes when the lifetimes of references could be related in more than one way.</p> <p>Rust requires us to annotate the relationships using generic lifetime parameters to ensure the references at runtime are valid.</p>"},{"location":"notes/rust/10-generics/#preventing-dangling-references-with-lifetimes","title":"Preventing Dangling References with Lifetimes","text":"<p>The main goal of lifetime is to prevent dangling references - which cause a program to reference data other than the data it was meant to reference:</p> <pre><code>{\nlet r;\n\n{\nlet x = 5;\nr = &amp;x;\n}\n\nprintln!(\"r: {}\", r);\n}\n</code></pre> <ul> <li>In the outer scope, we declare <code>r</code></li> <li>In the inner scope, we declare <code>x</code></li> <li>In the inner scope, we set <code>r</code> as a reference to <code>x</code></li> <li>Inner scope ends</li> <li>We print <code>r</code>.</li> </ul> <p>This won't compile because the value <code>r</code> is trying to reference has gone out of scope. <code>x</code> \"didn't live long enough\", since its scope ends in the inner scope. <code>r</code> is still valid for the outer scope, so \"it lives longer\".</p> <p>Rust uses a borrow checker to validate this.</p>"},{"location":"notes/rust/10-generics/#borrow-checker","title":"Borrow Checker","text":"<p>The borrow checker compares scopes to determine whether all borrows are valid.</p> <pre><code>{\nlet r;                // ---------+-- 'a\n//          |\n{                     //          |\nlet x = 5;        // -+-- 'b  |\nr = &amp;x;           //  |       |\n}                     // -+       |\n//          |\nprintln!(\"r: {}\", r); //          |\n}                         // ---------+\n</code></pre> <p>lifetime of r is annotated with <code>'a</code> and lifetime of x is annotated with <code>'b</code>. Rust compares the two lifetimes and sees that the reference lives longer than the subject of the reference.</p> <p>To fix this:</p> <pre><code>{\nlet x = 5;            // ----------+-- 'b\n//           |\nlet r = &amp;x;           // --+-- 'a  |\n//   |       |\nprintln!(\"r: {}\", r); //   |       |\n// --+       |\n}                         // ----------+\n</code></pre> <p>Here <code>r</code> can reference <code>x</code> because its lifetime is shorter.</p>"},{"location":"notes/rust/10-generics/#generic-lifetimes-in-functions","title":"Generic Lifetimes in Functions","text":"<p>Working example - write a function that returns the longer of two string slices. The function should take in two string slices and return a single string slice.</p> <pre><code>fn main() {\nlet string1 = String::from(\"abcd\");\nlet string2 = \"xyz\";\n\nlet result = longest(string1.as_str(), string2);\nprintln!(\"The longest string is {}\", result);\n}\n\nfn longest(x: &amp;str, y: &amp;str) -&gt; &amp;str {\nif x.len() &gt; y.len() {\nx\n} else {\ny\n}\n}\n</code></pre> <p>The compiler gives us an error:</p> <pre><code>$ cargo run\n   Compiling chapter10 v0.1.0 (file:///projects/chapter10)\nerror[E0106]: missing lifetime specifier\n --&gt; src/main.rs:9:33\n  |\n9 | fn longest(x: &amp;str, y: &amp;str) -&gt; &amp;str {\n  |                                 ^ expected lifetime parameter\n  |\n  = help: this function's return type contains a borrowed value, but the signature does not say whether it is borrowed from `x` or `y`\n\nerror: aborting due to previous error\n\nFor more information about this error, try `rustc --explain E0106`.\nerror: could not compile `chapter10`.\n\nTo learn more, run the command again with --verbose.\n</code></pre> <p>Rust cannot tell whether the reference being returned is <code>x</code> or <code>y</code>. We actually don't know either. The borrow checker cannot tell the concrete lifetimes of the parameters being passed in and the concrete lifetime being returned.</p> <p>To fix this error, we\u2019ll add generic lifetime parameters that define the relationship between the references so the borrow checker can perform its analysis.</p>"},{"location":"notes/rust/10-generics/#lifetime-annotation-syntax","title":"Lifetime Annotation Syntax","text":"<p>The lifetime annotation doesn't change the lifetime references.</p> <p>A function can accept a reference with any lifetime by specifying a generic lifetime parameter, just like functions can accept any type when the signature specifies a generic type parameter.</p> <p>Lifetime annotations describe the relationships of the lifetimes of multiple references to each other without affecting the lifetimes.</p> <p>The names of lifetime parameters must start with <code>'</code>, usually lowercase and very short. Most people uses <code>'a</code>. We place the lifetime parameter annotations after <code>&amp;</code>, with a space before the reference's type.</p> <p>Example:</p> <pre><code>&amp;i32        // a reference\n&amp;'a i32     // a reference with an explicit lifetime\n&amp;'a mut i32 // a mutable reference with an explicit lifetime\n</code></pre> <p>A single lifetime annotation doesn't have much meaning. The annotations are meant to tell Rust how lifetime annotation parameters of multiple references relate to each other.</p> <p>For example, in a function we can define two parameters with the same lifetime annotation parameter to indicate the two have the same lifetime.</p>"},{"location":"notes/rust/10-generics/#lifetime-annotations-in-function-signatures","title":"Lifetime Annotations in Function Signatures","text":"<p>Like with generic type parameters, we define generic lifetime parameters inside angle brackets between the function name and parameter list.</p> <pre><code>fn longest&lt;'a&gt;(x: &amp;'a str, y: &amp;'a str) -&gt; &amp;'a str {\nif x.len() &gt; y.len() {\nx\n} else {\ny\n}\n}\n</code></pre> <p>In the above example, we want the two parameters and the return type to all have the same lifetime, so we declare one lifetime annotation parameter and assign it to each of those.</p> <p>The function signature now tells Rust that for some lifetime <code>'a</code>, the function takes two parameters (both of which are string slices with a lifetime of at least as long as lifetime of <code>'a</code>).</p> <p>This means that the reference returned by the function is the same as the shorter of the two parameters' lifetimes.</p> <p>Setting the parameter to <code>'a</code> doesn't change the lifetime of any reference, rather the value of <code>'a</code> is determined by the references.</p> <p>When we pass the two concrete lifetimes of the references, the concrete lifetime that is substituted for <code>'a</code> is the scope of <code>x</code> that overlaps with the scope of <code>y</code> - aka it will be the shorter of the two lifetimes - aka it will be as long as both lifetimes are valid.</p> <p>Let's take a look at some examples:</p> <pre><code>fn main() {\nlet string1 = String::from(\"long string is long\");\n\n{\nlet string2 = String::from(\"xyz\");\nlet result = longest(string1.as_str(), string2.as_str());\nprintln!(\"The longest string is {}\", result);\n}\n}\n</code></pre> <p><code>string1</code> is valid until the end of the outer scope, <code>string2</code> is valid until the end of the inner scope. This means <code>result</code> is valid until the end of the inner scope.</p> <pre><code>fn main() {\nlet string1 = String::from(\"long string is long\");\nlet result;\n{\nlet string2 = String::from(\"xyz\");\nresult = longest(string1.as_str(), string2.as_str());\n}\nprintln!(\"The longest string is {}\", result);\n}\n</code></pre> <p>This fails compilation.</p> <pre><code>$ cargo run\n   Compiling chapter10 v0.1.0 (file:///projects/chapter10)\nerror[E0597]: `string2` does not live long enough\n --&gt; src/main.rs:6:44\n  |\n6 |         result = longest(string1.as_str(), string2.as_str());\n  |                                            ^^^^^^^ borrowed value does not live long enough\n7 |     }\n  |     - `string2` dropped here while still borrowed\n8 |     println!(\"The longest string is {}\", result);\n  |                                          ------ borrow later used here\n\nerror: aborting due to previous error\n\nFor more information about this error, try `rustc --explain E0597`.\nerror: could not compile `chapter10`.\n\nTo learn more, run the command again with --verbose.\n</code></pre> <p>Rust says <code>string2</code> didn't live long enough. It knows this because the function signature has generic lifetime annotation parameter among the parameters and return reference. It knows the lifetime of the returned reference is as long as <code>string2</code>, so it cannot use the reference outside the scope of <code>string2</code>.</p>"},{"location":"notes/rust/10-generics/#thinking-in-terms-of-lifetimes","title":"Thinking in Terms of Lifetimes","text":"<p>The way you need to specify lifetime parameters depends on your function.</p> <p>Example:</p> <pre><code>fn longest&lt;'a&gt;(x: &amp;'a str, y: &amp;str) -&gt; &amp;'a str {\nx\n}\n</code></pre> <p>We do not need an annotation on <code>y</code> because the lifetime of <code>y</code> has no relation with the lifetime of <code>x</code> or the return value.</p> <p>The lifetime parameter for the return type needs to match the lifetime parameter for one of the parameters when returning a reference from a function. If it didn't, that means it is referring to a value created in the function, meaning the value will become invalid outside of the function, making the compiler not happy.</p> <p>This won't compile. Even though we have a lifetime parameter on the return type, it isn't related to one of the parameters of the function. More importantly, it is a dangling reference, so the whole lifetime parameter issue is moot anyway:</p> <pre><code>fn longest&lt;'a&gt;(x: &amp;str, y: &amp;str) -&gt; &amp;'a str {\nlet result = String::from(\"really long string\");\nresult.as_str()\n}\n</code></pre> <p>Giving us this error message:</p> <pre><code>$ cargo run\n   Compiling chapter10 v0.1.0 (file:///projects/chapter10)\nerror[E0515]: cannot return value referencing local variable `result`\n  --&gt; src/main.rs:11:5\n   |\n11 |     result.as_str()\n   |     ------^^^^^^^^^\n   |     |\n   |     returns a value referencing data owned by the current function\n   |     `result` is borrowed here\n\nerror: aborting due to previous error\n\nFor more information about this error, try `rustc --explain E0515`.\nerror: could not compile `chapter10`.\n\nTo learn more, run the command again with --verbose.\n</code></pre>"},{"location":"notes/rust/10-generics/#lifetime-annotations-in-struct-definitions","title":"Lifetime Annotations in Struct Definitions","text":"<p>It is possible for structs to hold references, but we would need to add a lifetime annotation on every reference in the struct's definition.</p> <p>Quick refresher - why doesn't Rust have the lifetime to be equal to that of the struct?</p> <p>The struct has a reference to a value and doesn't own it. It doesn't control when it becomes out of scope.</p> <pre><code>struct ImportantExcerpt&lt;'a&gt; {\npart: &amp;'a str,\n}\n\nfn main() {\nlet novel = String::from(\"Call me Ishmael. Some years ago...\");\nlet first_sentence = novel.split('.').next().expect(\"Could not find a '.'\");\nlet i = ImportantExcerpt {\npart: first_sentence,\n};\n}\n</code></pre> <p>Here, <code>ImportantExcerpt</code> has a field that is a string slice. Note the angle brackets after the struct name. This annotation means an instance of <code>ImportantExcerpt</code> can\u2019t outlive the reference it holds in its part field.</p> <p>In the example above, <code>ImportantExcerpt</code> is created in scope after <code>novel</code> which is what provides the <code>part</code> field its value. The struct doesn't go out of scope after <code>novel</code>.</p>"},{"location":"notes/rust/10-generics/#lifetime-elision","title":"Lifetime Elision","text":"<p>The following method compiles without lifetime annotations:</p> <pre><code>fn first_word(s: &amp;str) -&gt; &amp;str {\nlet bytes = s.as_bytes();\n\nfor (i, &amp;item) in bytes.iter().enumerate() {\nif item == b' ' {\nreturn &amp;s[0..i];\n}\n}\n\n&amp;s[..]\n}\n</code></pre> <p>We expect the refernces to have lifetime annotations:</p> <pre><code>fn first_word&lt;'a&gt;(s: &amp;'a str) -&gt; &amp;'a str {\n</code></pre> <p>but this got super repetitive. The compiler was made to infer the lifetimes in these specific examples.</p> <p>Lifetime elision rules are these patterns programmed into Rust's analysis of references. If the compiler finds a specific pattern, we do not need to specify the lifetimes.</p> <p>The rules do not provide full inferences, though. If there are some references without a lifetime annotation after the elision rules are applied, the compiler will fail.</p> input lifetimes lifetimes on function/method parameters output lifetimes lifetiems on return values <p>The rules:</p> <ol> <li>Each parameter that is a reference gets its own lifetime annotation.</li> <li>If there is exactly one input lifetime parameter, that lifetime is assigned to all output lifetime parameters.</li> <li>If there are multiple input lifetime parameters, but one is <code>&amp;self</code> or <code>&amp;mut self</code> (indicating this is a method, not a function), the lifetime of <code>self</code> is assigned to all output lifetime parameters.</li> </ol> <p>Example 1</p> <p><code>fn first_word(s: &amp;str) -&gt; &amp;str {</code></p> <p><code>fn first_word&lt;'a&gt;(s: &amp;'a str) -&gt; &amp;str {    // Rule 1</code></p> <p><code>fn first_word&lt;'a&gt;(s: &amp;'a str) -&gt; &amp;'a str { // Rule 2</code></p> <p>The compiler stops, since all references have a lifetime.</p> <p>Example 2</p> <p><code>fn longest(x: &amp;str, y: &amp;str) -&gt; &amp;str {</code></p> <p><code>fn longest&lt;'a, 'b&gt;(x: &amp;'a str, y: &amp;'b str) -&gt; &amp;str { // Rule 1</code></p> <p>Rule 2 doesn't apply since there is more than 1 input lifetime parameter.</p> <p>Rule 3 doesn't apply since this is a function, not a method.</p> <p>Compiler fails, since we couldn't figure out the lifetimes of all the signature.</p>"},{"location":"notes/rust/10-generics/#lifetime-annotations-in-method-definitions","title":"Lifetime Annotations in Method Definitions","text":"<p>We implement methods on structs with lifetimes by using the same syntax as generics.</p> <p>TBD</p>"},{"location":"notes/rust/10-generics/#the-static-lifetime","title":"The Static Lifetime","text":"<p><code>'static</code> lifetime means the reference can live for the entire duration of the program.</p> <p>All string literals have the <code>'static</code> lifetimes.</p> <p>We can annotate strings like:</p> <pre><code>let s: &amp;'static str = \"I have a static lifetime.\";\n</code></pre> <p>The text of the string is stored in the binary, so it's always available.</p> <p>Double check if you really need static lifetime parameters....</p>"},{"location":"notes/rust/13-functional-features/","title":"Functional Features","text":""},{"location":"notes/rust/13-functional-features/#closures","title":"Closures","text":"Closures Anonymous functions that can be saved in a variable or passed into functions. <p>Closures, unlike functions, can capture values from the scope in which they're defined.</p> <pre><code>let x = |param1, param2| {\nprintln!(\"{}\", param2);\nparam1\n};\n</code></pre>"},{"location":"notes/rust/13-functional-features/#closure-type-inference-and-annotation","title":"Closure Type Inference and Annotation","text":"<p>Why isn't there type annotations in the closure above?</p> <p>Functions need type annotations on the parameters and the return values because they're part of an explicit interfaced exposed to your users. Rigidly defining the interface is important.</p> <p>Closures are not used in the exposed interface. They are stored in variables and used without naming them. They are relevant only in a small scope. The compiler is able to infer the type of the parameters and return value, just like it can infer most variables.</p> <p>We can type annotations if we want, but for the most part, they are redundant and not needed.</p> <p>Closures will have one concrete type inferred for each of their parameter and return value.</p> <p>This won't work:</p> <pre><code>fn main() {\nlet example_closure = |x| x;\n\nlet s = example_closure(String::from(\"hello\"));\nlet n = example_closure(5);\n}\n</code></pre> <p>because the closure was inferred to have type String from the first instance, and it fails when it encounters the second.</p>"},{"location":"notes/rust/13-functional-features/#storing-closures-using-generic-parameters-and-the-fn-trait","title":"Storing Closures Using Generic Parameters and the <code>Fn</code> Trait","text":"<p>In order to store a closure in a struct, we need to define the type. This is because struct requires to know the types of all its fields.</p> <p>Each closure has its own, unique anonymous type. Even if two closures have the same signature, they are still considered to have different types. So in order to use closures in functions, structs, or anywhere we need to define the type, we use generics and trait bounds.</p> <p>All closures implement one the following traits: <code>Fn</code>, <code>FnMut</code>, or <code>FnOnce</code>.</p> <p>We can add types to these trait bounds to represent the types of the parameters and return value.</p> <p>So for a closure that has a parameter type of <code>u32</code> and return type <code>u32</code>, the type for the closure would be <code>Fn(u32) -&gt; u32</code>.</p> <p>Functions can also implement these traits too. We can pass in functions in places that require these traits.</p>"},{"location":"notes/rust/13-functional-features/#capturing-the-environment-with-closures","title":"Capturing the Environment with Closures","text":"<p>Closures can do something functions can't - capture the environment and access variables from the scope in which they're defined.</p> <pre><code>fn main() {\nlet x = 4;\n\nlet equal_to_x = |z| z == x;\n\nlet y = 4;\n\nassert!(equal_to_x(y));\n}\n</code></pre> <p>We can't do the above with functions.</p> <p>A closure uses memory to store these variables for use in the closure body. Functions will never incur this overhead because they can't capture the environment.</p> <p>Closures can capture their environment, which maps to one of the traits it can implement:</p> <ol> <li><code>FnOnce</code> - Taking ownership - This method consumes variables it captures from the enclosing scope (the closure's environment). It needs to take the ownership of the variables and move them into the closure in order to consume them. It has <code>Once</code> in the name because the closure cannot take the ownership more than once for a variable, so it can only be called once.</li> <li><code>FnMut</code> - Borrows mutably.</li> <li><code>Fn</code> - Borrows immutably.</li> </ol> <p>Rust infers the trait a closure implements based on how variables from the environment are being used.</p> <p>All closures implement <code>FnOnce</code> since they can be called at least once. Closures that do not move the captured variable implement the <code>FnMut</code> trait. Closures that do not need mutable access also implement the <code>Fn</code> trait.</p> <p>You can force a closure to take ownership by using the <code>move</code> keyword before the param list.</p> <p>With move:</p> <pre><code>fn main() {\nlet x = vec![1, 2, 3];\n\nlet equal_to_x = move |z| z == x;\n\nprintln!(\"can't use x here: {:?}\", x);\n\nlet y = vec![1, 2, 3];\n\nassert!(equal_to_x(y));\n}\n</code></pre> <p><code>x</code> is now moved into the closure. The <code>println!</code> after will fail because x moved. It can be fixed by removing the <code>println!</code>.</p> <p><code>move</code> in the closure doesn't indicate anything specific to the param list it precedes. It is for the captures variables. May be a common misunderstanding due to its placement.</p> <p>Typically when defining functions, you can use <code>Fn</code> trait and the compiler will tell you if you need <code>FnMut</code> or <code>FnOnce</code>.</p>"},{"location":"notes/rust/13-functional-features/#iterators","title":"Iterators","text":"<p>In rust, iterators are lazy. You can use iterators in various ways, including a <code>for</code> loop:</p> <pre><code>let v1 = vec![1, 2, 3];\n\nlet v1_iter = v1.iter();\n\nfor val in v1_iter {\nprintln!(\"Got: {}\", val);\n}\n</code></pre> <p>Iterators abstract the logic of looping through an structure. E.g set an index to, perform an operation, increment index, and stop once there are no items left. This abstraction reduces the chances of errors performed by the user.</p>"},{"location":"notes/rust/13-functional-features/#the-iterator-trait-and-next-method","title":"The <code>Iterator</code> trait and <code>next</code> method","text":"<p>All iterators implement the <code>Iterator</code> trait, which is defined the standard library. Looks something like this:</p> <pre><code>pub trait Iterator {\ntype Item;\n\nfn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt;;\n\n// methods with default implementations elided\n}\n</code></pre> <p><code>type Item</code> defines an associated type for this trait.</p> <p>The trait has only one method, which returns one time wrapped in <code>Some</code> and <code>None</code> once the iterator is over.</p> <pre><code>#[test]\nfn iterator_demonstration() {\nlet v1 = vec![1, 2, 3];\n\nlet mut v1_iter = v1.iter();\n\nassert_eq!(v1_iter.next(), Some(&amp;1));\nassert_eq!(v1_iter.next(), Some(&amp;2));\nassert_eq!(v1_iter.next(), Some(&amp;3));\nassert_eq!(v1_iter.next(), None);\n}\n</code></pre> <p>Note We needed to make <code>v1_iter</code> mutable, because calling <code>next</code> on the iterator modifies the internal state of the iterator. (e.g. the tracking of the next item) The <code>for</code> loop didn't need to be mutable because the loop took ownership and made it immutable behind the scenes.</p> <p>The values returned by <code>next</code> are immutable references.</p> <ul> <li><code>iter</code> produces an iterator over immutable references.</li> <li><code>into_iter</code> produces an iterator that takes ownership of <code>v1</code> and returns owned values.</li> <li><code>iter_mut</code> produces an iterator over mutable references.</li> </ul>"},{"location":"notes/rust/13-functional-features/#methods-that-consume-the-iterator","title":"Methods that Consume the Iterator","text":"<p>The <code>Iterator</code> trait has some methods defined with it. (Check the documentation) Some of these method invokes the <code>next</code> method.</p> <p>These methods that invoke the <code>next</code> method are called consuming adaptors, since they \"consume\" the iterator.</p> <p>An example is <code>sum</code>:</p> <pre><code>let v1 = vec![1, 2, 3];\n\nlet v1_iter = v1.iter();\n\nlet total: i32 = v1_iter.sum();\n\nassert_eq!(total, 6);\n</code></pre> <p>The <code>sum</code> method repeatedly calls next and adds the valeus of the iterator. We can't use <code>v1_iter</code> after <code>sum</code> since it takes ownership of the iterator.</p>"},{"location":"notes/rust/13-functional-features/#methods-that-produce-other-iterators","title":"Methods that Produce Other Iterators","text":"<p>Some methods on the <code>Iterator</code> trait changes iterators into different types of iterators. These are called iterator adaptors. You can chain these methods to perform complicated computations. Since these are lazy, you have to call a consuming adaptor to get a result from the calls to the iterator adaptors.</p> <p>A common example, <code>map</code>:</p> <pre><code>let v1: Vec&lt;i32&gt; = vec![1, 2, 3];\n\nlet v2: Vec&lt;_&gt; = v1.iter().map(|x| x + 1).collect();\n\nassert_eq!(v2, vec![2, 3, 4]);\n</code></pre>"},{"location":"notes/rust/13-functional-features/#using-closure-that-capture-their-environment","title":"Using Closure that Capture Their Environment","text":"<p>The above <code>map</code> method takes in a closure. We can take advantage of closure's ability to capture their environment:</p> <pre><code>struct Shoe {\nsize: u32,\nstyle: String,\n}\n\nfn shoes_in_size(shoes: Vec&lt;Shoe&gt;, shoe_size: u32) -&gt; Vec&lt;Shoe&gt; {\nshoes.into_iter().filter(|s| s.size == shoe_size).collect()\n}\n</code></pre> <p>In the <code>shoes_in_size</code> function, we take the ownership of <code>shoes</code> by calling <code>into_iter</code> method and provide a closure to <code>filter</code> which captures the <code>shoe_size</code> from the environment.</p> <p>What if we used <code>iter</code> instead of <code>into_iter</code>?</p> <p>Compiling fails.</p> <pre><code>value of type `Vec&lt;Shoe&gt;` cannot be built from `std::iter::Iterator&lt;Item=&amp;Shoe&gt;`\n</code></pre> <p>This is because <code>iter</code> creates immutable references, so it returns an iterator of <code>&amp;Shoe</code>.</p>"},{"location":"notes/rust/13-functional-features/#creating-iterators-with-the-iterator-trait","title":"Creating Iterators with the <code>Iterator</code> Trait","text":"<p>We can create our own iterators by implementing the <code>Iterator</code> trait. We only need to implement <code>next</code> method, after which, you can use all the default methods of the <code>Iterator</code> trait.</p> <pre><code>struct Counter {\ncount: u32,\n}\n\nimpl Counter {\nfn new() -&gt; Counter {\nCounter { count: 0 }\n}\n}\n\nimpl Iterator for Counter {\ntype Item = u32;\n\nfn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; {\nif self.count &lt; 5 {\nself.count += 1;\nSome(self.count)\n} else {\nNone\n}\n}\n}\n</code></pre>"},{"location":"notes/rust/15-smart-pointers/","title":"Smart Pointers","text":"<p>Generally, a pointer is a variable that contains an address in memory.</p> <p>In Rust, the most common point is a reference, which is indicated by the <code>&amp;</code> and the value they point to. They have no other functionality than to refer to the data. They have no overhead.</p> <p>Why don't they have overhead? What does overhead mean here?</p> <p>Smart pointers are data structures that act like a pointer, but also have additional metadata and capabilities.</p> <p>Smart pointers originated in C++ and exist in other languages.</p> <p>Rust provides a variety of spark pointers defined in the standard library that provide functionality beyond that provided by references.</p> <p>In Rust, another distinction between references and smart pointers - references borrow data, smart pointers own the data they point to in many occassions.</p> <p><code>String</code> and <code>Vec&lt;T&gt;</code> are examples of smart pointers because they own some memory and allow you to manipulate it.</p> <ul> <li><code>String</code> stores its capacity as metadata and has the extra ability to ensure its data will always be valid UTF-8.</li> </ul> <pre><code>//TODO Explain why String and Vec are\n</code></pre> <p>Smart pointers are usually implemented using structs and implements the <code>Deref</code> and <code>Drop</code> traits.</p> <ul> <li><code>Deref</code> trait allows an instance of the smart pointer struct to behave like a reference. That way you can write your code to work with either references or smar pointers.</li> <li><code>Drop</code> trait allows you to customize the code that's run whena an instance of the smart pointer goes out of scope.</li> </ul> <p>Smart pointer pattern is a general design pattern used frequently in Rust. Some common smart pointers in the standard library:</p> <ul> <li><code>Box&lt;T&gt;</code> for allocating values on the heap</li> <li><code>Rc&lt;T&gt;</code>, a reference counting type that enables multiple ownership</li> <li><code>Ref&lt;T&gt;</code> and <code>RefMut&lt;T&gt;</code>, accessed through <code>RefCell&lt;T&gt;</code>, a type that enforces the borrowing rules at runtime instead of compile time</li> </ul>"},{"location":"notes/rust/15-smart-pointers/#boxt-to-store-data-on-the-heap","title":"<code>Box&lt;T&gt;</code> to Store Data on the Heap","text":""},{"location":"notes/rust/15-smart-pointers/#syntax","title":"Syntax","text":"<p>If we want to store an <code>i32</code> value on the heap:</p> <pre><code>fn main() {\nlet b = Box::new(5);\nprintln!(\"b = {}\", b);\n}\n</code></pre> <ul> <li>The variable <code>b</code> has the value of a <code>Box</code> that points to the value <code>5</code>, which is allocated on the heap.</li> <li>The program will print <code>b = 5</code>. We can access the data in the box similar to how we would if this data were on the stack.</li> <li>When a box goes out of scope, it will be deallocated, like any owned value. The deallocation happens both for the box (stored on the stack) and the data it points to (stored on the heap).</li> </ul> <p>A single value on the heap isn't much use, since it can easily be stored on the stack. We'll see some examples on why we need boxes.</p>"},{"location":"notes/rust/15-smart-pointers/#achieving-recursive-types-with-boxes","title":"Achieving Recursive Types with Boxes","text":"<p>A value of recursive type can have another value of the same type as part of itself.</p> <p>Rust needs to know how much space a type takes up, which makes recursive types a problem for Rust. Recursive types could go on infinitely, so Rust cannot know how much space to allocate. Boxes have a known size, so we can enable recursive types by using boxes.</p>"},{"location":"notes/rust/15-smart-pointers/#example-cons-list","title":"Example - cons list","text":"<p>A cons list is a data structure made of nested pairs. It originates from Lisp and is its version of a linked list.</p> <p>The name comes from the <code>cons</code> (short for \"construction\") function in Lisp that constructs a new pair from its two arguments.</p> <p>So for example, the list 1, 2, 3:</p> <pre><code>(1, (2, (3, Nil)))\n</code></pre> <p>It's not really a useful data structure in Rust (it has <code>Vec</code>) but it is good for this example.</p> <p>So our first attempt:</p> <pre><code>enum List {\nCons(i32, List),\nNil,\n}\n</code></pre> <p>This won't compile since <code>List</code> doesn't have a known size. The compiler will complain that <code>List</code> has infinite size.</p> <p>Let's see Rust try to determine the size of <code>List</code>. It sees the first variant as <code>Cons</code> and it determines it needs the space for one <code>i32</code> and one <code>List</code>. Rust then tries to solve this <code>List</code>, and so on. So it sees <code>i32</code> + <code>i32</code> + <code>i32</code> + <code>i32</code> + ... infinitely.</p> <p>The compiler suggests \"indirection\":</p> <pre><code>help: insert some indirection (e.g., a `Box`, `Rc`, or `&amp;`) to make `List` representable\n  |\n2 |     Cons(i32, Box&lt;List&gt;),\n  |               ^^^^    ^\n</code></pre> <p>Indirection means that instead of storing a value indirectly, we should change the data structure to store the value indirectly by storing a pointer to the value instead.</p> <pre><code>enum List {\nCons(i32, Box&lt;List&gt;),\nNil,\n}\n</code></pre> <p>Now when Rust determines the size, it knows how much space <code>Box&lt;T&gt;</code> takes - the pointer size doesn't change based on the the amount of data it's pointing to.</p> <p>Boxes provide only the indirection and heap allocation. No other special capabilities (like other smart pointers). No performance overhead that comes with the special capabilities either.</p> <p><code>Box&lt;T&gt;</code> type is a smart pointer because it implements the <code>Deref</code> trait, which allows <code>Box&lt;T&gt;</code> values to be treated like references. When <code>Box&lt;T&gt;</code> value goes out of scope, the heap data that the box is pointing to is cleaned up as well because of the <code>Drop</code> trait implementation.</p>"},{"location":"notes/rust/15-smart-pointers/#computing-the-size-of-a-non-recursive-type","title":"Computing the Size of a Non-Recursive Type","text":"<pre><code>enum Message {\nQuit,\nMove { x: i32, y: i32 },\nWrite(String),\nChangeColor(i32, i32, i32),\n}\n</code></pre> <p>To determine how much space to allocate for a <code>Message</code> value, Rust goes through each of the variants of see which variant needs the most space.</p> <ul> <li><code>Message::Quit</code> doesn't need any space //Why no space?</li> <li><code>Message::Move</code> needs enough space to store two <code>i32</code> values</li> <li>etc.</li> </ul> <p>Since one <code>Message</code> variant will be used, we only need as much space as the largest one.</p>"},{"location":"notes/scala/00-type-classes/","title":"Type Classes","text":"<p>Type classes are used to enable ad-hoc polymorphism, aka overloading.</p> <p>OO uses subtyping for polymorphism usually. FP uses a combination of parametric polymorphism and ad-hoc polymorphism.</p> <p>A type class:</p> <ol> <li>Declares functionality. (Traits)</li> <li>Guarantees behavior. (Laws)</li> </ol> <p>In order to learn about a type class, you have to learn these two characteristics. (Laws are especially easy to ignore. Don't.)</p> <p>Remember this is polymorphism.</p> <p>A type class doesn't necessarily define the trait. There can be multiple implementations of the trait, as long as it follows the laws.</p> <p>That being said, sometimes laws force a specific definition for a function. (E.g. <code>map</code> method for <code>Monad</code> is defined in terms of <code>flatMap</code> and <code>pure</code>)</p>"},{"location":"notes/scala/00-type-classes/#data-types-and-type-classes","title":"Data Types and Type Classes","text":"<p>Type classes are used to enable data types to have polymorphism. </p> <p>Data types have a \"has-a\" relationship with type classes, not a \"is-a\" relationship.</p> <ul> <li>[Correct] Data type <code>A</code> has an instance of type class <code>B</code></li> <li>[Correct] Data type <code>A</code> has 5 different instances of type class <code>B</code></li> <li>[Wrong] Data type <code>A</code> is a type class <code>B</code></li> <li>[Correct] <code>Either</code> has an instance of a <code>Monad</code>.</li> <li>[Wrong] <code>Either</code> is a <code>Monad</code>.</li> </ul>"},{"location":"notes/scala/01-monoids-and-semigroups/","title":"Monoids and Semigroups","text":"<p>Monoids and semigroups are type classes that allows us to combine values, such as <code>Int</code>, <code>String</code>, <code>Lists</code>, etc.</p> <p><code>Monoid</code> is a <code>Semigroup</code> with an additional <code>empty</code> function. The reason for this distinction is that some data types do not have a sensible <code>empty</code> element. (E.g. positive integer data type, non-empty list data type)</p>"},{"location":"notes/scala/01-monoids-and-semigroups/#definition-of-a-semigroup-and-monoid","title":"Definition of a Semigroup and Monoid","text":""},{"location":"notes/scala/01-monoids-and-semigroups/#functions","title":"Functions","text":"<p>A simplified version of this definition in Cats:</p> <pre><code>trait Semigroup[A] {\ndef combine(x: A, y: A): A\n}\n\ntrait Monoid[A] extends Semigroup[A] {\ndef empty: A\n}\n</code></pre>"},{"location":"notes/scala/01-monoids-and-semigroups/#laws","title":"Laws","text":"<ul> <li><code>combine(x: A, y: A): A</code> must be commutative</li> <li><code>empty</code> must be an identity element</li> </ul> <pre><code>def associaiveLaw[A](x: A, y: A, z: A)(implicit m; Monoid[A]): Boolean = {\nm.combine(x, m.combine(y, z)) == m.combine(m.combine(x, y), z)\n}\n\ndef identityLaw[A](x: A)(implicit m: Monoid[A]): Boolean = {\n(m.combine(x, m.empty) == x) &amp;&amp; (m.combine(m.empty, x) == x)\n}\n</code></pre> <p>So subtraction and division are not monoids, because they aren't associative.</p>"},{"location":"notes/scala/01-monoids-and-semigroups/#boolean-monoids","title":"Boolean Monoids","text":"<p>There are various ways to combine booleans, so there are various monoids we can create.</p> <pre><code>implicit val andMonoid = new Monoid[Boolean] {\ndef combine(x: Boolean, y: Boolean) = x &amp;&amp; y\ndef empty = true\n}\n\nimplicit val orMonoid = new Monoid[Boolean] {\ndef combine(x: Boolean, y: Boolean) = x || y\ndef empty = false\n}\n\nimplicit val xorMonoid = new Monoid[Boolean] {\ndef combine(x: Boolean, y: Boolean) = (x &amp;&amp; !y) || (!x &amp;&amp; y)\ndef empty = false\n}\n\nimplicit val xnorMonoid = new Monoid[Boolean] {\ndef combine(x: Boolean, y: Boolean) = (x || !y) &amp;&amp; (!x || y)\ndef empty = true\n}\n</code></pre>"},{"location":"notes/scala/01-monoids-and-semigroups/#set-monoids","title":"Set Monoids","text":"<p>There are varioius ways to combine sets.</p> <pre><code>implicit def unionMonoid[A]: Monoid[Set[A]] = new Monoid[Set[A]] {\ndef combine(x: Set[A], y: Set[A]) = x union y\ndef empty = Set.empty[A]\n}\n\nimplicit def intersectionSemigroup[A]: Semigroup[Set[A]] = new Semigroup[Set[A]] {\ndef combine(x: Set[A], y: Set[A]) = x intersect y\n//No identity element for intersection\n}\n\nimplicit def symDiffMonoid[A]: Monoid[Set[A]] = new Monoid[Set[A]] {\ndef combine(x: Set[A], y: Set[A]) = (a union b) diff (a intersect b)\ndef empty = Set.empty[A]\n}\n</code></pre> <p>Set difference is not associative, so no monoid/semigroup can be created.</p>"},{"location":"notes/scala/01-monoids-and-semigroups/#exercise","title":"Exercise","text":"<p>Write the code for <code>def add(items: List[Int]): Int</code></p> <pre><code>def add(items: List[Int]): Int =\nitems.foldLeft(0)(_ + _)\n</code></pre> <p>Or with Monoids, (we don't really need to do it this way.)</p> <pre><code>import cats.Monoid\nimport cats.instances.int._    // for Monoid\nimport cats.syntax.semigroup._ // for |+|\n\ndef add(items: List[Int]): Int =\nitems.foldLeft(Monoid[Int].empty)(_ |+| _)\n</code></pre> <p>Write the code for <code>def add(items: List[Option[Int]]): Int</code></p> <pre><code>import cats.Monoid\nimport cats.instances.int._    // for Monoid\nimport cats.syntax.semigroup._ // for |+|\n\ndef add(items: List[A])(implicit monoid: Monoid[A]): A =\nitems.foldLeft(monoid.empty)(_ |+| _)\n</code></pre> <p>or use Scala's context bound syntax:</p> <pre><code>def add[A: Monoid](items: List[A]): A =\nitems.foldLeft(Monoid[A].empty)(_ |+| _)\n</code></pre> <p>With this implementation, we can use to add elements of a <code>List[Int]</code> and <code>List[Option[Int]]</code></p> <pre><code>import cats.instances.int._ // for Monoid\n\nadd(List(1,2,3))\n// res9: Int = 6\n\nimport cats.instances.option._ // for Monoid\n\nadd(List(Some(1), None, Some(2), None, Some(3)))\n// res10: Option[Int] = Some(6)\n</code></pre> <p>This will fail if the <code>List</code> contained only <code>Some</code> values, since the inferred value of the list would be <code>List[Some[Int]]</code> not <code>List[Option[Int]]</code> and we don't have a Monoid for <code>Some[A]</code>.</p> <p>Now we want to add up <code>Orders</code></p> <pre><code>case class Order(totalCost: Double, quantity: Double)\n</code></pre> <p>How can we use <code>add</code>?</p> <pre><code>implicit val orderMonoid = new Monoid[Order] {\ndef combine(o1: Order, o2: Order) =\nOrder(\no1.totalCost + o2.totalCost,\no1.quantity + o2.quantity\n)\n\ndef empty = Order(0, 0)\n}\n</code></pre>"},{"location":"notes/scala/02-functors/","title":"Functors","text":"<p>In layman's terms, a functor is anything with a <code>map</code> function. The <code>map</code> can be thought as a means to change all values in a structure, without changing the structure.</p> <pre><code>List(1, 2, 3).map(n =&gt; n + 1)\n// res0: List[Int] = List(2, 3, 4)\n\nSome(1).map(n =&gt; n * 2)\n// res1: Option[Int] = Some(2)\n\nOption.empty[Int].map(n =&gt; n * 2)\n// res2: Option[Int] = None\n</code></pre> <p>Because it doesn't change, we can chain calls</p> <pre><code>Right(12)\n.map(n =&gt; n + 1)\n.map(n =&gt; n + 1)\n.map(n =&gt; n + 1)\n.map(n =&gt; n * 3)\n.map(n =&gt; n - 4)\n// res3: scala.util.Either[Nothing,Int] = Right(41)\n</code></pre> <p><code>List</code>, <code>Option</code>, <code>Either</code> all have eager evaluations. But <code>map</code> doesn't have to be. </p> <p><code>Functor</code> is a mean to sequence operations.</p>"},{"location":"notes/scala/02-functors/#definition-of-a-functor","title":"Definition of a Functor","text":"<p>A functor is a type <code>F[A]</code> that has a <code>map</code> operation of the type of <code>(A =&gt; B) =&gt; F[B]</code>.</p>"},{"location":"notes/scala/02-functors/#functions","title":"Functions","text":"<pre><code>package cats\n\nimport scala.language.higherKinds\n\ntrait Functor[F[_]] {\ndef map[A, B](fa: F[A])(f: A =&gt; B): F[B]\n}\n</code></pre>"},{"location":"notes/scala/02-functors/#laws","title":"Laws","text":"<p>It should adhere to two laws:</p> <pre><code>def identityLaw[A: Functor]: Boolean = {\nFunctor[A].map(a =&gt; a) == fa\n}\n\ndef compositionLaw[A: Functor, B, C](f: A =&gt; B, g: B =&gt; C): Boolean = {\nFunctor[A].map(g(f(_))) == Functor[A].map(f).map(g)\n}\n</code></pre> <p>This gives the property that functors will behavior doesn't change whether we do multiple operations or combine the operations into a single function and then apply it once.</p>"},{"location":"notes/scala/02-functors/#example-futures","title":"Example: Futures","text":"<p><code>Future</code> is a functor that sequences asynchronous computations, by executing each one as the previous one completes.</p> <pre><code>import scala.concurrent.{Future, Await}\nimport scala.concurrent.ExecutionContext.Implicits.global\nimport scala.concurrent.duration._\n\nval future: Future[String] =\nFuture(123).\nmap(n =&gt; n + 1).\nmap(n =&gt; n * 2).\nmap(n =&gt; n + \"!\")\n\nAwait.result(future, 1.second)\n// res3: String = 248!\n</code></pre> <p>Note: Future aren't referentially transparent. They are computed and results are cached. This gives us non functional behavior when wrapping side effects in <code>Future</code>'s.</p> <pre><code>import scala.concurrent.{Future, Await}\nimport scala.concurrent.ExecutionContext.Implicits.global\nimport scala.concurrent.duration._\nimport scala.util.Random\n\nval future1 = {\nval r = new Random(0L)\n\nval x = Future(r.nextInt) //nextInt is a side effect\n\nfor {\na &lt;- x\nb &lt;- x\n} yield (a, b)\n}\n\n//should be the same as\n\nval future2 = {\nval r = new Random(0L)\n\nfor {\na &lt;- Future(r.nextInt) //Replaced x with its value\nb &lt;- Future(r.nextInt)\n} yield (a, b)\n}\n\nval result1 = Await.result(future1, 1.second)\n// result1: (Int, Int) = (-1155484576,-1155484576)\n\nval result2 = Await.result(future2, 1.second)\n// result2: (Int, Int) = (-1155484576,-723955400)\n</code></pre>"},{"location":"notes/scala/02-functors/#exercise","title":"Exercise","text":"<p>Write a <code>Functor</code> for the following binary tree data type.</p> <pre><code>sealed trait Tree[+A]\n\nfinal case class Branch[A](left: Tree[A], right: Tree[A]) extends Tree[A]\n\nfinal case class Leaf[A](value: A) extends Tree[A]\n</code></pre> <pre><code>import cats.Functor\n\nimplicit val branchFunctor = new Functor[Branch] {\ndef map[A, B](branch: Branch[A])(f: A =&gt; B): Branch[B] = Branch(\nbranch.left.map(f),\nbranch.right.map(f)\n)\n}\n\nimplicit val leafFunctor = new Functor[Leaf] {\ndef map[A, B](leaf: Leaf[A])(f: A =&gt; B): Leaf[B] = Leaf(leaf.value.map(f))\n}\n</code></pre> <p>This would not work! Because of</p> <pre><code>branch.left.map(f),\nbranch.right.map(f)\n</code></pre> <p><code>branch.left</code> and <code>branch.right</code> are of type <code>Tree[A]</code>, for which we do not have a `Functor defined. Instead the solution would look like:</p> <pre><code>import cats.Functor\n\nimplicit val treeFunctor = new Functor[Tree] {\ndef map[A,B](tree: Tree[A])(func: A =&gt; B): Tree[B] =\ntree match {\ncase Branch(left, right) =&gt; Branch(map(left)(func), map(right)(func))\ncase Leaf(value) =&gt; Leaf(func(value))\n}\n}\n</code></pre> <p>We recursively call <code>map</code> on a branch above.</p> <p>However, below won't run:</p> <pre><code>Branch(Leaf(10), Leaf(20)).map(_ * 2)\n// &lt;console&gt;:42: error: value map is not a member of wrapper.Branch[Int]\n//        Branch(Leaf(10), Leaf(20)).map(_ * 2)\n//    \n</code></pre> <p>This is because of an invariance problem. The compiler knows a <code>Functor</code> instance for <code>Tree</code> but not for <code>Branch</code> or <code>Leaf</code>. We can add smart constructors to solve this:</p> <pre><code>object Tree {\ndef branch[A](left: Tree[A], right: Tree[A]): Tree[A] = Branch(left, right)\n\ndef leaf[A](value: A): Tree[A] = Leaf(left, right)\n}\n</code></pre> <p>Now we can use <code>Functor</code>:</p> <pre><code>Tree.leaf(100).map(_ * 2)\n// res10: wrapper.Tree[Int] = Leaf(200)\n\nTree.branch(Tree.leaf(10), Tree.leaf(20)).map(_ * 2)\n// res11: wrapper.Tree[Int] = Branch(Leaf(20),Leaf(40))\n</code></pre> <p>This works because <code>leaf</code> and <code>branch</code> method is defined to return <code>Tree</code>.</p> <pre><code>// TODO Contramap and Invariant Functors\n</code></pre>"},{"location":"notes/scala/03-monads/","title":"Monads","text":"<p>In layman's terms, a functor is anything with a <code>flatMap</code> function.</p> <p>A monad is a mechanism for sequencing computations.</p> <p>But doesn't a functor sequence computations? It allows us do perform computations while ignoring some \"complications\". The thing is, it can handles complications at the beginning. If more complications occur, it cannot handle that.</p> <p>Complications here\u00a0meaning the complications of a data type. E.g. how do we apply a function to an Option? We have to get the value, apply it, and return an Option wrapping it. If it is None, return None.</p> <p>So with functors, we can change <code>Option[A]</code> with <code>A =&gt; B</code> and get <code>Option[B]</code>. What happens if a \"complication\" occurs, i.e. with <code>A =&gt; Option[B]</code>? Then we get <code>Option[Option[B]]</code>.</p> <p>This is where monads come in. The <code>flapMap</code> method allows us to specify what to apply next, accouting for the complication. </p> <p>The <code>flatMap</code> method of <code>Option</code> takes intermediate <code>Options</code> to account. Same with the <code>flatMap</code> method of <code>List</code>, etc.</p> <p>This \"complication\" makes more sense if we look at the <code>Future</code> monad. <code>Future</code> is a monad that sequences computations without having to worry that they are asynchronous.</p> <pre><code>import scala.concurrent.Future\nimport scala.concurrent.ExecutionContext.Implicits.global\nimport scala.concurrent.duration._\n\ndef doSomethingLongRunning: Future[Int] = ???\ndef doSomethingElseLongRunning: Future[Int] = ???\n\ndef doSomethingVeryLongRunning: Future[Int] =\nfor {\nresult1 &lt;- doSomethingLongRunning\nresult2 &lt;- doSomethingElseLongRunning\n} yield result1 + result2\n</code></pre> <p>The <code>flatMap</code> takes care of all the complexity of thread pools, schedulers, and that garbage.</p> <p>The above runs the computations in sequence. We can think of it as <code>Future[A] flatMap A =&gt; Future[B]</code> giving us <code>Future[B]</code>. We can also do parallel, but thats for another time.</p>"},{"location":"notes/scala/03-monads/#definition-of-a-monad","title":"Definition of a Monad","text":"<p>A monad of constructor type <code>F[_]</code> has:</p> <ul> <li>An operation <code>pure</code> of type <code>A =&gt; F[A]</code></li> <li>An operation <code>flatMap</code> of type <code>(F[A], A=&gt; F[B]) = F[B]</code></li> </ul>"},{"location":"notes/scala/03-monads/#functions","title":"Functions","text":"<pre><code>import scala.language.higherKinds\n\ntrait Monad[F[_]] {\ndef pure[A](value: A): F[A]\n\ndef flatMap[A, B](value: F[A])(func: A =&gt; F[B]): F[B]\n}\n</code></pre>"},{"location":"notes/scala/03-monads/#laws","title":"Laws","text":"<p>Monads must obey certain laws:</p> <p>Left Identity. Calling <code>pure</code> and then transforming with <code>func</code> is the same as calling <code>func</code>.</p> <pre><code>pure(a).flatMap(func) == func(a)\n</code></pre> <p>Right identity. Passing <code>pure</code> to <code>flatMap</code> is the same as doing nothing.</p> <pre><code>m.flatMap(pure) == m\n</code></pre> <p>Associativity.</p> <pre><code>m.flatMap(f).flatMap(g) == m.flatMap(x =&gt; f(x).flatMap(g))\n</code></pre>"},{"location":"notes/scala/03-monads/#exercise-a-monad-is-also-a-functor","title":"Exercise - A monad is also a functor","text":"<p>Define <code>map</code> using <code>flatMap</code> and <code>pure</code>:</p> <pre><code>import scala.language.higherKinds\n\ntrait Monad[F[_]] {\ndef pure[A](a: A): F[A]\n\ndef flatMap[A, B](value: F[A])(func: A =&gt; F[B]): F[B]\n\ndef map[A, B](value: F[A])(func: A =&gt; B): F[B] =\nflatMap(value)(a =&gt; pure(func(a)))\n}\n</code></pre>"},{"location":"notes/scala/03-monads/#the-identity-monad","title":"The Identity Monad","text":"<p>We can define methods that are abstracted over different monads:</p> <pre><code>import scala.language.higherKinds\nimport cats.Monad\nimport cats.syntax.functor._ // for map\nimport cats.syntax.flatMap._ // for flatMap\n\ndef sumSquare[F[_]: Monad](a: F[Int], b: F[Int]): F[Int] =\nfor {\nx &lt;- a\ny &lt;- b\n} yield x*x + y*y\n</code></pre> <p>This works with <code>Options</code> and <code>Lists</code> but not plain old values:</p> <pre><code>sumSquare(3,4) //This won't work! An F doesn't exist such that F[Int] equals Int\n</code></pre> <p>It'd be nice if we could define a method that would handle monadic and non-monadic types. Cats provdes the <code>Id</code> type to achieve this.</p> <pre><code>import cats.Id\n\nsumSquare(3 : Id[Int], 4 : Id[Int])\n// res2: cats.Id[Int] = 25\n</code></pre> <p>We're casting an <code>Int</code> to <code>Id[Int]</code>, what is going on? Here is the definition of <code>Id</code></p> <pre><code>package cats\n\ntype Id[A] = A\n</code></pre> <p>Id is actually a type alias. We can cast any value to its corresponding <code>Id</code>. Cats provides instances for various type classes for <code>Id</code>, including <code>Functor</code> and <code>Monad</code>.</p>"},{"location":"notes/scala/03-monads/#exercise-implement-id-monad-instance","title":"Exercise - Implement Id Monad Instance","text":"<p>Implement <code>pure</code>, <code>map</code>, and <code>flatMap</code> for <code>Id</code></p> <pre><code>  val monad = new Monad[Id] {\n\ndef pure[A](a: A): Id[A] = a\n\ndef flatMap[A, B](value: Id[A])(func: A =&gt; Id[B]): Id[B] = func(a)\n\ndef map[A, B](value: Id[A])(func: A =&gt; B): Id[B] = func(a)\n}\n</code></pre> <p><code>map</code> can be defined with <code>pure</code> and <code>flatMap</code>. How does that reduce to <code>func(a)</code>?</p> <pre><code>flatMap(value)(a =&gt; pure(func(a)))\nflatMap(value)(a =&gt; func(a))\nflatMap(value)(func)\nfunc(value)\n</code></pre> <p>Why is <code>flatMap</code> and <code>map</code> the same?</p> <p>Functors and Monads are used for sequencing computations ignoring some kind of complications. In the case of <code>Id</code>, there is no complication, so making both of them identical.</p>"},{"location":"notes/scala/03-monads/#the-either-monad","title":"The Either Monad","text":"<p>In Scala 2.11 and prior, <code>Either</code> wasn't really considered a monad because it didn't have <code>map</code> and <code>flatMap</code>. Starting with 2.12, <code>Either</code> became right biased and a monad.</p> <p>Meaning <code>map</code> and <code>flatMap</code> were applied to <code>Right</code>. If it was <code>Left</code> then no-op.</p> <p>It is used a lot for error handling</p> <pre><code>type Result[A] = Either[Throwable, A]\n</code></pre> <p><code>Throwable</code> can be very general, we can make it more explicit:</p> <pre><code>sealed trait LoginError extends Product with Serializable\n\nfinal case class UserNotFound(username: String)\nextends LoginError\n\nfinal case class PasswordIncorrect(username: String)\nextends LoginError\n\ncase object UnexpectedError extends LoginError\n\ncase class User(username: String, password: String)\n\ntype LoginResult = Either[LoginError, User]\n</code></pre> <p>This gives us the ability to discretely handle specific errors.</p>"},{"location":"notes/scala/03-monads/#the-eval-monad","title":"The Eval Monad","text":"<p><code>cats.Eval</code> is a monad that allows us to abstract over different models of evaluation. Three models that cats provides, eager, lazy, and memoized.</p> <ul> <li>eager is done immediately</li> <li>lazy is done when value is accessed</li> <li>memoized is done on first accessed and then cached</li> </ul> <p><code>vals</code> are eager and memoized</p> <pre><code>val x = {\nprintln(\"Computing X\")\nmath.random\n}\n// Computing X\n// x: Double = 0.013533499657218728\n\nx // first access\n// res0: Double = 0.013533499657218728\n\nx // second access\n// res1: Double = 0.013533499657218728\n</code></pre> <p><code>defs</code> are lazy and not memoized</p> <pre><code>def y = {\nprintln(\"Computing Y\")\nmath.random\n}\n// y: Double\n\ny // first access\n// Computing Y\n// res2: Double = 0.5548281126990907\n\ny // second access\n// Computing Y\n// res3: Double = 0.7681777032036599\n</code></pre> <p><code>lazy vals</code> are lazy and memoized.</p> <pre><code>lazy val z = {\nprintln(\"Computing Z\")\nmath.random\n}\n// z: Double = &lt;lazy&gt;\n\nz // first access\n// Computing Z\n// res4: Double = 0.45707125364871903\n\nz // second access\n// res5: Double = 0.45707125364871903\n</code></pre> <p><code>Eval</code> has three subtypes: <code>Now</code>, <code>Later</code>, and <code>Always</code>. To draw comparisons:</p> Scala Cats Properties <code>val</code> <code>Now</code> eager, memoized <code>lazy val</code> <code>Later</code> lazy, memoized <code>def</code> <code>Always</code> lazy, not memoized <p>We access the value with the <code>value</code> method.</p> <p>The <code>map</code> and <code>flatMap</code> methods add computations to a chain. In this case, it is a list of functions, that aren't run until <code>value</code> method is invoked.</p> <pre><code>val greeting = Eval.\nalways { println(\"Step 1\"); \"Hello\" }.\nmap { str =&gt; println(\"Step 2\"); s\"$str world\" }\n// greeting: cats.Eval[String] = cats.Eval$$anon$8@79ddd73b\n\ngreeting.value\n// Step 1\n// Step 2\n// res15: String = Hello world\n</code></pre> <p>The mapping functions are always called lazily on demand (<code>def</code>)</p> <pre><code>val ans = for {\na &lt;- Eval.now { println(\"Calculating A\"); 40 }\nb &lt;- Eval.always { println(\"Calculating B\"); 2 }\n} yield {\nprintln(\"Adding A and B\")\na + b\n}\n// Calculating A\n// ans: cats.Eval[Int] = cats.Eval$$anon$8@12da1eee\n\nans.value // first access\n// Calculating B\n// Adding A and B\n// res16: Int = 42\n\nans.value // second access\n// Calculating B\n// Adding A and B\n// res17: Int = 42\n</code></pre> <p><code>Eval</code> has a <code>memoize</code> method to memoize a change of computations.</p> <pre><code>val saying = Eval.\nalways { println(\"Step 1\"); \"The cat\" }.\nmap { str =&gt; println(\"Step 2\"); s\"$str sat on\" }.\nmemoize.\nmap { str =&gt; println(\"Step 3\"); s\"$str the mat\" }\n// saying: cats.Eval[String] = cats.Eval$$anon$8@159a20cc\n\nsaying.value // first access\n// Step 1\n// Step 2\n// Step 3\n// res18: String = The cat sat on the mat\n\nsaying.value // second access\n// Step 3\n// res19: String = The cat sat on the mat\n</code></pre> <pre><code>TODO\n\n- Trampolining and Eval.defer\n- Writer Monad\n- Reader Monad\n- State Monad\n</code></pre> <p>Why do we need <code>pure</code>?</p>"},{"location":"notes/scala/03-monads/#the-writer-monad","title":"The Writer Monad","text":"<p>The writer monad allows us to carry a log along with a computation.</p> <ul> <li>A use case for this is multi-threaded computations. We can keep track of logs for separate threads without worrying about them interleaving.</li> </ul> <p>The <code>Writer[W, A]</code> has two values, a log of type <code>W</code> and a result of type <code>A</code>.</p> <p>Writer has some convenience methods.</p> <p><code>pure</code> syntax - to create with only result. We need to have <code>Monoid[W]</code> so we can create an empty log (<code>W</code>).</p> <pre><code>type Logged[A] = Writer[Vector[String], A]\n\n123.pure[Logged]\n// res2: Logged[Int] = WriterT((Vector(),123))\n</code></pre> <p><code>tell</code> syntax - to create with only log.</p> <pre><code>Vector(\"msg1\", \"msg2\", \"msg3\").tell\n// res3: cats.data.Writer[scala.collection.immutable.Vector[String],Unit] = WriterT((Vector(msg1, msg2, msg3),()))\n</code></pre> <p><code>Writer.apply</code> or <code>writer</code> syntax if we have both.</p> <pre><code>val a = Writer(Vector(\"msg1\", \"msg2\", \"msg3\"), 123)\n// a: cats.data.WriterT[cats.Id,scala.collection.immutable.Vector[String],Int] = WriterT((Vector(msg1, msg2, msg3),123))\n\nval b = 123.writer(Vector(\"msg1\", \"msg2\", \"msg3\"))\n// b: cats.data.Writer[scala.collection.immutable.Vector[String],Int] = WriterT((Vector(msg1, msg2, msg3),123))\n</code></pre> <p><code>value</code> to get result. <code>written</code> to get logs.</p> <pre><code>val aResult: Int =\na.value\n// aResult: Int = 123\n\nval aLog: Vector[String] =\na.written\n// aLog: Vector[String] = Vector(msg1, msg2, msg3)\n</code></pre> <p><code>run</code> to get both.</p> <pre><code>val (log, result) = b.run\n// log: scala.collection.immutable.Vector[String] = Vector(msg1, msg2, msg3)\n// result: Int = 123\n</code></pre>"},{"location":"notes/scala/03-monads/#composing-and-transforming","title":"Composing and Transforming","text":"<p><code>map</code> only operates on the result</p> <p><code>flatMap</code> appends the logs (so it needs <code>Semigroup[W]</code>) and with the computed results.</p> <p>This is an example of how <code>flatMap</code> handles complexity. We use <code>flatMap</code> to apply a function to our result giving us another <code>Writer</code>. One with a log and the result. <code>flatMap</code> here handles this by taking in the new result and taking the old log and appending the new log. That is handled out of the box.</p> <p><code>mapWritten</code> transforms the logs.</p> <pre><code>val writer2 = writer1.mapWritten(_.map(_.toUpperCase))\n// writer2: cats.data.WriterT[cats.Id,scala.collection.immutable.Vector[String],Int] = WriterT((Vector(A, B, C, X, Y, Z),42))\n</code></pre> <p><code>bimap</code> transforms both log and result, taking in two functions.</p> <p><code>mapBoth</code> transforms both log and result, taking in one function with two arguments.</p> <pre><code>val writer3 = writer1.bimap(\nlog =&gt; log.map(_.toUpperCase),\nres =&gt; res * 100\n)\n// writer3: cats.data.WriterT[cats.Id,scala.collection.immutable.Vector[String],Int] = WriterT((Vector(A, B, C, X, Y, Z),4200))\n\nwriter3.run\n// res6: cats.Id[(scala.collection.immutable.Vector[String], Int)] = (Vector(A, B, C, X, Y, Z),4200)\n\nval writer4 = writer1.mapBoth { (log, res) =&gt;\nval log2 = log.map(_ + \"!\")\nval res2 = res * 1000\n(log2, res2)\n}\n// writer4: cats.data.WriterT[cats.Id,scala.collection.immutable.Vector[String],Int] = WriterT((Vector(a!, b!, c!, x!, y!, z!),42000))\n\nwriter4.run\n// res7: cats.Id[(scala.collection.immutable.Vector[String], Int)] = (Vector(a!, b!, c!, x!, y!, z!),42000)\n</code></pre> <p><code>result</code> clears the logs.</p> <p><code>swap</code> swaps the log and result.</p>"},{"location":"notes/scala/03-monads/#exercise-factorial","title":"Exercise - factorial","text":"<p>Let's say we have a slow <code>factorial</code> that logs.</p> <pre><code>def slowly[A](body: =&gt; A) =\ntry body finally Thread.sleep(100)\n\ndef factorial(n: Int): Int = {\nval ans = slowly(if(n == 0) 1 else n * factorial(n - 1))\nprintln(s\"fact $n $ans\")\nans\n}\n</code></pre> <p>If we have multi-threaded application, the logs will get interleaved.</p> <p>Rewrite <code>factorial</code> to capture the log messages.</p> <pre><code>type Logged[A] = Writer[Vector[String], A]\n\ndef slowly[A](body: =&gt; A) =\ntry body finally Thread.sleep(100)\n\ndef factorial(n: Int): Logged[Int] = {\n\nfor {\nans &lt;-  if (n==0)\n1.pure[Logged]\nelse\nslowly(factorial(n - 1).map(_ * n))\n_ &lt;- Vector(s\"fact $n $ans\").tell\n} yield ans\n}\n</code></pre>"},{"location":"notes/scala/03-monads/#the-reader-monad","title":"The Reader Monad","text":"<p>The Reader monad allows us to sequence operations that depend on some input.</p>"},{"location":"notes/scala/03-monads/#composing-and-transforming_1","title":"Composing and Transforming","text":"<p>We can create <code>Reader[A, B]</code> from a function <code>A =&gt; B</code>.</p> <pre><code>import cats.data.Reader\n\ncase class Cat(name: String, favoriteFood: String)\n// defined class Cat\n\nval catName: Reader[Cat, String] =\nReader(cat =&gt; cat.name)\n// catName: cats.data.Reader[Cat,String] = Kleisli(&lt;function1&gt;)\n</code></pre> <p><code>run</code> extracts the function, and then we can call it as usual.</p> <pre><code>catName.run(Cat(\"Garfield\", \"lasagne\"))\n// res0: cats.Id[String] = Garfield\n</code></pre> <p>We can have a set of <code>Readers</code> that accept the same type of input, combine it using <code>map</code> or <code>flatMap</code>, and then call <code>run</code> at the end.</p> <p><code>map</code> passes the result of the computation through a function.</p> <pre><code>val greetKitty: Reader[Cat, String] =\ncatName.map(name =&gt; s\"Hello ${name}\")\n\ngreetKitty.run(Cat(\"Heathcliff\", \"junk food\"))\n// res1: cats.Id[String] = Hello Heathcliff\n</code></pre> <p><code>flatMap</code> allows us to combine readers that depend on the same input type.</p> <pre><code>val feedKitty: Reader[Cat, String] =\nReader(cat =&gt; s\"Have a nice bowl of ${cat.favoriteFood}\")\n\nval greetAndFeed: Reader[Cat, String] =\nfor {\ngreet &lt;- greetKitty\nfeed  &lt;- feedKitty\n} yield s\"$greet. $feed.\"\n\n//Or\n// greetKitty.flatMap(greeting -&gt; feedKitty.map(feeding -&gt; s\"$greet. $feed.\"))\n\ngreetAndFeed(Cat(\"Garfield\", \"lasagne\"))\n// res3: cats.Id[String] = Hello Garfield. Have a nice bowl of lasagne.\n\ngreetAndFeed(Cat(\"Heathcliff\", \"junk food\"))\n// res4: cats.Id[String] = Hello Heathcliff. Have a nice bowl of junk food.\n</code></pre>"},{"location":"notes/scala/03-monads/#exercise","title":"Exercise","text":"<p>Build a program that accept a configuration as a parameter - a login system.</p> <pre><code>case class Db(\nusernames: Map[Int, String],\npasswords: Map[String, String]\n)\n</code></pre> <p>Create a type alias <code>DbReader</code> for a <code>Reader</code> that consumes <code>Db</code>.</p> <pre><code>type DbReader[A] = Reader[Db, A]\n</code></pre> <pre><code>def findUsername(userId: Int): DbReader[Option[String]] =\nReader(db =&gt; db.usernames.get(id))\n\ndef checkPassword(\nusername: String,\npassword: String): DbReader[Boolean] =\nReader(db =&gt; db.passwords.get(username).contains(password))\n\ndef checkLogin(\nuserId: Int,\npassword: String): DbReader[Boolean] =\nfor {\nusername &lt;- findUsername(userId)\ncheck &lt;- username.map { name =&gt; checkPassowrd(name, password)\n}.getOrElse { false.pure[DbReader] }\n} yield check\n</code></pre>"},{"location":"notes/scala/03-monads/#the-state-monad","title":"The State Monad","text":"<p>The State monad allow us to pass additional state around as part of a computation.</p> <p>Instances of <code>State[S, A]</code> represent functions of type <code>S =&gt; (S, A)</code>. <code>S</code> is the type of state, <code>A</code> is the type of the result.</p> <pre><code>import cats.data.State\n\nval a = State[Int, String] { state =&gt;\n(state, s\"The state is $state\")\n}\n// a: cats.data.State[Int,String] = cats.data.IndexedStateT@6ceace82\n</code></pre> <p>We can run our monad by giving the inital state.</p> <p><code>run</code> gives us both the state and result.</p> <p><code>runS</code> gives us the state</p> <p><code>runA</code> gives the result.</p> <pre><code>// Get the state and the result:\nval (state, result) = a.run(10).value\n// state: Int = 10\n// result: String = The state is 10\n\n// Get the state, ignore the result:\nval state = a.runS(10).value\n// state: Int = 10\n\n// Get the result, ignore the state:\nval result = a.runA(10).value\n// result: String = The state is 10\n</code></pre>"},{"location":"notes/scala/03-monads/#composing-and-transforming_2","title":"Composing and Transforming","text":"<p><code>map</code> and <code>flatMap</code> thread the state from one instance to another by combining instances. Each individual instances represents an atomic state transformation, and the combination represents a complete sequence of changes.</p> <pre><code>val step1 = State[Int, String] { num =&gt;\nval ans = num + 1\n(ans, s\"Result of step1: $ans\")\n}\n// step1: cats.data.State[Int,String] = cats.data.IndexedStateT@76122894\n\nval step2 = State[Int, String] { num =&gt;\nval ans = num * 2\n(ans, s\"Result of step2: $ans\")\n}\n// step2: cats.data.State[Int,String] = cats.data.IndexedStateT@1eaaaa5d\n\nval both = for {\na &lt;- step1\nb &lt;- step2\n} yield (a, b)\n// both: cats.data.IndexedStateT[cats.Eval,Int,Int,(String, String)] = cats.data.IndexedStateT@47a10835\n\nval (state, result) = both.run(20).value\n// state: Int = 42\n// result: (String, String) = (Result of step1: 21,Result of step2: 42)\n</code></pre> <p>The final state is the result of applying both transformations in sequence. The single state gets threaded from step to step even though we don't interact with it in the for comprehension.</p> <p>How does the state get threaded? It is a behind a scene of flatMap.</p> <p>The general model for using <code>State</code> is to represent each step as an instance and then compose it using general monad operators.</p> <p>Some methods for convenience for creating primitive steps:</p> <ul> <li><code>get</code> extracts the state as the result. <code>// State[A, A](a =&gt; (a,a))</code></li> <li><code>set</code> updates the state and returns unit as the result. <code>// State[A, Unit](a =&gt; (a,())</code></li> <li><code>pure</code> ignores the state and returns a supplied result.</li> <li><code>inspect</code> extracts the state via a transformation function.</li> <li><code>modify</code> updates the state using an update function.</li> </ul> <p>We can use these in a for comprehension. We usually ignore the result of intermediate stages.</p> <pre><code>import State._\n\nval program: State[Int, (Int, Int, Int)] = for {\na &lt;- get[Int]\n_ &lt;- set[Int](a + 1)\nb &lt;- get[Int]\n_ &lt;- modify[Int](_ + 1)\nc &lt;- inspect[Int, Int](_ * 1000)\n} yield (a, b, c)\n// program: cats.data.State[Int,(Int, Int, Int)] = cats.data.IndexedStateT@22a799f8\n\nval (state, result) = program.run(1).value\n// state: Int = 3\n// result: (Int, Int, Int) = (1,2,3000)\n</code></pre>"},{"location":"notes/scala/03-monads/#exercise-post-order-calculator","title":"Exercise - Post-Order Calculator","text":"<pre><code>1 2 + //gives us 3\n</code></pre> <p>Let's parse each symbol into a <code>State</code> instance</p> <pre><code>import cats.data.State\n\ntype CalcState[A] = State[List[Int], A]\n\ndef evalOne(sym: String): CalcState[Int] = sym match {\ncase \"+\" =&gt; operator(_ + _)\ncase \"-\" =&gt; operator(_ - _)\ncase \"*\" =&gt; operator(_ * _)\ncase \"/\" =&gt; operator(_ / _)\ncase num =&gt; operand(num.toInt)\n}\n\ndef operand(num: Int): CalcState[Int] = CalcState[Int] { stack =&gt; (num :: stack, num) }\n\ndef operator(func: (Int, Int) =&gt; Int): CalcState[Int] =\nCalcState[Int] {\ncase b :: a :: tail =&gt;\nval ans = func(a, b)\n(ans :: tail, ans)\n\ncase _ =&gt;\nsys.error(\"Fail!\")\n}\n</code></pre> <p>Now we can use <code>evalOne</code></p> <pre><code>evalOne(\"42\").runA(Nil).value\n// res3: Int = 42\n</code></pre> <p>We can use <code>flatMap</code> to get more complex</p> <pre><code>val program = for {\n_   &lt;- evalOne(\"1\")\n_   &lt;- evalOne(\"2\")\nans &lt;- evalOne(\"+\")\n} yield ans\n// program: cats.data.IndexedStateT[cats.Eval,List[Int],List[Int],Int] = cats.data.IndexedStateT@19744e79\n\nprogram.runA(Nil).value\n// res4: Int = 3\n</code></pre> <p>We can write an <code>evalAll</code> method.</p> <pre><code>def evalAll(input: List[String]): CalcState[Int] =\ninput.foldLeft(0.pure[CalcState]) { (a, b) =&gt;\na.flatMap(_ =&gt; evalOne(b))\n}\n</code></pre> <p>How do we recognize that fold is needed here?</p> <p>We can combine <code>evalAll</code> and <code>evalOne</code> since they are the same type:</p> <pre><code>val program = for {\n_   &lt;- evalAll(List(\"1\", \"2\", \"+\"))\n_   &lt;- evalAll(List(\"3\", \"4\", \"+\"))\nans &lt;- evalOne(\"*\")\n} yield ans\n// program: cats.data.IndexedStateT[cats.Eval,List[Int],List[Int],Int] = cats.data.IndexedStateT@e08e443\n\nprogram.runA(Nil).value\n// res7: Int = 21\n</code></pre> <p>We can define a function that takes in one string:</p> <pre><code>def evalInput(input: String): Int =\nevalAll(input.split(\" \").toList).runA(Nil).value\n\nevalInput(\"1 2 + 3 4 + *\")\n// res8: Int = 21\n</code></pre>"},{"location":"notes/scala/03-monads/#defining-custom-monads","title":"Defining Custom Monads","text":"<p>We can define our own <code>Monad</code> by providing implementation of <code>flatMap</code>, <code>pure</code> and <code>tailRecM</code> (haven't seen this yet).</p> <pre><code>// TODO Finish custom \n</code></pre>"},{"location":"notes/scala/04-semigroupal-and-applicatives/","title":"Semigroupal and Applicative","text":"<p>Functors and Monads lets us sequence operations using <code>map</code> and <code>flatMap</code>, which is very useful. But there are some limitations in what computation flow they can do.</p> <p>For example, form validation. We want all errors, just not the first one. <code>Either</code> is great for validation, but it only gets us the first one.</p> <p>Another example, concurrent evaluation of <code>Futures</code>. <code>map</code> and <code>flatMap</code> can combine Futures, but each one is dependent on the previous one completing.</p> <p>There are two type classes that enables these use cases:</p> <ol> <li><code>Semigroupal</code> composes pairs of context. By using <code>Semigroupal</code> and <code>Functor</code> we can sequence functions with multiple arguments.</li> <li><code>Applicative</code> extends <code>Semigroupal</code> and <code>Functor</code>. It provides a way to apply functions to parameters within a context. It also provides the <code>pure</code> function we've used before.</li> </ol>"},{"location":"notes/scala/04-semigroupal-and-applicatives/#semigroupal","title":"Semigroupal","text":"<p><code>Semigroupal</code> is a type class that allows us to combine contexts. <code>Semigroupal[F]</code> allows us to combine <code>F[A]</code> and <code>F[B]</code> into <code>F[(A,B)]</code>.</p> <pre><code>trait Semigroupal[F[_]] {\ndef product[A,B](fa: F[A], fb: F[B]): F[(A,B)]\n}\n</code></pre> <p>The order of the two contexts doesn't matter, they are independent. This makes this more flexible than <code>flatMap</code> which has a definite order.</p> <pre><code>import cats.Semigroupal\nimport cats.instances.option._ // for Semigroupal\n\nSemigroupal[Option].product(Some(123), Some(\"abc\"))\n// res0: Option[(Int, String)] = Some((123,abc))\n\nSemigroupal[Option].product(None, Some(\"abc\"))\n// res1: Option[(Nothing, String)] = None\n\nSemigroupal[Option].product(Some(123), None)\n// res2: Option[(Int, Nothing)] = None\n</code></pre>"},{"location":"notes/scala/04-semigroupal-and-applicatives/#semigroupal-with-example-types","title":"Semigroupal With Example Types","text":"<p>Future</p> <p>We can use <code>Semigroupal</code> to have concurrent <code>Futures</code> zipped together:</p> <pre><code>import cats.syntax.apply._ // for mapN\n\ncase class Cat(\nname: String,\nyearOfBirth: Int,\nfavoriteFoods: List[String]\n)\n\nval futureCat = (\nFuture(\"Garfield\"),\nFuture(1978),\nFuture(List(\"Lasagne\"))\n).mapN(Cat.apply)\n\nAwait.result(futureCat, 1.second)\n// res4: Cat = Cat(Garfield,1978,List(Lasagne))\n</code></pre> <p>List</p> <p>However, <code>Lists</code> doesn't get zipped, but rather it performs a cartesian product:</p> <pre><code>import cats.Semigroupal\nimport cats.instances.list._ // for Semigroupal\n\nSemigroupal[List].product(List(1, 2), List(3, 4))\n// res5: List[(Int, Int)] = List((1,3), (1,4), (2,3), (2,4))\n</code></pre> <p>Either</p> <p>We had the example of form validation to collect all errors. So, naturally we expect combining Eithers would give us all the errors. We'd be wrong. It does the same fail fast behavior as <code>flatMap</code>:</p> <pre><code>import cats.instances.either._ // for Semigroupal\n\ntype ErrorOr[A] = Either[Vector[String], A]\n\nSemigroupal[ErrorOr].product(\nLeft(Vector(\"Error 1\")),\nLeft(Vector(\"Error 2\"))\n)\n// res7: ErrorOr[(Nothing, Nothing)] = Left(Vector(Error 1))\n</code></pre>"},{"location":"notes/scala/04-semigroupal-and-applicatives/#semigroupal-with-monads","title":"Semigroupal with Monads","text":"<p>The reason why <code>Either</code> and <code>List</code> is weird is because they are both monads. <code>Monad</code> extends <code>Semigroupal</code> and has a consistent, standard definition of <code>product</code> in terms of <code>map</code> and <code>flatMap</code>. The consistency is needed for  higher level abstractions.</p> <p><code>Future</code> only works because we create the futures before we use <code>product</code>.</p> <p>So why semigroupal? We can create data types that have instances of <code>Semigroupal</code> (and <code>Applicative</code>) but not <code>Monad</code>. This enables us to have useful <code>product</code> implementations.</p>"},{"location":"notes/scala/04-semigroupal-and-applicatives/#exercise-implement-monads-product","title":"Exercise: Implement Monad's Product","text":"<p>Implement <code>product</code> in terms of <code>flatMap</code>:</p> <pre><code>import cats.syntax.flatMap._ // for flatMap\nimport cats.syntax.functor._ // for map\nimport cats.Monad\n\ndef product[M[_]: Monad, A, B](x: M[A], y: M[B]): M[(A, B)] =\nx.flatMap(a =&gt; y.map(b =&gt; (a, b)))\n</code></pre> <p>which is the same as:</p> <pre><code>def product[M[_]: Monad, A, B](x: M[A], y: M[B]): M[(A, B)] =\nfor {\na &lt;- x\nb &lt;- y\n} yield (a, b)\n</code></pre> <p>This explains why <code>List</code> does not zip and <code>Either</code> only takes the first error.</p>"},{"location":"notes/scala/04-semigroupal-and-applicatives/#validated","title":"Validated","text":"<p>Cats provides a data type called <code>Validated</code> that has an instance of <code>Semigroupal</code> but no instance of <code>Monad</code> (which <code>Either</code> does). The <code>product</code> can then aggregate errors.</p> <pre><code>import cats.Semigroupal\nimport cats.data.Validated\nimport cats.instances.list._ // for Monoid\n\ntype AllErrorsOr[A] = Validated[List[String], A]\n\nSemigroupal[AllErrorsOr].product(\nValidated.invalid(List(\"Error 1\")),\nValidated.invalid(List(\"Error 2\"))\n)\n// res1: AllErrorsOr[(Nothing, Nothing)] = Invalid(List(Error 1, Error 2))\n</code></pre> <p>We can use <code>Validated</code> to accumulate errors and <code>Either</code> to fail fast.</p> <p><code>Validated</code> isn't a monad, so it doesn't have <code>flatMap</code> but it does have <code>andThen</code> for something similar. It isn't called <code>flatMap</code> because it doesn't follow all the laws of monads.</p>"},{"location":"notes/scala/04-semigroupal-and-applicatives/#exercise-form-validation","title":"Exercise - Form Validation","text":"<pre><code>TODO\n</code></pre>"},{"location":"notes/scala/04-semigroupal-and-applicatives/#apply-and-applicative","title":"Apply and Applicative","text":"<p>Semigroupals are not referenced frequently - they provide a subset of the functionality of another type class, applicative functor or \"applicative\" for short.</p> <p>Cats provide two type classes to model applicatives: </p> <ol> <li><code>Apply</code> which extends <code>Semigroupal</code> and <code>Functor</code> and adds <code>ap</code> method, which applies a parameter to a function with a context. </li> <li><code>Applicative</code> extends <code>Apply</code> and adds <code>pure</code> method.</li> </ol> <pre><code>trait Apply[F[_]] extends Semigroupal[F] with Functor[F] {\ndef ap[A, B](ff: F[A =&gt; B])(fa: F[A]): F[B]\n\ndef product[A, B](fa: F[A], fb: F[B]): F[(A, B)] =\nap(map(fa)(a =&gt; (b: B) =&gt; (a, b)))(fb)\n}\n\ntrait Applicative[F[_]] extends Apply[F] {\ndef pure[A](a: A): F[A]\n}\n</code></pre> <ul> <li>The <code>ap</code> method  applies a parameter <code>fa</code> to a function <code>ff</code> within a context <code>F[_]</code>.</li> <li>The <code>product</code> is defined in terms of <code>ap</code> and <code>map</code>.</li> </ul> <p><code>ap</code>, <code>map</code>, and <code>product</code> are tightly bound - each one can be expressed in terms of the other.</p> <p><code>Applicative</code> introduces <code>pure</code> method to create an instance from an unwrapped value.</p> <p><code>Applicative</code> is to <code>Apply</code> as <code>Monoid</code> is to <code>Semigroup</code>.</p>"},{"location":"notes/scala/04-semigroupal-and-applicatives/#excercise-define-ap-map-and-product-in-monad-only-in-flatmap-and-pure","title":"Excercise - Define <code>ap</code>, <code>map</code>, and <code>product</code> in <code>Monad</code> only in <code>flatMap</code> and <code>pure</code>","text":"<p>From previous Monad seciton, we already defined <code>map</code></p> <pre><code>trait Monad[F[_]] extends Applicative[F] with FlatMap[F] {\ndef pure[A](a: A): F[A]\n\ndef flatMap[A, B](value: F[A])(func: A =&gt; F[B]): F[B]\n\ndef map[A, B](value: F[A])(func: A =&gt; B): F[B] =\nflatMap(value)(a =&gt; pure(func(a)))\n}\n</code></pre> <p>How do we define <code>def ap[A, B](ff: F[A =&gt; B])(fa: F[A]): F[B]</code>?</p> <pre><code>    def ap[A, B](ff: F[A =&gt; B])(fa: F[A]): F[B] =\nfor {\nf &lt;- ff\na &lt;- fa\n} yield f(a)\n</code></pre> <p>or </p> <pre><code>    def ap[A, B](ff: F[A =&gt; B])(fa: F[A]): F[B] =\nff.flatMap(f =&gt; fa.map(f))\n</code></pre> <p>Putting it together (and pulling <code>product</code> definition in <code>Apply</code>)</p> <pre><code>trait Monad[F[_]] extends Applicative[F] with FlatMap[F] {\ndef pure[A](a: A): F[A]\n\ndef flatMap[A, B](value: F[A])(func: A =&gt; F[B]): F[B]\n\ndef map[A, B](value: F[A])(func: A =&gt; B): F[B] =\nflatMap(value)(a =&gt; pure(func(a)))\n\ndef ap[A, B](ff: F[A =&gt; B])(fa: F[A]): F[B] =\nflatMap(ff)(f =&gt; map(fa)(f))\n\ndef product[A, B](fa: F[A], fb: F[B]): F[(A, B)] =\nap(map(fa)(a =&gt; (b: B) =&gt; (a, b)))(fb)\n}\n</code></pre> <p>Replacing <code>map</code> and <code>ap</code> (need to double check my code here):</p> <pre><code>trait Monad[F[_]] extends Applicative[F] with FlatMap[F] {\ndef pure[A](a: A): F[A]\n\ndef flatMap[A, B](value: F[A])(func: A =&gt; F[B]): F[B]\n\ndef map[A, B](value: F[A])(func: A =&gt; B): F[B] =\nflatMap(value)(a =&gt; pure(func(a)))\n\ndef ap[A, B](ff: F[A =&gt; B])(fa: F[A]): F[B] =\nflatMap(ff)(f =&gt; flatMap(fa)(a =&gt; pure(f(a))))\n\n//Yikes\ndef product[A, B](fa: F[A], fb: F[B]): F[(A, B)] =\nflatMap(flatMap(fa)(a =&gt; pure((b: B) =&gt; (a, b))))(f =&gt; flatMap(fb)(b =&gt; pure(f(b))))\n}\n</code></pre>"},{"location":"notes/scala/05-foldable-and-traverse/","title":"Foldable and Traverse","text":"<ul> <li><code>Foldable</code> abstracts the <code>foldLeft</code> and <code>foldRight</code> operations.</li> <li><code>Traverse</code> is a higher-level abstraction that uses <code>Applicative</code> to iterate with less pain than folding.</li> </ul>"},{"location":"notes/scala/05-foldable-and-traverse/#foldable","title":"Foldable","text":"<p><code>Foldable</code> type class contains <code>foldLeft</code> and <code>foldRight</code> methods.</p> <p>Commonly used in sequences like <code>Lists</code>, <code>Vectors</code>, and <code>Streams</code>.</p> <p>It is a great use case for <code>Monoids</code> and <code>Eval</code> monad.</p>"},{"location":"notes/scala/05-foldable-and-traverse/#folds-and-folding","title":"Folds and Folding","text":"<p>The concept of \"folding\" - have an accumulator value and a binary function to combine the accumulator with each element in the sequence.</p> <pre><code>def show[A](list: List[A]): String =\nlist.foldLeft(\"nil\")((accum, item) =&gt; s\"$item then $accum\")\n\nshow(Nil)\n// res0: String = nil\n\nshow(List(1, 2, 3))\n// res1: String = 3 then 2 then 1 then nil\n</code></pre> <p>We can operate on the sequence in two ways:</p> <ol> <li>left - beginning to end (<code>foldLeft</code>)</li> <li>right - end to beginning (<code>foldRight</code>)</li> </ol> <p>For example</p> <pre><code>List(1, 2, 3).foldLeft(0)(_ + _)\n// res2: Int = 6\n\nList(1, 2, 3).foldRight(0)(_ + _)\n// res3: Int = 6\n</code></pre> <p>Addition is associative, so both operations gives us the same result.</p> <p>It would differ if the binary was non-associative:</p> <pre><code>List(1, 2, 3).foldLeft(0)(_ - _)\n// res4: Int = -6\n\nList(1, 2, 3).foldRight(0)(_ - _)\n// res5: Int = 2\n</code></pre>"},{"location":"notes/scala/05-foldable-and-traverse/#foldable-with-monoids","title":"Foldable with Monoids","text":"<p>Cats provides two functions in <code>Foldable</code> on top of <code>foldLeft</code> that takes advantage of <code>Monoids</code>.</p> <ul> <li><code>combineAll</code> (alias of <code>fold</code>) - combines all elements in the sequence (using <code>combine</code> in <code>Monoid</code>, starting with <code>empty</code> in <code>Monoid</code>)</li> <li><code>foldMap</code> - maps a function over the sequence and combines the results</li> </ul>"},{"location":"notes/scala/05-foldable-and-traverse/#foldable-in-cats","title":"Foldable in Cats","text":"<p><code>foldLeft</code> is pretty much what you expect. Not much to add.</p> <p><code>foldRight</code> is different though. It is defined in terms of <code>Eval</code> monad:</p> <pre><code>def foldRight[A, B](fa: F[A], lb: Eval[B])(f: (A, Eval[B]) =&gt; Eval[B]): Eval[B]\n</code></pre> <p>We can use <code>Eval</code> to keep <code>foldRight</code> stack safe, even when a data type's <code>foldRight</code> default implmentation isn't.</p> <p>Take <code>Stream</code> for example. It isn't stack safe:</p> <pre><code>import cats.Eval\nimport cats.Foldable\n\ndef bigData = (1 to 100000).toStream\n\nbigData.foldRight(0L)(_ + _)\n// java.lang.StackOverflowError ...\n</code></pre> <p>Using <code>Foldable</code> can make it stack safe</p> <pre><code>import cats.instances.stream._ // for Foldable\n\nval eval: Eval[Long] =\nFoldable[Stream].\nfoldRight(bigData, Eval.now(0L)) { (num, eval) =&gt;\neval.map(_ + num)\n}\n\neval.value\n// res7: Long = 5000050000\n</code></pre>"},{"location":"notes/scala/05-foldable-and-traverse/#exercise-fold-using-empty-list-and","title":"Exercise - Fold using empty list and <code>::</code>","text":"<pre><code>List(1, 2, 3).foldLeft(List.empty[Int])((a, i) =&gt; i :: a)\n// res6: List[Int] = List(3, 2, 1)\n\nList(1, 2, 3).foldRight(List.empty[Int])((i, a) =&gt; i :: a)\n// res7: List[Int] = List(1, 2, 3)\n</code></pre>"},{"location":"notes/scala/05-foldable-and-traverse/#exercise-define-other-methods","title":"Exercise - Define other methods","text":"<p><code>foldLeft</code> and <code>foldRight</code> are general methods that do a lot of things. We can use them to implement other, high-level sequence operations.</p> <pre><code>def map[A, B](list: List[A])(func: A =&gt; B): List[B] =\nlist.foldRight(List.empty[B])((a, agg) =&gt; func(a) :: agg)\n\ndef flatMap[A, B](list: List[A])(func: A =&gt; List[B]): List[B] =\nlist.foldRight(List.empty[B])((a, agg) =&gt; func(a) ::: agg)\n\ndef filter[A](list: List[A])(func: A =&gt; Boolean): List[A] =\nlist.foldRight(List.empty[A])((a, agg) =&gt; if(func(a)) a :: agg else agg)\n\ndef sum[A: Monoid](list: List[A]) = list.foldRight(Monoid[A].empty)((a, agg) =&gt; a |+| agg)\n// list.foldRight(Monoid[A].empty)(Monoid[A].combine)\n</code></pre>"},{"location":"notes/scala/05-foldable-and-traverse/#traverse","title":"Traverse","text":"<p><code>Traverse</code> is a higher-level type class that leverages <code>Applicatives</code> to provide a more convenient, lawful, pattern for iteration.</p>"},{"location":"notes/scala/99-heirarchy-of-type-classes/","title":"Heirarchy of Sequencing Type Classes","text":"<p>(See also this nice infographic)</p> <p>Each type classes represents:</p> <ul> <li>represents a set of sequencing semantics</li> <li>represents a set of charateristic methods</li> <li>defines the functionality of its supertypes in terms of them</li> </ul> <p>The inheritance relationships are constant across all instances of a type class.</p> <ul> <li><code>Apply</code> defines <code>product</code> in terms of <code>ap</code> and <code>map</code></li> <li><code>Monad</code> defines <code>product</code>, <code>ap</code>, and <code>map</code> in terms of <code>pure</code> and <code>flatMap</code>.</li> </ul> <pre><code>trait Monad[F[_]] extends Applicative[F] with FlatMap[F] {\ndef pure[A](a: A): F[A]\n\ndef flatMap[A, B](value: F[A])(func: A =&gt; F[B]): F[B]\n\ndef map[A, B](value: F[A])(func: A =&gt; B): F[B] =\nflatMap(value)(a =&gt; pure(func(a)))\n\ndef ap[A, B](ff: F[A =&gt; B])(fa: F[A]): F[B] =\n}\n</code></pre> <p>For example, let's say we have two data types:</p> <ul> <li><code>Foo</code> is a monad. It has an instance of <code>Monad</code> type class that implements <code>pure</code> and <code>flatMap</code>. <code>ap</code>, <code>product</code>, and <code>map</code> are the inherited standard definitions.</li> <li><code>Bar</code> is an applicative functor. It has an instance of <code>Applicative</code> that implements <code>pure</code> and <code>ap</code>. <code>product</code> and <code>map</code> are inherited standard definitions.</li> </ul> <p>We know more about <code>Foo</code> than <code>Bar</code>. <code>Monad</code> is a subtype of <code>Applicative</code>, so we can guarantee the all the properties of <code>Bar</code> for <code>Foo</code> as well. But <code>Foo</code> has another property we can guarantee (i.e. <code>flatMap</code>) that we cannot guarantee with <code>Bar</code>. On the other hand, we know that <code>Bar</code> may have wider range of behaviors than <code>Foo</code>, since it doesn't have to follow laws brought it by <code>flatMap</code>.</p> <p>This is a trade off of power versus constraint. The more constraints, the better known behaviors, the fewer behavior it can model.</p> <p>Monads can serve a lot of behaviors while providing good guarantees about those behaviors. Sometimes, though, it may not be right for the job.</p> <p>Monads provide strict sequencing, applicatives and semigroupals do not. We can use the latter for parallel/independent computations that monads cannot do.</p>"},{"location":"notes/scala/higher-kinds-and-type-constructors/","title":"Higher Kinds and Type Constructors","text":"<p>Kinds are like types for types. They describe the number of \"holes\" (or type parameters) in a type.</p> <p>Regular types have no \"holes\" while type constructors have holes that need to be \"filled\" to produce a type.</p> <ul> <li><code>List</code> is a type constructor with one hole, takes one parameter</li> <li><code>List[A]</code> is a type, produced using a type parameter</li> </ul> <p>This is analogous to functions and values. Functions are \"value constructors\"</p> <ul> <li><code>math.abs</code> is a function, takes one parameter</li> <li><code>math.abs(x)</code> is a value, produced using a value parameter</li> </ul> <p>In Scala, we declare type constructors using underscores.</p> <pre><code>// Declare F using underscores:\ndef myMethod[F[_]] = {\n\n// Reference F without underscores:\nval functor = Functor.apply[F]\n\n// ...\n}\n</code></pre> <p>Analously, we define a function's parameters in its definition and omit them when referring to it.</p> <pre><code>// Declare f specifying parameters:\nval f = (x: Int) =&gt; x * 2\n\n// Reference f without parameters:\nval f2 = f andThen f\n</code></pre> <p>This is an advanced feature, so in Scala we have to enable support. Either by importing it or adding in the <code>scalacOptions</code> in <code>build.sbt</code></p> <pre><code>import scala.language.higherKinds\n</code></pre> <pre><code>scalacOptions += \"-language:higherKinds\"\n</code></pre>"},{"location":"notes/scala/selections/","title":"Selections","text":"<p>Two questions:</p> <ul> <li>How does types and subtypes relate?</li> </ul> <p>If we create an instance of <code>JsonWriter[Option[Int]]</code>, will <code>Json.toJson(Some(1))</code> use this instance?</p> <ul> <li>How do we choose between type classes when there is more than one available?</li> </ul>"},{"location":"notes/scala/selections/#variance","title":"Variance","text":"<p>We can add variance to the type parameter for a type class.</p> <p><code>B</code> is a subtype of <code>A</code> if we can use a value of type <code>B</code> anywhere <code>A</code> is expected.</p> <p>The idea of covariance and contravariance is introduced when using variance with type constructors.</p>"},{"location":"notes/scala/selections/#covariance","title":"Covariance","text":"<p>Covariance means <code>F[B]</code> is a subtype of <code>F[A]</code> if <code>B</code> is a subtype of <code>A</code>. Many collections like <code>List</code> or <code>Option</code> are covariant.</p> <pre><code>trait List[+A]\ntrait Option[+A]\n</code></pre> <p>With covariant, something like this is possible:</p> <pre><code>sealed trait Shape\ncase class Circle(radius: Double) extends Shape\n\nval circles: List[Circle] = ???\nval shapes: List[Shape] = circles\n</code></pre>"},{"location":"notes/scala/selections/#contravariance","title":"Contravariance","text":"<p>Contravariance means <code>F[A]</code> is a subtyp of <code>F[B]</code> if <code>B</code> is a subtype of <code>A</code>. Our example <code>JsonWriter</code> is an example of this.</p> <pre><code>trait JsonWriter[-A] {\ndef write(value: A): Json\n}\n</code></pre> <p>In order to understand this, lets an example with <code>Circle</code>, <code>Shape</code>, and our <code>JsonWriter</code>:</p> <pre><code>val shape: Shape = ???\nval circle: Circle = ???\n\nval shapeWriter: JsonWriter[Shape] = ???\nval circleWriter: JsonWriter[Circle] = ???\n\ndef format[A](value: A, writer: JsonWriter[A]): Json =\nwriter.write(value)\n</code></pre> <p>Which combinations makes sense? Obviously, passing a <code>Circle</code> value and <code>JsonWriter[Circle]</code> makes sense.</p> <p>But what about passing a <code>Shape</code> value and <code>JsonWriter[Circle]</code>? That would not work because not all shapes are circles. This means we cannot substitute <code>JsonWriter[Shape]</code> with <code>JsonWriter[Circle]</code>.</p> <p>But what about passing a <code>Circle</code> value and <code>JsonWriter[Shape]</code>? That is fine because a <code>Circle</code> is a <code>Shape</code> and can be treated as such. This means we can substitute <code>JsonWriter[Circle]</code> with <code>JsonWriter[Shape]</code>.</p> <p>From this we learned that <code>JsonWriter[Shape]</code> is a subtype of <code>JsonWriter[Circle]</code>, because we can replace any <code>JsonWriter[Circle]</code> with <code>JsonWriter[Shape]</code>.</p>"},{"location":"notes/scala/selections/#co-vs-contra","title":"Co vs Contra","text":"<p>So how do we tell if a type parameter is covariant or contravariant? It depends on what we are doing with that type.</p> <p>It is contravariant if we are performing actions on instances of the type. In <code>JsonWriter</code>, it writes a value of the type parameter.</p> <p>It is covariant if we are reading from instances of the type. <code>List</code> and <code>Option</code> have covariant type parameters because they are collections. Their only functionality is to read the value of the instance of the type parameters.</p> <p>Given this, we can say parameters types are contravariant and return types are covariant for functions. To understand this, let's make a trait <code>Function1[P,R]</code>, which holds a function that takes a single parameter of type <code>P</code> and returns a value of type <code>R</code>. Using variance, the proper declaration would be:</p> <pre><code>trait Function1[-P, +R] {\ndef exec(param: P): R\n}\n</code></pre> <p>So, <code>Function1[Shape, Circle]</code> is a subtype of <code>Function1[Circle, Shape]</code>. Does this make sense? Let's test this theory.</p> <pre><code>//Redefining Shape\nsealte trait Shape {\ndef area: Double\n}\n//Redefining Circle\ncase class Circle(radius: Double) extends Shape {\ndef area = Math.pi * radius * radius\n}\n\nval func1: Function1[Shape, Circle] = new Function {\n//Takes in a shape and returns a circle with the same area\ndef func(param: Shape): Circle = {\nval r = Math.sqrt(param.area/Math.pi)\nCircle(r)\n}\n}\n\nval func2: Function1[Circle, Shape] = new Function {\n//Creates a new instance of Shape with area defined\n//as the same as the radius of the circle.\ndef func(param: Circle): Shape = {\nnew Shape {\ndef area = param.radius\n}\n}\n}\n</code></pre> <p>Now let's say we do:</p> <pre><code>val shape = new Shape {\ndef area = 4\n}\n\nval r = func1.exec(shape).radius\n</code></pre> <p>The compiler won't complain, because <code>func1</code> take in a shape and returns a circle, which we can call radius on. Cool. Can we replace <code>func1</code> with <code>func2</code>?</p> <pre><code>val r = func2.exec(shape).radius\n</code></pre> <p>No, no we cannot. Two issues. First, we passed in an object that wasn't <code>Circle</code> as a parameter. So <code>param.radius</code> won't compile. Second, we called <code>radius</code> on the return value of the <code>exec</code> method, but the returned Shape object doesn't have a radius method. So <code>Function1[Circle, Shape]</code> is not a subtype of <code>Function1[Shape, Circle]</code>.</p> <p>How about the other way around?</p> <pre><code>val a = func2.exec(Circle(2)).area\n</code></pre> <p>This is a valid statement. <code>func2</code> takes in a circle and returns a Shape with an area function that returns the same value as the circle's area. Cool. Now let's try to substitute with <code>func1</code>.</p> <pre><code>val a = func1.exec(Circle(2)).area\n</code></pre> <p>Does this work? Yes! <code>func1</code> is now taking in a <code>Circle</code>, which is fine because it treating it as a shape. Anything done on <code>Shape</code> can be done to <code>Circle</code>. The <code>exec</code> method now returns an instance of <code>Circle</code>, which we can call <code>area</code> method on, because anything <code>Shape</code> can do, <code>Circle</code> can do it as well. So <code>Function1[Shape, Circle]</code> is a subtype of <code>Function1[Circle, Shape]</code>.</p> <p>If <code>B</code> is a subtype of <code>A</code> and <code>Function1[A,B]</code> is a subtype of <code>Function1[B,A]</code>, then the first parameter type is contravariant and the second is covariant. Hence <code>Function1[-P,+R]</code>.</p>"},{"location":"notes/scala/selections/#invariance","title":"Invariance","text":"<pre><code>trait F[A]\n</code></pre> <p><code>F[A]</code> and <code>F[B]</code> are never subtypes of each other, no matter the relationship between <code>A</code> and <code>B</code>.</p>"},{"location":"notes/scala/selections/#controlling-selection","title":"Controlling Selection","text":"<p>When the compiler looks for an implicit, it looks for one matching the type or subtype. We can use variance to control somewhat how implicits are selected.</p> <p>This brings up two questions. Take the example:</p> <pre><code>sealed trait A\nfinal case object B extends A\nfinal case object C extends A\n</code></pre> <ol> <li>Will an instance defined on a supertype if available? E.g. we have one defined for <code>A</code>, can we use it if we're looking one for <code>B</code> or <code>C</code>?</li> <li>Will an instance of subtype be selected over the supertype? E.g. we have defined <code>A</code> and <code>B</code>, will <code>B</code> be selected over <code>A</code>?</li> </ol> <p>Both can't happen:</p> Type Class Variance Invariant Covariant Contravariant Supertype instance used? No No Yes More specific type preferred? No Yes No <p>Cats prefers invariant, to allow more control. This does bring up the scenario where if we have value of type <code>Some[Int]</code>, a type class instance of <code>Option</code> won't be used. This can be solved by having something like <code>Some(1): Option[Int]</code> or using \"smart  constructors\" like <code>Option.apply</code>, <code>Option.empty</code>, <code>some</code>, and <code>none</code>.</p>"},{"location":"notes/scala/cats/2019-01-19-type-classes/","title":"Type Classes","text":"<p>I decided to take a crack at learning the Cats library for Scala. This serves as reference for my notes. You'll notice that contents will mirror the book, and pieces of it will be very similar if not identical to it as well. Again, this serves as my notes and will just contain the pieces that I think are important, not obvious, or a good reminder.</p> <p>A lot of tools provided by Cats are in the form of type classes, a programming pattern that allows use to add additional functionality to existing libraries. This avoids inheritance and changing the libraries' source code.</p>"},{"location":"notes/scala/cats/2019-01-19-type-classes/#anatomy-of-a-type-class","title":"Anatomy of a Type Class","text":"<p>Type class pattern has three components:</p> <ul> <li>The type class</li> <li>The instances for particular types</li> <li>The interface methods exposed</li> </ul>"},{"location":"notes/scala/cats/2019-01-19-type-classes/#type-class","title":"Type Class","text":"<p>A type class is an interface or API that represents some functionality we want to implement. In Cats, a type class is represented by a trait with at least one type parameter</p> <p>Ex: We want the functionality to serialize to JSON</p> <pre><code>//Type class\ntrait JsonWriter[A] {\ndef write(value: A): Json\n}\n</code></pre>"},{"location":"notes/scala/cats/2019-01-19-type-classes/#type-class-instances","title":"Type Class Instances","text":"<p>The instances of a type class provide implementations for the types we care about.</p> <p>In Scala, we create concrete implementations of the type class and make them <code>implicit</code>.</p> <pre><code>final case class Person(name: String, email: String)\n\nobject JsonWriterInstances {\n//For string\nimplicit val stringWriter: JsonWriter[String] =\nnew JsonWriter[String] {\ndef write(value: String): Json =\nJsString(value)\n}\n\n\n//For Person\nimplicit val personWriter: JsonWriter[Person] =\nnew JsonWriter[Person] {\ndef write(value: Person): Json =\nJsObject(Map(\n\"name\" -&gt; JsString(value.name),\n\"email\" -&gt; JsString(value.email)\n))\n}\n\n//etc.\n}\n</code></pre>"},{"location":"notes/scala/cats/2019-01-19-type-classes/#type-class-interface","title":"Type Class Interface","text":"<p>A type class interface is any functionality that we expose, taking an instance of the type class as an <code>implicit</code> paramter.</p> <p>This is done two ways, interface objects and interface syntax.</p>"},{"location":"notes/scala/cats/2019-01-19-type-classes/#interface-objects","title":"Interface Objects","text":"<p>One form of an interface is to place methods in a singleton object.</p> <pre><code>object Json {\ndef toJson[A](value: A)(implicit w: JsonWriter[A]): Json =\nw.write(value)\n}\n</code></pre> <p>and to use the interface:</p> <pre><code>import JsonWriterInstances._\n\nJson.toJson(Person(\"Dave\", \"dave@example.com\"))\n</code></pre>"},{"location":"notes/scala/cats/2019-01-19-type-classes/#interface-syntax","title":"Interface Syntax","text":"<p>Another way to create an interface is to use extension methods. (This is referred to as syntax in Cats).</p> <pre><code>object JsonSyntax {\nimplicit class JsonWriterOps[A](value: A) {\ndef toJson(implicit w: JsonWriter[A]): Json =\nw.write(value)\n}\n}\n</code></pre> <p>and to use the interface:</p> <pre><code>import JsonWriterInstances._\nimport JsonSyntax._\n\nPerson(\"Dave\", \"dave@example.com\").toJson\n</code></pre> <p>This took me a second to understand what was happening here, as I am not familiar with extension methods. The way I understand it, <code>Person</code> doesn't have a <code>toJson</code> method, so the Scala compiler looks for a way for it to have it. By using the <code>implicit class</code>, the compiler passes in the instance of <code>Person</code> as part of the constructor and creates an instance of <code>JsonWriterOps</code>. With this implicit, <code>Person</code> can call <code>toJson</code>.</p>"},{"location":"notes/scala/cats/2019-01-19-type-classes/#conclusion","title":"Conclusion","text":"<p>That's basically it! Using type classes, we can define functionality and it's implementations for specific types. It's a pretty cool pattern to implement.</p> <p>The main advantage that is apparent to me is the ability to have on demand functionality. We can serialize <code>Person</code> in different ways for different parts of a program. This on demand feature has definite benefits over inheritance, which requires implementation of functionality at the time of writing code, or implementing functionality in the libraries iteself.</p> <p>Implicits make type class implementations look very clean as well. The only potential issue I see is that the use of extension methods may not be apparent, if that interface is used.</p> <p>The purpose of implicits hasn't been clear to me, in general, since it seemed to only make the declaration of the parameter passed less clear when looking at the code. However, I can see how it can be useful as long as there is a standard practice of when it is used, rather than making parameters implicity arbitrarily. In Cats, they set the standard of type classes to use implicits. However, we can also implement type classes without using implicits. It would be the same as the examle above, with the only change being to explicitly pass in the type class instance to the type class interface.</p>"},{"location":"notes/scala/cats/2019-01-23-implicits/","title":"Implicits","text":"<p>Continuing my reading of Scala With Cats.</p> <p>Couple things to know when using implicits</p>"},{"location":"notes/scala/cats/2019-01-23-implicits/#packaging-implicits","title":"Packaging Implicits","text":"<p>Any definition marked <code>implicit</code> in Scala must be placed inside an object or trait rather than top level. In a previous post, we created an object called <code>JsonWriterInstances</code> to hold our type class instances. Another approach we could have taken is to place these instances in the companion object of <code>JsonWriter</code>. This is significant in Scala because it bring in the concept of implicit scope.</p>"},{"location":"notes/scala/cats/2019-01-23-implicits/#implicit-scope","title":"Implicit Scope","text":"<pre><code>Json.toJson(\"A string!\")\n</code></pre> <p>In the example above, the compiler will look for an instance type of <code>JsonWriter[String]</code> in the implicit scope at the call site. This includes:</p> <ul> <li>local or inherited definitions</li> <li>imported definitions</li> <li>definitions in the companion object of the type class or parameter type (in our example, <code>JsonWrite</code> and <code>String</code> respectively)</li> </ul> <p>If more than one definition is found, the compiler will fail with \"ambiguous implicit values\" error.</p> <p>In Cats, we can package type class instances in 4 ways:</p> By placing them in Bring into scope by an object such as <code>JsonWriterInstances</code> Importing a trait Inheritance the companion object of the type class Already in scope the companion object of the parameter type Already in scope"},{"location":"notes/scala/cats/2019-01-23-implicits/#recursive-implicit-resolution","title":"Recursive Implicit Resolution","text":"<p>The compiler can combine implicit definitions when searching for instances, making type classes with implicits a powerful tool.</p> <p>We can actually define implicits in two ways by defining:</p> <ol> <li>concrete instances as <code>implicit val</code>'s of the required type</li> <li><code>implicit</code> methods to construct instances from other type class instances.</li> </ol> <p>Why would we need to construct instances rather than defining concrete instances? Let's look back at <code>JsonWriter</code> type class. Say we want to use <code>Option</code> with it. We would need an instance of the type <code>JsonWriter[Option[A]]</code>. Meaning we would need to define one for every <code>A</code>:</p> <pre><code>implicit val optionPersonWriter: JsonWriter[Option[Int]] = ???\n\nimplicit val optionPersonWriter: JsonWriter[Option[Person]] = ???\n\n// etc\n</code></pre> <p>giving us a total of two new instances for every type we introduce. Luckily we can abstract the code.</p> <pre><code>implicit def optionWriter[A]\n(implicit writer: JsonWriter[A]): JsonWriter[Option[A]] =\nnew JsonWriter[Option[A]] {\ndef write(option: Option[A]): Json =\noption match {\ncase Some(aValue) =&gt; writer.write(aValue)\ncase None         =&gt; JsNull\n}\n}\n</code></pre> <p>Now when a compiler sees this:</p> <pre><code>Json.toJson(Option(\"A string\"))\n</code></pre> <p>it searches for an implicit <code>JsonWriter[Option[String]]</code>. If finds the method returning <code>JsonWriter[Option[A]]</code></p> <pre><code>Json.toJson(Option(\"A string\"))(optionWriter[String])\n</code></pre> <p>and recursively searches for a <code>JsonWriter[String]</code> to use as a parameter to <code>optionWriter</code>.</p> <pre><code>Json.toJson(Option(\"A string\"))(optionWriter(stringWriter))\n</code></pre> <p>With this, implicit resolution becomes a search throughout the whole domain of possible combinations of implicit definitions to find the right combination to give us a type class definition of the right type.</p>"},{"location":"notes/scala/cats/2019-01-23-implicits/#note-implicit-conversion","title":"Note: Implicit Conversion","text":"<p>When creating a type class instance constructor using <code>implicit def</code>, be sure to mark all parameters with <code>implicit</code>, so the compiler can fill these in during resolution. If not marked, it creates another programming pattern called implicit conversion which is frowned upon in Scala.</p>"},{"location":"notes/scala/cats/2019-01-23-implicits/#conclusion","title":"Conclusion","text":"<p>This really brings out the advantages of implicits. Implicit resolution is a powerful tool that lets the compiler automatically resolve parameters by automatically constructing the appropriate type. In my previous post, I mentioned that type classes can be implemented without <code>implicit</code>s. However, implicits are key if we want to utilize a powerful tool such as implicit resolution.</p>"},{"location":"notes/scala/cats/2019-02-18-monoids-cats/","title":"Monoids Cats","text":""},{"location":"notes/scala/cats/2019-02-18-monoids-cats/#monoid-type-class","title":"Monoid Type Class","text":"<p><code>cats.kernel.Monoid</code> (aliased <code>cats.Monoid</code>) extends <code>cats.external.Semigroup</code> (alias <code>cats.Semigroup</code>).</p> <p>Cats Kernel</p> <p>A subproject of Cats to provide a small set of type classes for libraries that don't need the full Cats toolbox. They are in the <code>cats.kernel</code> package, but they are aliased as <code>cats</code>.</p>"},{"location":"notes/scala/cats/2019-02-18-monoids-cats/#monoid-instances","title":"Monoid Instances","text":"<p><code>Monoid</code> has the same Cats pattern for the user interface, a companion object has an <code>apply</code> method.</p> <pre><code>import cats.Monoid\nimport cats.instances.string._ // for Monoid\n\nMonoid[String].combine(\"Hi \", \"there\")\n// res0: String = Hi there\n\nMonoid[String].empty\n// res1: String = \"\"\n</code></pre> <p>is the same thing as:</p> <pre><code>Monoid.apply[String].combine(\"Hi \", \"there\")\n// res2: String = Hi there\n\nMonoid.apply[String].empty\n// res3: String = \"\"\n</code></pre> <p>and if we don't need <code>empty</code>, then we can do this instead:</p> <pre><code>import cats.Semigroup\n\nSemigroup[String].combine(\"Hi \", \"there\")\n// res4: String = Hi there\n</code></pre>"},{"location":"notes/scala/cats/2019-02-18-monoids-cats/#monoid-syntax","title":"Monoid Syntax","text":"<p>Cats provides syntax for <code>combine</code> with <code>|+|</code>. It technically comes from <code>Semigroup</code>, so we need <code>cats.syntax.semigroup</code>:</p> <pre><code>import cats.instances.string._ // for Monoid\nimport cats.syntax.semigroup._ // for |+|\n\nval stringResult = \"Hi \" |+| \"there\" |+| Monoid[String].empty\n// stringResult: String = Hi there\n\nimport cats.instances.int._ // for Monoid\n\nval intResult = 1 |+| 2 |+| Monoid[Int].empty\n// intResult: Int = 3\n</code></pre>"},{"location":"notes/scala/cats/2019-02-18-monoids-cats/#example","title":"Example","text":"<p>A function that adds: <code>def add(items: List[Int]): Int</code></p> <pre><code>def add(items: List[Int]): Int = items.foldLeft(0)(_ + _)\n\n//or\n\nimport cats.Monoid\nimport cats.instances.int._\nimport cats.syntax.semigroup._\n\ndef add(items: List[Int]): Int =\nitems.foldLeft(Monoid[Int].empty)(_ |+| _)\n</code></pre> <p>A function that now adds <code>List[Option[Int]]</code>:</p> <pre><code>//Make it generic!!\n\nimport cats.Monoid\nimport cats.syntax.semigroup._ // for |+|\n\ndef add[A](items: List[A])(implicit monoid: Monoid[A]): A =\nitems.foldLeft(monoid.empty)(_ |+| _)\n</code></pre> <p>Equivalently with context bounds syntax:</p> <pre><code>def add[A: Monoid](items: List[A]): A =\nitems.foldLeft(Monoid[A].empty)(_ |+| _)\n</code></pre> <pre><code>import cats.instances.int._ // for Monoid\n\nadd(List(1, 2, 3))\n// res9: Int = 6\n\nimport cats.instances.option._ // for Monoid\n\nadd(List(Some(1), None, Some(2), None, Some(3)))\n// res10: Option[Int] = Some(6)\n</code></pre> <p>Now we want to sum of <code>Order</code>'s</p> <pre><code>case class Order(totalCost: Double, quantity: Double)\n</code></pre> <pre><code>implicit val monoid: Monoid[Order] = new Monoid[Order] {\ndef combine(o1: Order, o2: Order) =\nOrder(\no1.totalCost + o2.totalCost,\no1.quantity + o2.quantity\n)\n\ndef empty = Order(0, 0)\n}\n</code></pre>"},{"location":"notes/scala/cats/ad-hoc-polymorphism/","title":"Ad-hoc Polymorphism in Cats","text":"<p>Taking a deeper look into how ad-hoc polymorphism works with Scala Cats.</p> <p>The concept of polymorphism is the ability for a code that can work with multiple types.</p> <p>TODO What does ad-hoc mean here?</p> <p>This can be done in many different ways.</p>"},{"location":"notes/scala/cats/ad-hoc-polymorphism/#inheritance","title":"Inheritance","text":"<p>TODO Look up Type System</p> <p>With inheritance, polymorphism is achieved with subclasses.</p> <p>The OO way. Subclassing.</p> <p>Java supports inheritance.</p> <p>We can declare an interface or class with the desired functionality.</p> <p>Functionality vs Behavior</p> <p>Functionality - The function Behavior  - The implementation of the function</p> <pre><code>interface Animal {\npublic String speak();\n}\n</code></pre> <p>We can have many forms of <code>speak</code> by implementing the interface.</p> <pre><code>class Dog implements Animal {\npublic String speak() {\nreturn \"woof\";\n}\n}\n\nclass Cat implements Animal {\npublic String speak() {\nreturn \"woof\";\n}\n}\n</code></pre> <p>We can also override implemented behavior by subclassing</p> <pre><code>class BigDog extends Dog {\npublic String speak() {\nreturn \"WOOF\";\n}\n}\n</code></pre> <p>This overrides the previous behavior.</p> <p>The downside</p>"},{"location":"notes/scala/cats/ad-hoc-polymorphism/#trait-objects","title":"Trait Objects","text":""},{"location":"notes/service/api/","title":"Api","text":"<p>SDK vs API vs SPI (Service provider inerface)</p> <p>SPI - accessible from within the service https://stackoverflow.com/questions/2954372/difference-between-spi-and-api</p>"},{"location":"notes/system_design/0-general-approach/","title":"Overview","text":"<p>The goal of system design is to have a realistic end to end solution. We can start with a simple solution at first and iterate with scalability, availability, security, etc. We are not expected to design every single aspect.</p> <p>The general approach:</p> <ol> <li>Read the question</li> <li>Gather Requirements</li> <li>Perform Calculations</li> <li>Service API Design</li> <li>Database Design</li> <li>High Level Design</li> <li>Low Level Design</li> <li>Scalability and Other Issues</li> </ol>"},{"location":"notes/system_design/0-general-approach/#1-read-the-question","title":"1 - Read the Question","text":"<p>Pretty self explanatory</p>"},{"location":"notes/system_design/0-general-approach/#2-gather-requirements","title":"2 - Gather Requirements","text":"<p>Narrow the scope of your design. Ask clarifying questions and jot them down for later.</p> <p>Do we have an expected number of users?</p> <p>How frequent will this be used?</p>"},{"location":"notes/system_design/0-general-approach/#3-perform-calculations","title":"3 - Perform Calculations","text":"<p>There are 3 general things we can calculate in most cases:</p> <ol> <li>Data Storage - Take a rough estimate of the size of your data. You can confirm with your interviewer.</li> <li>Scale of System - Number of daily users, number of calls, etc.</li> <li>Expected Network Bandwidth</li> </ol> <p>Ex - Design YouTube</p> <p>Given these assumptions from Requirements Gathering:</p> Metric Value Number of users 1 billion Number of daily users 500 million Avg Views/User 5 Number of videos uploaded 1/300 of the number of views Avg Video Size 100 MB Video Upload Bandwidth 10 MB/min <p>The calculations would look like:</p> Metric Value Views/Sec 500M Users/Day * 5 Views/User / 86400 Sec/Day = 29K Videos/Sec Videos Uploaded/Sec 29K Videos/Sec / 300 Storage 97 Videos/sec * 100MB/Video = 9700 MB/Sec Bandwidth/Sec 0.17 * 97 - 16.49 MB/Sec"},{"location":"notes/system_design/0-general-approach/#4-service-api-design","title":"4 - Service API Design","text":"<p>We can use REST API to design basic requests we think our use cases needs. </p>"},{"location":"notes/system_design/0-general-approach/#5-database-design","title":"5 - Database Design","text":"<p>Choose relational or noSQL based on use case. You can mention to the interview that we can handle scalability iteratively, and we can revisit the decision you made here.</p> <p>You do not need to spend 20 minutes on this going into every detail. Just show the main columns (like the primary key).</p>"},{"location":"notes/system_design/0-general-approach/#6-high-level-design","title":"6 - High Level Design","text":"<p>Give a high level picture of the overall system architecture and its components, explaining what each component accomplishes.</p> <p></p>"},{"location":"notes/system_design/0-general-approach/#7-low-level-design","title":"7 - Low Level Design","text":"<p>Go into futher details for some of the components. The components you further into detail depend on the question. You can ask your interviewer on what specifics you should go into.</p> <p>Should I explain XX more?</p>"},{"location":"notes/system_design/0-general-approach/#8-scalability-other-issues","title":"8 - Scalability Other Issues","text":"<p>Talk about scaling and its solutions (partitioning, caching, load balancing, etc). Discuss bottlenecks - call out flaws.</p>"},{"location":"notes/system_design/0-general-approach/#case-study-url-shortening-service","title":"Case Study - URL Shortening Service","text":""},{"location":"notes/system_design/0-general-approach/#gather-requirements","title":"Gather Requirements","text":"<p>Functional Requirements</p> <ol> <li>Given a URL, our service should provide a shorter, unique URL.</li> <li>When users access this shorter URL, it should redirect to their original URL</li> <li>The URL will expire after a certain default time. Users can provide their own expiration date if needed.</li> </ol> <p>Non Functional Requirements</p> <ol> <li>System should be highly available</li> <li>URL redirection should happen with minimal latency</li> </ol>"},{"location":"notes/system_design/0-general-approach/#perform-calculations","title":"Perform Calculations","text":"<p>Assumptions:</p> Metric Value New Shortenings per month 1 million Size of Object 500 bytes Avg Read of Object 100 times Avg Lifetime 1 year <p>Calculations:</p> <p>Writes - 1 million/month = ~0.38 writes/sec Reads - 100 million/month = ~38 reads/sec Storage - 1 million objects/month * 12 months/year * 1 year * 500 bytes/object = 6 GB</p> <p>Bandwidth Write - 0.38 writes/sec * 500 bytes/write = 190 bytes/sec Bandwidth Read - 38 reads/sec * 500 bytes/read = 19 Kb/sec</p>"},{"location":"notes/system_design/0-general-approach/#service-api","title":"Service API","text":"<pre><code>createURL(url, expiration)\n</code></pre> <pre><code>deleteURL(url)\n</code></pre>"},{"location":"notes/system_design/0-general-approach/#database-design","title":"Database Design","text":"<p>This is a read intensive operation.</p> <p>We can create a DB for the URLs.</p> PK Hash Original URL Creation Date Expiration Date <p>noSQL or SQL? There isn't any relational data, so we can use noSQL.</p>"},{"location":"notes/system_design/0-general-approach/#high-level-design","title":"High Level Design","text":"<p>We have the web client -&gt; application server -&gt; DB</p>"},{"location":"notes/system_design/0-general-approach/#low-level-design","title":"Low Level Design","text":"<p>A closer look at our application server. How do we create the shortened url?</p>"},{"location":"notes/system_design/0-general-approach/#option-1-encoding-a-hash","title":"Option 1 - Encoding a Hash","text":"<p>We can use a hash and then encode the bits to be diplayed.</p> <p>We can encode the bits in base36 (a-z, 0-9), base 62 (a-z, A-Z, 0-9) or add \"+\", \"/\" to make it base64</p> <p>We need to decide how long the URL shortening should be? 6? 8? 10?</p> <p>With 6 letters, we have 64^6 = 68.7B possible values. This meets our expected sizing.</p> <p>Let's say we use MD5 hash - this produces 128 bits. After encoding we get more than 21 characters (base64 encodes 6 bits). We can take the first 6 characters. If there are conflicts we can take the next letter or something.</p> <p>Problems:</p> <ol> <li>If two users enter the same URL, it will produce the same URL shortened</li> <li>URL Encoded and Not URL encoded of the same URL will produce different shortened URLs.</li> </ol>"},{"location":"notes/system_design/0-general-approach/#option-2-generate-keys-offline","title":"Option 2 - Generate Keys Offline","text":"<p>We have a key generation service that generates random 6 letteer strings and stores them in a DB. When we create a new one, we just pull from this DB.</p> <p>Concurrency Problems? What if two servers are pulling at the same time? We can introduce locking on the items.</p> <p>How do we ensure that the key is marked as use as soon as it is provided? We can have to tables, one for not used, one for used. It can be moved to use and then providied the app server.</p> <p>What is the key db size? If it is storing base64 encoding, we can provide 68.7B 6 letter keys. If each letter is one byte, then 68.7B strings * 6 letters/string * 1 byte/letter = 412GB.</p> <p>How do we ensure high availability? We can have replicas of KGS.</p>"},{"location":"notes/system_design/1-general-considerations/","title":"General System Design Considerations","text":""},{"location":"notes/system_design/1-general-considerations/#trade-offs","title":"Trade Offs","text":"<p>Choices made when designing a system always have trade-offs. Here a couple of high-level trade offs.</p>"},{"location":"notes/system_design/1-general-considerations/#performance-vs-scalability","title":"Performance vs Scalability","text":"Scalable Performance increases (somewhat proportionally) to the amount of resources added. Performance The amount of work a system can do, or the size of work a system can handle. <p><code>TODO: How are these traded off?</code></p>"},{"location":"notes/system_design/1-general-considerations/#latency-vs-throughput","title":"Latency vs Throughput","text":"Latency Time to complete some unit of work. Throughput Amount of work completed per unit of time. <p>Generally, you should aim for max throughput with acceptable latency.</p>"},{"location":"notes/system_design/1-general-considerations/#availability-vs-consistency","title":"Availability vs Consistency","text":"<p>See CAP Theorem.</p>"},{"location":"notes/system_design/1-general-considerations/#availability-patterns","title":"Availability Patterns","text":"<p>Couple of ways to keep high availability.</p> <p>Note: Common association with availability is databases and CAP theorem, but this concept can be applied to other parts of the system - application servers, load balancers, etc.</p>"},{"location":"notes/system_design/1-general-considerations/#failover","title":"Failover","text":""},{"location":"notes/system_design/1-general-considerations/#active-passive","title":"Active-Passive","text":"<p>Only the active server is handling traffic.</p> <p>Heartbeats are sent from the active to the passive server on standby. If heartbeats are stopped/missed the passive server takes over the active's IP address and resumes the service.</p> <p>Downtime is determined by how long it takes for the passive system to start. (Cold start vs pre-warmed)</p> <p>Also known as master-slave failover.</p>"},{"location":"notes/system_design/1-general-considerations/#active-active","title":"Active-Active","text":"<p>Both servers are handling traffic, spreading the load between them.</p> <p>If they are public facing, DNS needs to know both IP's. If it is internal, the application needs to know about both servers.</p> <p>Also known as master-master failover.</p>"},{"location":"notes/system_design/1-general-considerations/#cons-of-failover","title":"Cons of Failover","text":"<ol> <li>More hardware and added complexity of switching to other machine or handling both.</li> <li>Potential data loss if system fails before copied to passive.</li> </ol>"},{"location":"notes/system_design/1-general-considerations/#replication","title":"Replication","text":"<p>THIS IS DATABASE SPECIFIC. SEE Scaling in DB.</p>"},{"location":"notes/system_design/asynchronism/","title":"Asynchronism","text":"<p>Async workflows help reduce times for expensive operations.</p> <p>Is this really true? It's not that it reduces times for expensive operations, it just reduces the API latency by doing it outside of the request.</p>"},{"location":"notes/system_design/asynchronism/#message-queues","title":"Message Queues","text":"Message Queue Receives, holds, and delivers messages. <p>Common arch pattern:</p> <ol> <li>App publishes a job to the queue, returns to the user a job status.</li> <li>A worker picks up the job from the queu, processes it, then signals the job is complete.</li> </ol> <p>User doesn't wait for the API call to perform the job, just the time for the API to put it into the queue.</p> <p>Redis is useful as a simple message broker but messages can be lost.</p> <p>RabbitMQ requires you to adapt the <code>AMQP</code> protocol and manage your own nodes.</p> <p>Amazon SQS is hosted but can have higer latency and has at least one deliver.</p>"},{"location":"notes/system_design/asynchronism/#task-queues-workers","title":"Task Queues (Workers?)","text":"<p>???</p>"},{"location":"notes/system_design/asynchronism/#back-pressure","title":"Back Pressure","text":"<p>If items are placed in a queue at a rate more than the workers consuming them, the queue can grow large.</p> <p>Back pressure limits the queue size to help maintain throughput.</p> <p>When a queue gets full, clients gets a server busy or HTTP 503 to try again later.</p>"},{"location":"notes/system_design/asynchronism/#cons-of-async","title":"Cons of Async","text":"<p>Adds delays and complexity, so shouldn't be used for simple operations.</p>"},{"location":"notes/system_design/cache/","title":"Cache","text":"<p>Caching can reduce load on servers and databases.</p>"},{"location":"notes/system_design/cache/#where-caching-resides","title":"Where Caching Resides","text":"<ul> <li>Client side - OS, browser</li> <li>CDN - CDN is considered a type of cache</li> <li>Web Server - Reverse proxies can serve static and dynamic content directly. Web servers can also cache requests and their responses.</li> <li>Database - DB's usually have some default caching set up.</li> <li>Application - In-memory caches such as memcached and Redis are key-value data held in RAM. RAM is more limited than disk so invalidation algorithms are important (e.g. LRU)</li> </ul>"},{"location":"notes/system_design/cache/#categories-of-caching","title":"Categories of Caching","text":"<p>There are multiple levels of caching that fall into two general categories: db queries and objects.</p>"},{"location":"notes/system_design/cache/#database-query-level","title":"Database Query Level","text":"<p>Hash the query as a key and store the result in the cache.</p> <p>Cons - If an item changes, you need to delete all cached keys involving that item. - Hard to delete a cached result with complex queries</p>"},{"location":"notes/system_design/cache/#object-level","title":"Object Level","text":"<p>Store data as an object/data structure. Remove if the data has changed. Allow for async processing - workers can assemble objects by using the cache (?)</p>"},{"location":"notes/system_design/cache/#updating-the-cache","title":"Updating the Cache","text":""},{"location":"notes/system_design/cache/#cache-aside","title":"Cache-Aside","text":"<p>The application is responsible for reading and writing from storage. Cache doesn't work with storage directly.</p> <p>The application:</p> <ul> <li>Looks in cache</li> <li>Looks in DB</li> <li>Adds to cache</li> <li>Returns result</li> </ul> <p>Memcached is used this way.</p> <p>Cons</p> <ul> <li>Cache miss has a delay (added cost of read from DB, write to cache)</li> <li>Data can get stale if updated in DB. Mitigated by a TTL or write-through</li> <li>When a node fails, it is replaced with an empty node.</li> </ul>"},{"location":"notes/system_design/cache/#write-through","title":"Write-Through","text":"<p>Application interacts with the cache as the DB, writing and reading data to it. The cache is responsible for reading and writing to the database.</p> <p>Write-through is slow because of the write operation, but reads are fast. This is okay generally since users are more tolerant of latency when updating data  than reading data. Data in the cache are not stale (when it gets updated, it'll update in the cache)</p> <p>Cons</p> <ul> <li>New node will not cache until item is updated. Mitigated by also adding cache-aside</li> <li>Most data written might be never read. Mitigated with a TTL.</li> </ul>"},{"location":"notes/system_design/cache/#write-behind-write-back","title":"Write-Behind (Write-Back)","text":"<p>It's like write-through but writes are async.</p> <p>Cons</p> <ul> <li>Data loss if cache goes down before data hits data store.</li> <li>Complex compared to other approaches.</li> </ul>"},{"location":"notes/system_design/cache/#refresh-ahead","title":"Refresh-Ahead","text":"<p>This can be used in the other caching methods above.</p> <p>Configure the cache to automatically refresh any recently accessed cache entry porior to its expiration.</p> <ul> <li>Reduce latency vs read-through if it can predice what items will be read.</li> </ul> <p>Cons</p> <ul> <li>Not accurate predictions result in reduced performance.</li> </ul>"},{"location":"notes/system_design/cache/#cons-of-cache","title":"Cons of Cache","text":"<ul> <li>Need to maintain consistency with source of truth, using cache invalidation, which is a difficult problem.</li> </ul> <p><code>TODO Cache Invalidation</code></p>"},{"location":"notes/system_design/content-delivery-network/","title":"Content Deliver Network (CDN)","text":"CDN Globally distributed network of proxy servers, serving content from locations closer to the user. <p>Usually serves static files like HTML/CSS/JS, photos, and videos. Some CDNs (like Amazon CloudFront) serve dynamic content.</p> <p>Benefits</p> <ul> <li>User receives content from data centers close to them</li> <li>Servers do not have to serve requests that CDN can fulfill</li> </ul>"},{"location":"notes/system_design/content-delivery-network/#push-cdns","title":"Push CDNs","text":"Push CDNs CDNs that receive new content when changes occur on your server. <p>You have to update content on the CDN. It is only updated when data is new or changed. This means traffic is low, but storage is high. Content is placed on CDNs once, instead of being pulled regularly.</p> <p>Sites with small amount of traffic or sites with really static content works well with this.</p>"},{"location":"notes/system_design/content-delivery-network/#pull-cdns","title":"Pull CDNs","text":"Pull CDNs CDNs that grab new content from your server when the first user requests the content. <p>Slower request until the content is cached on the CDN.</p> <p>A TTL determines how long content is cached. This minimizes storage, but can add redundant traffic if files expire when they haven't changed.</p> <p>Sites with heavy traffic work well with this. Traffic is spread out more evenly with recently-requested content on the CDN.</p>"},{"location":"notes/system_design/databases/","title":"Database","text":""},{"location":"notes/system_design/databases/#relational-database-management-system-rdbms","title":"Relational Database Management System (RDBMS)","text":"<p>Data is organized in tables.</p> <p>ACID is a property of relational databases</p> <ul> <li>Atomicity - Each transaction is all or nothing</li> <li>Consistency - Any transaction will bring the database from one valid state to another</li> <li>Isolation - Executing transactions concurrently has the same results as if the transactions were executed serially</li> <li>Durability - Once a transaction has been committed, it will remain so</li> </ul>"},{"location":"notes/system_design/databases/#scaling","title":"Scaling","text":"<ul> <li> <p>Master - slave replication. Master reads and writes, slaves reads. Slaves can also replicate to other slaves. If master is down, we can't write, just read.</p> <ul> <li>We need logic if we want to promote a slave to a master.</li> </ul> </li> <li> <p>Master - master replication. Both read and write and coordinate with each other.</p> <ul> <li>We need a LB or logic in choosing which master to invoke.</li> <li>Most are loosely consistent (to sync with each other) which breaks ACID or have higher latency.</li> <li>We need conflict resolution as more masters are added.</li> </ul> </li> </ul> <p>General downsides</p> <ul> <li>Loss of data if master dies before replicating</li> <li>High volume of writes will add load to slaves</li> <li>More slaves, more replication, causing lag.</li> </ul>"},{"location":"notes/system_design/databases/#federation-functional-parititoning","title":"Federation/ Functional Parititoning","text":"<p>Split databases into logic groups. One db for customers, one for orders, etc.</p> <p>This results in less traffic to each one and less replicaiton lag.</p> <p>Downsides - Joining is complex - App logic to determine which DB to choose - Not effective schema requires large functions or tables.</p>"},{"location":"notes/system_design/databases/#sharding","title":"Sharding","text":"<p>Splits data across multiple DBs.</p> <p>Less traffic, less replicaiton lag, smaller indices.</p> <p>Downsides</p> <ul> <li>Distribution is lopsided, power users can cause load on one shard.</li> <li>Joining across shards is complex.</li> <li>Rebalancing add complexity</li> </ul>"},{"location":"notes/system_design/databases/#denormalization","title":"Denormalization","text":"<p>Tried to improve reads at the expense of writes by duplicating data across tables.</p>"},{"location":"notes/system_design/databases/#nosql","title":"NoSQL","text":"<p>Most do not have ACID properties because they are eventually consistent</p> <p>They tend to have BASE properties</p> <ul> <li>Basically available - the system guarantees availability.</li> <li>Soft state - the state of the system may change over time, even without input.</li> <li>Eventual consistency - the system will become consistent over a period of time, given that the system doesn't receive input during that period.</li> </ul>"},{"location":"notes/system_design/databases/#consistency-patterns","title":"Consistency Patterns","text":"<p>With duplication of data across nodes, we need to consider how we synchronize them.</p> <p>See CAP Theorem for Consistency definition.</p>"},{"location":"notes/system_design/databases/#weak-consistency","title":"Weak Consistency","text":"<p>After a write, a read may or may not see it, best effort.</p> <p>Example - Video Calls. You may lose reception and for that time video is frozen, you'll not get the data.</p>"},{"location":"notes/system_design/databases/#eventual-consistency","title":"Eventual Consistency","text":"<p>After a write, a read will eventually see it (usually within milliseconds). Data is replicated asynchronously.</p> <p>This is seen in DNS and email. Works well in highly available systems.</p>"},{"location":"notes/system_design/databases/#stong-consistency","title":"Stong Consistency","text":"<p>After a write, reads will see it. Data is replicated synchronously.</p> <p>This is seen in file systems and RDBMS's. Works well in systems that needs transactions.</p>"},{"location":"notes/system_design/databases/#cap-theorem","title":"CAP Theorem","text":"<p>Consistency, Availability, Parition Tolerant</p> Consistency All nodes in a distributed system sees the same state or data at the same point in time. Every read receives the most recent write or an error Availability Resistance to failure. If some nodes are down, other nodes would be able to keep the system running. Every request to an active node receives a (non-error) response, without the guarantee that it contains the most recent write. Partition Tolerant The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes. <p>It is impossible for a distributed system to provide more than two of these properties</p> <p>CAP is frequently misunderstood as if one has to choose to abandon one of the three guarantees at all times. In fact, the choice is really between consistency and availability only when a network partition or failure happens; at all other times, no trade-off has to be made.</p> System C A P noSQL N Y Y RDBMD Y Y N <p>noSQL is not consistent, rather it has eventual consistency. Changes are not applied to every component in this distributed system at the same time. Hence \"eventual\".</p> <p>Relational DB's do not support distributed joins out of the box - it is very difficult to implement, so it does not support partitioning of data.</p> <p>Choose a system that meets the use cases' requirements.</p> <p>Example - An Ordering System (like Ebay)</p> <p>Consistency is important in this system. Otherwise an item may be over ordered. So we would go with relational.</p> <p>Ex: Twitter</p> <p>Twitter gave up consistency for high scalability with paritioning.</p> CAP Type Example CA A single node server. In the presence of the network partition, a distributed system is either available or consistent. CP If a network between two nodes break, it will refuse to respond to a request, so availability is gone. AP If a network between two nodes break, it will still process request, but not all nodes have the same data. So consistency is gone."},{"location":"notes/system_design/load-balancer/","title":"Load Balancer","text":"<p>LB distributes incoming requests to compute resources (e.g. application servers, dbs). LB's are good for </p> <ul> <li>Preventing requests from going to unhealthy servers.</li> <li>Preventing overloading resources.</li> <li>Eliminating single point of failures. (Is this really because of LB or because of scaling?)</li> </ul> <p>In general, good for horizontal scaling.</p> <p>LBs can be implemented with hardware (which is expensive) or software.</p> <p>Other benefits</p> <ul> <li>SSL termination - Encrypt server responses so that backend servers do not have to perform this expensive operations.</li> <li>Session persitence - Issue cookies and route specific cleint's request to the same instance (if the web app doesn't track session).</li> </ul> <p>As always, to keep high availability, it is common to set up more than one LB either using active-passive or active-active mode.</p> <p>Methods of routing:</p> <ul> <li>Random</li> <li>Least loaded</li> <li>Session/cookies</li> <li>Round robin or weighted round robin</li> <li>Layer 4</li> <li>Layer 7</li> </ul>"},{"location":"notes/system_design/load-balancer/#layer-4","title":"Layer 4","text":"<p>Layer 4 LB's look at the <code>transport layer</code> to distribute requests. This includes source and destination IP's, and ports. Not the actual content of the packet.</p> <p>These LB's forward network packages to and from the upstream server, performing NAT.</p> <p><code>TODO: transport layer, NAT</code></p>"},{"location":"notes/system_design/load-balancer/#layer-7","title":"Layer 7","text":"<p>Layer 7 LB's look at the <code>application layer</code> to distribute requests. This can include, contents of header, message, and cookies. LB's terminate network traffic, read the message, decide, and then open a connection to the selected server.</p> <p>LB can direct video traffic to servers that host vidoes while directing user billing traffic to security-hardened servers. This data is available on this layer.</p> <p>While LB 7 is more flexibile, LB 4 requires less time and compute. The difference may be minimal though.</p>"},{"location":"notes/system_design/reverse-proxy/","title":"Reverse Proxy","text":"Reverse Proxy Web server that centralizes internal services and provides a unified interface to the public. Requests from clients are forwarded to the appropriate server and then the reverse proxy returns the response to the customer. <p>Benefits:</p> <ul> <li>Increased security - Abstract backend, block IPs, limit connections, etc.</li> <li>Increased scalability and flexibility - Servers are hidden behind the reverse proxy's IP address. We can add/modify servers with ease.</li> <li>SSL termination</li> <li>Compression - compress server responses</li> <li>Caching - Return the response for cached requests</li> <li>Static content - Serve static content directly</li> </ul> <p>Load Balancer vs Reverse Proxy</p> <ul> <li>LB is useful when you have multiple servers with the same functionality</li> <li>Reverese Proxy is useful even if you have one for the above benefits.</li> </ul> <p>Solutions like NGINX and HAProxy can support both.</p>"},{"location":"notes/system_design/reverse-proxy/#cons","title":"Cons","text":"<ul> <li>Increased complexity to the system.</li> <li>Single point of failure. Can be mitigated with multiple reverse proxies (i.e. adding failovers), which also adds complexity.</li> </ul>"},{"location":"notes/system_design/scalability/","title":"Scalabilty","text":"<p>Clones - Having multiple machines to handle requests. - Ideally should be stateless. So if a caller can go to different machine. - Sessions should be stored in a centralized place, outside of the serveres.     - A cache or DB</p> <p>Scalability vs Performance</p> <ul> <li>Performance - a single call is fast</li> <li>Scalability - a call is slow under heavy load.</li> </ul> <p>Latency vs Throughput</p> <ul> <li>Latency - time for an action to complete</li> <li>Throughput - number of actions per unit of time</li> </ul> <p>Goal is maximal throughput at an acceptable latency. (As opposed to furthering latency even further for a worse throughput. Not really much sense to over optimizing latency).</p>"},{"location":"notes/system_design/scalability/#consistency","title":"Consistency","text":"<ul> <li>Weak consistency - a read may not pick up a write.<ul> <li>Video Games and Phone Calls. When you lose connection, you just don't get the missing data.</li> </ul> </li> <li>Eventual consistency - Data is replicated async, so you may not get it.</li> <li>Strong consistency - Replicated sync, blocking</li> </ul>"},{"location":"notes/system_design/scalability/#availability","title":"Availability","text":""},{"location":"notes/system_design/scalability/#fail-over","title":"Fail-over","text":"<p>For servers it seems?</p> <ul> <li> <p>Active - passing. Passive is on stand by and takes over when heartbeat is dead. There is some downtime when switching to passive. (If passive is cold, it'll take more time.)</p> </li> <li> <p>Active - Active. Two servers handles reads and writes.</p> </li> </ul> <p>Downsides - Additional hardware. Loss of data if master dies before replication.</p>"},{"location":"notes/system_design/scalability/#replication","title":"Replication","text":"<p>For DB it seems?</p>"},{"location":"posts/2018/2018-11-16-breadth-first-search/","title":"Breadth First Search","text":"<p>Wanting to expand my comment on this reddit post, I wanted to take a functional approach to classic algorithms. In this case, I wanted to create a breadth first.</p> <p>We'll use <code>Node</code> to represent a node in the graph we're traversing.</p> <pre><code>case class Node(id: String, neighbors: Set[Node])\n</code></pre> <p>The general approach to BFS is to use a FIFO queue to visit neighbors, marking each node as visited. We can use <code>Seq</code> to implement a FIFO queue and <code>Set</code> to keep track of visited neighbors.</p> <p>We can utilize recursive functions. Each iteration will need to know the target, the visited nodes, and the one that needs to be visited. It should return a Node, which will be our target, or <code>null</code> if not found.</p> <pre><code>def find(targetId: String, toVisit: Seq[Node], visitedNodes: Set[Node]): Node = ???\n</code></pre> <p>First let's address the terminating conditions: when we find the node or if there no more nodes left to look. In each iteration we will be looking at the head of the <code>toVisit</code> queue.</p> <pre><code>def find(targetId: String, toVisit: Seq[Node], visitedNodes: Set[Node]): Node = {\nif (toVisit.isEmpty) return null\nif (toVisit.head.id == targetId) return toVisit.head\n...\n}\n</code></pre> <p>Now let's address the recursive part. If we haven't found the node, we want to check the neighbors (that have not been visited) and remember this node we have already visited.</p> <pre><code>def find(targetId: String, toVisit: Seq[Node], visitedNodes: Set[Node]): Node = {\nif (toVisit.isEmpty) return null\nif (toVisit.head.id == targetId) return toVisit.head\n\nval newVisitedNodes = visitedNodes + toVisit.head\n// &amp;~ find the difference of the two sets\nval newToVisit = toVisit ++: (toVisit.head.neighbors &amp;~ visitedNodes).toSeq\n\nreturn find(targetId, newToVisit, newVisitedNodes)\n}\n</code></pre> <p>Don't use return in Scala.</p> <pre><code>def find(targetId: String, toVisit: Seq[Node], visitedNodes: Set[Node]): Node = {\nif (toVisit.isEmpty) null\nelse if (toVisit.head.id == targetId) toVisit.head\nelse {\nval newVisitedNodes = visitedNodes + toVisit.head\n// &amp;~ find the difference of the two sets\nval newToVisit = toVisit ++: (toVisit.head.neighbors &amp;~ visitedNodes).toSeq\n\nfind(targetId, newToVisit, newVisitedNodes)\n}\n}\n</code></pre> <p>The if statement is conditional on the <code>toVisit</code> variable. Given this, I prefer utilizing <code>match</code>:</p> <pre><code>def find(targetId: String, toVisit: Seq[Node], visitedNodes: Set[Node]): Node =\ntoVisit match {\ncase Nil =&gt; null\ncase head :: _ if head.id == targetId =&gt; head\ncase head :: tail =&gt; {\nval newVisitedNodes = visitedNodes + toVisit.head\n// &amp;~ find the difference of the two sets\nval newToVisit = toVisit ++: (toVisit.head.neighbors &amp;~ visitedNodes).toSeq\n\nfind(targetId, newToVisit, newVisitedNodes)\n}\n}\n</code></pre> <p>Inlining some variables and removing some braces results in:</p> <pre><code>def find(targetId: String, toVisit: Seq[Node], visitedNodes: Set[Node]): Node =\ntoVisit match {\ncase Nil =&gt; null\ncase head :: _ if head.id == targetId =&gt; head\ncase head :: tail =&gt; find(targetId, tail ++: (head.neighbors &amp;~ visitedNodes).toSeq,\nvisitedNodes + head)\n}\n</code></pre> <p>and add an entry method, giving us the final:</p> <pre><code>def find(targetId: String, startingNode: Node): Node =\nfind(targetId, Seq(startingNode), Set.empty)\n\ndef find(targetId: String, toVisit: Seq[Node], visitedNodes: Set[Node]): Node =\ntoVisit match {\ncase Nil =&gt; null\ncase head :: _ if head.id == targetId =&gt; head\ncase head :: tail =&gt; find(targetId, tail ++: (head.neighbors &amp;~ visitedNodes).toSeq,\nvisitedNodes + head)\n}\n</code></pre>"},{"location":"posts/2020/2020-09-16-learning-oauth2/","title":"OAuth 2","text":""},{"location":"posts/2020/2020-09-16-learning-oauth2/#the-driving-example","title":"The Driving Example","text":"<p>In my attempt to learn Rust (check out my notes here), I wanted to see if I can create a discord API wrapper in Rust.</p> <p>I was able to create a new project, use an http crate, and make api calls. Cool! The next step was hitting Discord API's. This is when it got tricky.</p> <p>Discord requires authentication (as it should) from clients that want to access it API's. It does this by supporting OAuth2.</p> <p>Glancing over Discord's documentation for OAuth2, I saw terms such as authorization url, token url, OAuth2 scopes, code grant, etc - which made me realize I had no idea what I was doing.</p> <p>I took a step back and decided to learn what OAuth2 was. I found a helpful article on DigitalOcean that broke it down in a helpful way.</p>"},{"location":"posts/2020/2020-09-16-learning-oauth2/#oauth2","title":"OAuth2","text":"<p>OAuth2 is an authorization framework that allows:</p> <ol> <li>an application (my rust binary) to</li> <li>access user accounts (my discord account)</li> <li>on an HTTP service (i.e. Discord)</li> </ol> <p>This allows any third party applications to access a users account for their own purposes. This could be an application that populates a calendar with your friend's birthdays by looking at Facebook. The application needs access to your Facebook account to do this, and it can't just sign in as you to achieve this.</p>"},{"location":"posts/2020/2020-09-16-learning-oauth2/#roles","title":"Roles","text":"<p>There are 4 OAuth roles:</p> Role Description Resource Owner The user who authorizes an application to access their account. (i.e. me) Client The application that wants to access a user's account. (i.e. my rust binary) Resource Server The server that hosts the user's account. (i.e. Discord) Authorization Server The server that verifies the user's id and issues access tokens to the application. (i.e. Discord)"},{"location":"posts/2020/2020-09-16-learning-oauth2/#high-level-flow-of-authorization","title":"High Level Flow of Authorization","text":"<ol> <li>The application requests the user authorization to access (some) service resources.</li> <li>The user authorizes the request, and the application receives an authorization grant.</li> <li>The application requests the authorization server an access token by showing authentication of its own identity (the application's, not the user's) and the authorization grant.</li> <li>The authorization server issues an access token to the application.</li> <li>The application requests the resource server some resources and presents the access token.</li> <li>The resource server serves the resource to the application.</li> </ol>"},{"location":"posts/2020/2020-09-16-learning-oauth2/#application-registration","title":"Application Registration","text":"<p>Before an application can use OAuth2, it needs to register itself with the service. Services usually provide a registration form of some manner.</p> <p>In Discord, this looks like a developer portal, where you can create a new application:</p> <p></p>"},{"location":"posts/2020/2020-09-16-learning-oauth2/#client-id-and-client-secret","title":"Client ID and Client Secret","text":"<p>The service will issue client credentials in the form of</p> <ul> <li>client id - A publicly exposed string used by the service to identify the application</li> <li>client secret - A private string used to authenticate the application when requesting user resources to the service. This must kept private.</li> </ul>"},{"location":"posts/2020/2020-09-16-learning-oauth2/#authorization-grant","title":"Authorization Grant","text":"<p>There are 4 types of authorization grants defined by OAuth2:</p> <ol> <li>Authorization CodeApplications</li> <li>Implicit</li> <li>Resource Owner Password Credentials</li> <li>Client Credentials</li> </ol> <p>The authorization grant type used depends on:</p> <ol> <li>The method used by the application to request authorization.</li> <li>The grant types supported by the service API.</li> </ol>"},{"location":"posts/2020/2020-09-16-learning-oauth2/#grant-type-authorization-code","title":"Grant Type - Authorization Code","text":"<p>This grant type is optimized for server-side applications. The application must be able to receive HTTP requests from the user-agent (i.e. the user's web browser) because the service will redirect the user once authorization is granted.</p> <ol> <li>Client is given an authorization code link: <code>https://discord.com/api/oauth2/authorize?response_type=code&amp;client_id=123456789&amp;permissions=8&amp;redirect_uri=http%3A%2F%2Farjun.adhia.net&amp;scope=bot</code><ul> <li><code>https://discord.com/api/oauth2/authorize</code> - Discord's API authorization endpoint</li> <li><code>client_id=123456789</code> - the application's client id.</li> <li><code>redirect_uri=http%3A%2F%2Farjun.adhia.net</code> - The URI that the service redirects the user after an authorization code is granted.</li> <li><code>response_type=code</code> - Specifies that the application is requesting an authorization code grant.</li> <li><code>scope=bot</code> - specifies the level of access that the application is requesting. (For Discord, this is defined under OAuth2 Scopes).</li> </ul> </li> <li>Client authorizes the application - The user will click on the above link, and the service will ask the user to authorize or deny the application.</li> <li>Client is redirected to the provided <code>redirect_url</code> once they authorize: <code>https://arjun.adhia.net/?code=987654321</code><ul> <li><code>code=987654321</code> - The authorization code provided by the service, as an argument to the redirect url.</li> </ul> </li> <li>Application requests access token - The application, requests a token with a <code>POST</code>: <code>https://discord.com/api/oauth2/token?client_id=1234567890&amp;client_secret=3216549870&amp;grant_type=authorization_code&amp;code=098763421&amp;redirect_uri=http%3A%2F%2Farjun.adhia.net&amp;scope=bot</code><ul> <li><code>client_id=1234567890</code></li> <li><code>client_secret=3216549870</code> - the client secret. The client secret can be held by the application because it is server-side and source code is hidden. If this was client side, anyone can see the secret.</li> <li><code>grant_type=authorization_code</code></li> <li><code>code=098763421</code></li> <li><code>redirect_uri=http%3A%2F%2Farjun.adhia.net</code></li> <li><code>scope=bot</code></li> </ul> </li> <li>The API will return a response with the access token (and potentially a refresh token, to get a new token when the returned one expires) - the application can now use this token when making calls to the service.</li> </ol>"},{"location":"posts/2020/2020-09-16-learning-oauth2/#grant-type-implicit","title":"Grant Type - Implicit","text":"<p>This grant type is for mobile apps and web applications, where the client secret confidentaility is not guaranteed.</p> <p>In this grant type, the user-agent gets the access token to give to the application. Because of this, the token is exposed to the user and potentially other applications on the user device.</p> <p>This flow does not authenticate the identity of the application. It relies that the redirect URI is properly configured.</p> <ol> <li>THe user is given an authorization link, to get a token from the service. This is similar to autorization code link except it requests a token instead of a code. (Check the reponse type in the url): <code>https://discord.com/api/oauth2/authorize?response_type=token&amp;client_id=290926444748734499&amp;state=15773059ghq9183habn&amp;scope=identify</code></li> <li>Client authorizes the application - The user will click on the above link, and the service will ask the user to authorize or deny the application.</li> <li>User-agent receives the redirect URI and the URL contains the access token: <code>https://arjun.adhia.net/?access_token=RTfP0OK99U3kbRtHOoKLmJbOn45PjL&amp;token_type=Bearer&amp;expires_in=604800&amp;scope=identify&amp;state=15773059ghq9183habn</code>.</li> <li>User-agent gets redirected to the redirect URI.</li> <li>The application returns a webpage that contains a script that can get the access token from the redirect URI.</li> <li>User-agent gets the token and passes it to the application.</li> </ol>"},{"location":"posts/2020/2020-09-16-learning-oauth2/#grant-type-resource-owner-password-credentials","title":"Grant Type - Resource Owner Password Credentials","text":"<p>The user provides their service credentials (like username and password) directly to the application, which uses the credentials to get the token from the service.</p> <p>This should only be used if the application is trusted by the user.</p> <ol> <li>The application requests a token via a <code>POST</code>. Ex: <code>https://oauth.example.com/token?grant_type=password&amp;username=USERNAME&amp;password=PASSWORD&amp;client_id=CLIENT_ID</code></li> </ol> <p>(Discord doesn't have this grant type)</p>"},{"location":"posts/2020/2020-09-16-learning-oauth2/#grant-type-client-credentials","title":"Grant Type - Client Credentials","text":"<p>This provides an application a way to access its own service account.</p> <p>Examples of when this would be useful:</p> <ul> <li>An application wants to update its registered description or redirect URI</li> <li> <p>Access other data stored in its service account via the API.</p> </li> <li> <p>The application requests a token via a <code>POST</code> with its credentials, client id, and client secret:</p> </li> </ul> <pre><code>'https://discord.com/api/oauth2/token'\n\nauth = (CLIENT_ID, CLIENT_SECRET)\ndata = {\n    'grant_type': 'client_credentials',\n    'scope': 'identify connections'\n}\nheaders = {\n    'Content-Type': 'application/x-www-form-urlencoded'\n}\n</code></pre>"},{"location":"posts/2020/2020-09-16-learning-oauth2/#token-usage","title":"Token Usage","text":"<p>Once an application has a token, it can use the token to access the user's account via the API.</p> <p><code>curl -X POST -H \"Authorization: Bearer ACCESS_TOKEN\"\"https://discord.com/api/users/@me\"</code>.</p>"},{"location":"posts/2020/2020-09-16-learning-oauth2/#refresh-token-flow","title":"Refresh Token Flow","text":"<p>After an access token expires, API's will return an \"Invalid Token Error\". If a refresh toke was included when getting the original token was provided, the application can use it to request a new token.</p> <p>Discord requires the following (for authorization code grant type, the other grant types do not have refresh token):</p> <ul> <li>client id</li> <li>client secret</li> <li>grant type</li> <li>refresh token</li> <li>redirect uri</li> <li>scope</li> </ul> <pre><code>'https://discord.com/api/oauth2/token'\n\ndata = {\n    'client_id': CLIENT_ID,\n    'client_secret': CLIENT_SECRET,\n    'grant_type': 'refresh_token',\n    'refresh_token': refresh_token,\n    'redirect_uri': REDIRECT_URI,\n    'scope': 'identify email connections'\n}\nheaders = {\n    'Content-Type': 'application/x-www-form-urlencoded'\n}\n</code></pre>"}]}